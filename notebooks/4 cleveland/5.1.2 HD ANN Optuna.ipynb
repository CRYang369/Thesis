{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a9cc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score  \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,roc_auc_score,accuracy_score, plot_confusion_matrix,classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12583cbc",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8c97c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>chol</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>233</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>286</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>229</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>204</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  chol  restecg  thalach  exang  oldpeak  ca  thal  label\n",
       "0   63    1   1   233        2      150      0      2.3   0     6      0\n",
       "1   67    1   4   286        2      108      1      1.5   3     3      1\n",
       "2   67    1   4   229        2      129      1      2.6   2     7      1\n",
       "3   37    1   3   250        0      187      0      3.5   0     3      0\n",
       "4   41    0   2   204        2      172      0      1.4   0     3      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HDData=pd.read_csv('HD selected 10 features.csv')\n",
    "HDData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0db571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQe0lEQVR4nO3df6zddX3H8efLFnDonJBeGLZomals4FiUO+aPzKjMwTZHmQFTMrZGWbofzB/LpoOZDLOlC5u6zTg1abRSJ4E1+INuyVTWTYmbwi6IQqmMRhxUKr3INn8sQ4vv/XG+/Xisp/Ry7TnfS8/zkZBzvp/P93vOi6Tpq9+fJ1WFJEkAT+g7gCRp6bAUJEmNpSBJaiwFSVJjKUiSmuV9B/hBrFixolavXt13DEl6XLnlllserKqZUXOP61JYvXo1c3NzfceQpMeVJP95sDkPH0mSGktBktRYCpKkxlKQJDWWgiSpsRQkSY2lIElqLAVJUmMpSJKax/UdzYfDmW94f98RtATd8pZf7zuC1Av3FCRJzdhKIcnmJHuT3HHA+GuS3JVkR5K/GBq/PMmubu6cceWSJB3cOA8fXQX8DdCOzyR5CbAWOKOqHk5yQjd+GrAOOB14GvBPSZ5VVY+MMZ8k6QBj21OoqhuBhw4Y/m3gyqp6uFtnbze+Fri2qh6uqnuAXcBZ48omSRpt0ucUngX8bJKbknwyyU934yuB+4bW292NfZ8kG5LMJZmbn58fc1xJmi6TLoXlwHHA84A3AFuTBMiIdWvUB1TVpqqararZmZmRvxEhSVqkSZfCbuBDNXAz8B1gRTd+8tB6q4D7J5xNkqbepEvhI8BLAZI8CzgaeBDYBqxLckySU4A1wM0TziZJU29sVx8luQZ4MbAiyW7gCmAzsLm7TPVbwPqqKmBHkq3AncA+4FKvPJKkyRtbKVTVRQeZuvgg628ENo4rjyTp0LyjWZLUWAqSpMZSkCQ1loIkqbEUJEmNpSBJaiwFSVJjKUiSGktBktRYCpKkxlKQJDWWgiSpsRQkSY2lIElqLAVJUmMpSJKasZVCks1J9na/snbg3B8kqSQrhsYuT7IryV1JzhlXLknSwY1zT+Eq4NwDB5OcDLwMuHdo7DRgHXB6t827kiwbYzZJ0ghjK4WquhF4aMTUXwFvBGpobC1wbVU9XFX3ALuAs8aVTZI02kTPKSQ5D/hyVX3ugKmVwH1Dy7u7sVGfsSHJXJK5+fn5MSWVpOm0fFJflORY4E3Az4+aHjFWI8aoqk3AJoDZ2dmR60hHgnv/5Cf7jqAl6Ol/fPtYP39ipQA8EzgF+FwSgFXArUnOYrBncPLQuquA+yeYTZLEBA8fVdXtVXVCVa2uqtUMiuC5VfUVYBuwLskxSU4B1gA3TyqbJGlgnJekXgN8Gjg1ye4klxxs3araAWwF7gQ+ClxaVY+MK5skabSxHT6qqosOMb/6gOWNwMZx5ZEkHZp3NEuSGktBktRYCpKkxlKQJDWWgiSpsRQkSY2lIElqLAVJUmMpSJIaS0GS1FgKkqTGUpAkNZaCJKmxFCRJjaUgSWosBUlSM85fXtucZG+SO4bG3pLkC0k+n+TDSZ46NHd5kl1J7kpyzrhySZIObpx7ClcB5x4wdgPw7Ko6A/gP4HKAJKcB64DTu23elWTZGLNJkkYYWylU1Y3AQweMfbyq9nWLnwFWde/XAtdW1cNVdQ+wCzhrXNkkSaP1eU7h1cA/du9XAvcNze3uxr5Pkg1J5pLMzc/PjzmiJE2XXkohyZuAfcDV+4dGrFajtq2qTVU1W1WzMzMz44ooSVNp+aS/MMl64OXA2VW1/y/+3cDJQ6utAu6fdDZJmnYT3VNIci7wh8B5VfW/Q1PbgHVJjklyCrAGuHmS2SRJY9xTSHIN8GJgRZLdwBUMrjY6BrghCcBnquq3qmpHkq3AnQwOK11aVY+MK5skabSxlUJVXTRi+L2Psv5GYOO48kiSDs07miVJjaUgSWosBUlSYylIkhpLQZLUWAqSpMZSkCQ1loIkqbEUJEmNpSBJaiwFSVJjKUiSGktBktRYCpKkxlKQJDWWgiSpGVspJNmcZG+SO4bGjk9yQ5K7u9fjhuYuT7IryV1JzhlXLknSwY1zT+Eq4NwDxi4DtlfVGmB7t0yS04B1wOndNu9KsmyM2SRJI4ytFKrqRuChA4bXAlu691uA84fGr62qh6vqHmAXcNa4skmSRpv0OYUTq2oPQPd6Qje+ErhvaL3d3ZgkaYKWyonmjBirkSsmG5LMJZmbn58fcyxJmi6TLoUHkpwE0L3u7cZ3AycPrbcKuH/UB1TVpqqararZmZmZsYaVpGkz6VLYBqzv3q8Hrh8aX5fkmCSnAGuAmyecTZKm3vJxfXCSa4AXAyuS7AauAK4Etia5BLgXuBCgqnYk2QrcCewDLq2qR8aVTZI02thKoaouOsjU2QdZfyOwcVx5JEmHtlRONEuSloAFlUKS7QsZkyQ9vj3q4aMkTwSOZXBe4Di+e+noU4CnjTmbJGnCDnVO4TeB1zMogFv4bil8DXjn+GJJkvrwqKVQVW8H3p7kNVX1jgllkiT1ZEFXH1XVO5K8AFg9vE1VvX9MuSRJPVhQKST5W+CZwG3A/vsHCrAUJOkIstD7FGaB06pq5POIJElHhoXep3AH8KPjDCJJ6t9C9xRWAHcmuRl4eP9gVZ03llSSpF4stBTePM4QkqSlYaFXH31y3EEkSf1b6NVHX+e7P3pzNHAU8M2qesq4gkmSJm+hewo/PLyc5Hz8DWVJOuIs6impVfUR4KWHN4okqW8LPXz0iqHFJzC4b8F7FiTpCLPQq49+eej9PuBLwNrDnkaS1KuFnlN41eH80iS/B/wGg72N24FXMXhE998xeL7Sl4BXVtV/Hc7vlSQ9uoX+yM6qJB9OsjfJA0k+mGTVYr4wyUrgtcBsVT0bWAasAy4DtlfVGmB7tyxJmqCFnmh+H7CNwe8qrAT+vhtbrOXADyVZzmAP4X4Gh6O2dPNbgPN/gM+XJC3CQkthpqreV1X7uv+uAmYW84VV9WXgrcC9wB7gf6rq48CJVbWnW2cPcMKo7ZNsSDKXZG5+fn4xESRJB7HQUngwycVJlnX/XQx8dTFf2P2s51rgFAZ7Hk/qPm9BqmpTVc1W1ezMzKJ6SZJ0EAsthVcDrwS+wuBf9xcwODm8GD8H3FNV81X1beBDwAuAB5KcBNC97l3k50uSFmmhpfCnwPqqmqmqExiUxJsX+Z33As9LcmySAGcDOxmcs1jfrbMeuH6Rny9JWqSF3qdwxvDloVX1UJLnLOYLq+qmJNcBtzK45+GzwCbgycDWJJcwKI4LF/P5kqTFW2gpPCHJcfuLIcnxj2Hb71NVVwBXHDD8MIO9BklSTxb6F/vbgH/r/oVfDM4vbBxbKklSLxZ6R/P7k8wxeAhegFdU1Z1jTSZJmrgFHwLqSsAikKQj2KIenS1JOjJZCpKkxlKQJDWWgiSpsRQkSY2lIElqLAVJUmMpSJIaS0GS1FgKkqTGUpAkNZaCJKmxFCRJTS+lkOSpSa5L8oUkO5M8P8nxSW5Icnf3elwf2SRpmvW1p/B24KNV9ePATzH4jebLgO1VtQbY3i1LkiZo4qWQ5CnAi4D3AlTVt6rqv4G1wJZutS3A+ZPOJknTro89hR8D5oH3JflskvckeRJwYlXtAeheTxi1cZINSeaSzM3Pz08utSRNgT5KYTnwXODdVfUc4Js8hkNFVbWpqmaranZmZmZcGSVpKvVRCruB3VV1U7d8HYOSeCDJSQDd694esknSVJt4KVTVV4D7kpzaDZ3N4LeftwHru7H1wPWTziZJ0255T9/7GuDqJEcDXwRexaCgtia5BLgXuLCnbJI0tXophaq6DZgdMXX2hKNIkoZ4R7MkqbEUJEmNpSBJaiwFSVJjKUiSGktBktRYCpKkxlKQJDWWgiSpsRQkSY2lIElqLAVJUmMpSJIaS0GS1FgKkqTGUpAkNb2VQpJlST6b5B+65eOT3JDk7u71uL6ySdK06nNP4XXAzqHly4DtVbUG2N4tS5ImqJdSSLIK+CXgPUPDa4Et3fstwPkTjiVJU6+vPYW/Bt4IfGdo7MSq2gPQvZ4wasMkG5LMJZmbn58fe1BJmiYTL4UkLwf2VtUti9m+qjZV1WxVzc7MzBzmdJI03Zb38J0vBM5L8ovAE4GnJPkA8ECSk6pqT5KTgL09ZJOkqTbxPYWquryqVlXVamAd8M9VdTGwDVjfrbYeuH7S2SRp2i2l+xSuBF6W5G7gZd2yJGmC+jh81FTVJ4BPdO+/CpzdZx5JmnZLaU9BktQzS0GS1FgKkqTGUpAkNZaCJKmxFCRJjaUgSWosBUlSYylIkhpLQZLUWAqSpMZSkCQ1loIkqbEUJEmNpSBJaiwFSVIz8VJIcnKSf0myM8mOJK/rxo9PckOSu7vX4yadTZKmXR97CvuA36+qnwCeB1ya5DTgMmB7Va0BtnfLkqQJmngpVNWeqrq1e/91YCewElgLbOlW2wKcP+lskjTtej2nkGQ18BzgJuDEqtoDg+IATugxmiRNpd5KIcmTgQ8Cr6+qrz2G7TYkmUsyNz8/P76AkjSFeimFJEcxKISrq+pD3fADSU7q5k8C9o7atqo2VdVsVc3OzMxMJrAkTYk+rj4K8F5gZ1X95dDUNmB99349cP2ks0nStFvew3e+EPg14PYkt3VjfwRcCWxNcglwL3BhD9kkaapNvBSq6lNADjJ99iSzSJK+l3c0S5IaS0GS1FgKkqTGUpAkNZaCJKmxFCRJjaUgSWosBUlSYylIkhpLQZLUWAqSpMZSkCQ1loIkqbEUJEmNpSBJaiwFSVJjKUiSmiVXCknOTXJXkl1JLus7jyRNkyVVCkmWAe8EfgE4DbgoyWn9ppKk6bGkSgE4C9hVVV+sqm8B1wJre84kSVNjed8BDrASuG9oeTfwM8MrJNkAbOgWv5HkrgllmwYrgAf7DrEU5K3r+46g7+Wfzf2uyOH4lGccbGKplcKo/9v6noWqTcCmycSZLknmqmq27xzSgfyzOTlL7fDRbuDkoeVVwP09ZZGkqbPUSuHfgTVJTklyNLAO2NZzJkmaGkvq8FFV7Uvyu8DHgGXA5qra0XOsaeJhOS1V/tmckFTVodeSJE2FpXb4SJLUI0tBktRYCvLRIlqykmxOsjfJHX1nmRaWwpTz0SJa4q4Czu07xDSxFOSjRbRkVdWNwEN955gmloJGPVpkZU9ZJPXMUtAhHy0iaXpYCvLRIpIaS0E+WkRSYylMuaraB+x/tMhOYKuPFtFSkeQa4NPAqUl2J7mk70xHOh9zIUlq3FOQJDWWgiSpsRQkSY2lIElqLAVJUmMpSI9Bkm8cYn71Y32iZ5KrklzwgyWTDg9LQZLUWArSIiR5cpLtSW5NcnuS4SfLLk+yJcnnk1yX5NhumzOTfDLJLUk+luSknuJLB2UpSIvzf8CvVNVzgZcAb0uy/+GCpwKbquoM4GvA7yQ5CngHcEFVnQlsBjb2kFt6VMv7DiA9TgX4syQvAr7D4HHjJ3Zz91XVv3bvPwC8Fvgo8Gzghq47lgF7JppYWgBLQVqcXwVmgDOr6ttJvgQ8sZs78NkxxaBEdlTV8ycXUXrsPHwkLc6PAHu7QngJ8Iyhuacn2f+X/0XAp4C7gJn940mOSnL6RBNLC2ApSItzNTCbZI7BXsMXhuZ2AuuTfB44Hnh391OnFwB/nuRzwG3ACyYbWTo0n5IqSWrcU5AkNZaCJKmxFCRJjaUgSWosBUlSYylIkhpLQZLU/D/ESxY5tJcMzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='label',data=HDData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee8cd2",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b09ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HDData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d5b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HDData01=HDData.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0164e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=HDData01.drop(labels=['label'],axis=1)\n",
    "\n",
    "y1=HDData01['label'].values\n",
    "y1 = LabelEncoder().fit_transform(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed2ad0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stanardilization\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X1)\n",
    "X1=scaler.transform(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe46089",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c359dfcf",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a45779f",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape : (242, 10)\n",
      "X_test.shape : (61, 10)\n"
     ]
    }
   ],
   "source": [
    "#split train dataset and test dataset\n",
    "X1_train, X1_test,y1_train,y1_test= train_test_split(X1,y1,test_size=0.2, shuffle = True,stratify=y1,random_state=42)\n",
    "print(\"X_train.shape :\",X1_train.shape)\n",
    "print(\"X_test.shape :\",X1_test.shape)\n",
    "# print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e17518",
   "metadata": {},
   "source": [
    "Define the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12db8e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X1_train = torch.from_numpy(X1_train)\n",
    "y1_train = torch.from_numpy(y1_train ).type(torch.LongTensor)\n",
    "\n",
    "X1_test  = torch.from_numpy(X1_test )\n",
    "y1_test= torch.from_numpy(y1_test).type(torch.LongTensor)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train = torch.utils.data.TensorDataset(X1_train, y1_train )\n",
    "test = torch.utils.data.TensorDataset(X1_test , y1_test)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a2d920",
   "metadata": {},
   "source": [
    "Define the Optuna  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e43e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-09 15:35:05,114]\u001b[0m A new study created in memory with name: no-name-f4734063-b33d-47f3-a2d0-0a8c0d9e4b46\u001b[0m\n",
      "C:\\Users\\COOLER~1\\AppData\\Local\\Temp/ipykernel_16184/3318135143.py:96: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2022-09-09 15:35:05,261]\u001b[0m Trial 0 finished with value: 0.7213114754098361 and parameters: {'learning_rate': 0.0006360539349309912, 'optimizer': 'Adam', 'n_layers': 1, 'n_units_l0': 10}. Best is trial 0 with value: 0.7213114754098361.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:05,381]\u001b[0m Trial 1 finished with value: 0.8524590163934426 and parameters: {'learning_rate': 0.004508065858019759, 'optimizer': 'RMSprop', 'n_layers': 1, 'n_units_l0': 14}. Best is trial 1 with value: 0.8524590163934426.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:05,521]\u001b[0m Trial 2 finished with value: 0.8688524590163934 and parameters: {'learning_rate': 0.008975335581549077, 'optimizer': 'SGD', 'n_layers': 1, 'n_units_l0': 117}. Best is trial 2 with value: 0.8688524590163934.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:05,692]\u001b[0m Trial 3 finished with value: 0.8852459016393442 and parameters: {'learning_rate': 0.002118026787621538, 'optimizer': 'Adam', 'n_layers': 2, 'n_units_l0': 104, 'n_units_l1': 66}. Best is trial 3 with value: 0.8852459016393442.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:05,903]\u001b[0m Trial 4 finished with value: 0.8688524590163934 and parameters: {'learning_rate': 0.0006843930365672622, 'optimizer': 'Adam', 'n_layers': 3, 'n_units_l0': 70, 'n_units_l1': 83, 'n_units_l2': 93}. Best is trial 3 with value: 0.8852459016393442.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:05,913]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:05,923]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:05,933]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:05,943]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:05,953]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,154]\u001b[0m Trial 10 finished with value: 0.819672131147541 and parameters: {'learning_rate': 0.09062528955099464, 'optimizer': 'Adam', 'n_layers': 2, 'n_units_l0': 93, 'n_units_l1': 118}. Best is trial 3 with value: 0.8852459016393442.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,174]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,204]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,222]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,255]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,275]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,305]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,325]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,345]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,514]\u001b[0m Trial 19 finished with value: 0.8360655737704918 and parameters: {'learning_rate': 0.001662265716352253, 'optimizer': 'RMSprop', 'n_layers': 2, 'n_units_l0': 43, 'n_units_l1': 34}. Best is trial 3 with value: 0.8852459016393442.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,536]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,556]\u001b[0m Trial 21 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,586]\u001b[0m Trial 22 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,616]\u001b[0m Trial 23 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,646]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,666]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,696]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,847]\u001b[0m Trial 27 finished with value: 0.8360655737704918 and parameters: {'learning_rate': 0.004093392606346011, 'optimizer': 'RMSprop', 'n_layers': 2, 'n_units_l0': 30, 'n_units_l1': 76}. Best is trial 3 with value: 0.8852459016393442.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:06,988]\u001b[0m Trial 28 finished with value: 0.8524590163934426 and parameters: {'learning_rate': 0.0325908902427629, 'optimizer': 'Adam', 'n_layers': 1, 'n_units_l0': 121}. Best is trial 3 with value: 0.8852459016393442.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:35:07,008]\u001b[0m Trial 29 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a model by implementing define-by-run design from Optuna\n",
    "def build_model_custom(trial):\n",
    "    \n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 10\n",
    "# looping to determine the number of layers and nodes in each layer     \n",
    "    for i in range(n_layers):\n",
    "#         the number of nodes in each layer.\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        \n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "#         p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "#         layers.append(nn.Dropout(p))\n",
    "        \n",
    "        in_features = out_features\n",
    "        \n",
    "    layers.append(nn.Linear(in_features, 10))\n",
    "#     layers.append(nn.ReLU())\n",
    "    \n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# Train and evaluate the accuracy of neural network with the addition of pruning mechanism\n",
    "def train_and_evaluate(param, model, trial):\n",
    "    \n",
    "\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = getattr(optim, param['optimizer'])(model.parameters(), lr= param['learning_rate'])\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(EPOCHS):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in train_loader:\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                train_input = train_input.to(device)\n",
    "\n",
    "                output = model(train_input.float())\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in test_loader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    val_input = val_input.to(device)\n",
    "\n",
    "                    output = model(val_input.float())\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            accuracy = total_acc_val/len(test)\n",
    "            \n",
    "            # Add prune mechanism\n",
    "            trial.report(accuracy, epoch_num)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "  \n",
    "# Define a set of hyperparameter values, build the model, train the model, and evaluate the accuracy\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "              'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "              'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
    "              }\n",
    "    \n",
    "    model = build_model_custom(trial)\n",
    "\n",
    "    accuracy = train_and_evaluate(params, model, trial)\n",
    "\n",
    "    return accuracy\n",
    "  \n",
    "EPOCHS = 30\n",
    "    \n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "494ce74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.002118026787621538\n",
      "optimizer: Adam\n",
      "n_layers: 2\n",
      "n_units_l0: 104\n",
      "n_units_l1: 66\n"
     ]
    }
   ],
   "source": [
    "#the best result\n",
    "best_trial = study.best_trial\n",
    "\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f205e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate: 0.0016759066603823113\n",
    "# optimizer: RMSprop\n",
    "# n_layers: 1\n",
    "# n_units_l0: 65\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f8a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(ANNModel, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu1 = nn.ReLU()      \n",
    "       \n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a67eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =30\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = X1.shape[1]\n",
    "hidden_dim=65\n",
    "output_dim = len(set(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a447bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANNModel(input_dim, hidden_dim,output_dim)\n",
    "\n",
    "\n",
    "learning_rate = 0.0016\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e313495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn_metrics] Epoch:0 loss:0.3046 accuracy:0.8516 precision:0.8516 recall:0.8516 f1:0.8516\n",
      "[sklearn_metrics] Epoch:0 loss:0.5737 accuracy:0.8719 precision:0.8719 recall:0.8719 f1:0.8719\n",
      "[sklearn_metrics] Epoch:1 loss:0.2794 accuracy:0.8906 precision:0.8906 recall:0.8906 f1:0.8906\n",
      "[sklearn_metrics] Epoch:1 loss:0.5674 accuracy:0.8760 precision:0.8760 recall:0.8760 f1:0.8760\n",
      "[sklearn_metrics] Epoch:2 loss:0.2704 accuracy:0.8750 precision:0.8750 recall:0.8750 f1:0.8750\n",
      "[sklearn_metrics] Epoch:2 loss:0.5660 accuracy:0.8760 precision:0.8760 recall:0.8760 f1:0.8760\n",
      "[sklearn_metrics] Epoch:3 loss:0.2597 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:3 loss:0.5622 accuracy:0.8802 precision:0.8802 recall:0.8802 f1:0.8802\n",
      "[sklearn_metrics] Epoch:4 loss:0.2376 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:4 loss:0.5628 accuracy:0.8802 precision:0.8802 recall:0.8802 f1:0.8802\n",
      "[sklearn_metrics] Epoch:5 loss:0.2866 accuracy:0.8672 precision:0.8672 recall:0.8672 f1:0.8672\n",
      "[sklearn_metrics] Epoch:5 loss:0.5525 accuracy:0.8843 precision:0.8843 recall:0.8843 f1:0.8843\n",
      "[sklearn_metrics] Epoch:6 loss:0.2427 accuracy:0.9062 precision:0.9062 recall:0.9062 f1:0.9062\n",
      "[sklearn_metrics] Epoch:6 loss:0.5517 accuracy:0.8802 precision:0.8802 recall:0.8802 f1:0.8802\n",
      "[sklearn_metrics] Epoch:7 loss:0.2167 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:7 loss:0.5509 accuracy:0.8843 precision:0.8843 recall:0.8843 f1:0.8843\n",
      "[sklearn_metrics] Epoch:8 loss:0.2418 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:8 loss:0.5454 accuracy:0.8802 precision:0.8802 recall:0.8802 f1:0.8802\n",
      "[sklearn_metrics] Epoch:9 loss:0.2378 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:9 loss:0.5423 accuracy:0.8843 precision:0.8843 recall:0.8843 f1:0.8843\n",
      "[sklearn_metrics] Epoch:10 loss:0.2521 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:10 loss:0.5354 accuracy:0.8843 precision:0.8843 recall:0.8843 f1:0.8843\n",
      "[sklearn_metrics] Epoch:11 loss:0.2638 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:11 loss:0.5316 accuracy:0.8843 precision:0.8843 recall:0.8843 f1:0.8843\n",
      "[sklearn_metrics] Epoch:12 loss:0.2307 accuracy:0.9062 precision:0.9062 recall:0.9062 f1:0.9062\n",
      "[sklearn_metrics] Epoch:12 loss:0.5276 accuracy:0.8884 precision:0.8884 recall:0.8884 f1:0.8884\n",
      "[sklearn_metrics] Epoch:13 loss:0.2545 accuracy:0.8828 precision:0.8828 recall:0.8828 f1:0.8828\n",
      "[sklearn_metrics] Epoch:13 loss:0.5214 accuracy:0.8884 precision:0.8884 recall:0.8884 f1:0.8884\n",
      "[sklearn_metrics] Epoch:14 loss:0.2458 accuracy:0.8828 precision:0.8828 recall:0.8828 f1:0.8828\n",
      "[sklearn_metrics] Epoch:14 loss:0.5190 accuracy:0.8884 precision:0.8884 recall:0.8884 f1:0.8884\n",
      "[sklearn_metrics] Epoch:15 loss:0.2472 accuracy:0.8828 precision:0.8828 recall:0.8828 f1:0.8828\n",
      "[sklearn_metrics] Epoch:15 loss:0.5187 accuracy:0.8926 precision:0.8926 recall:0.8926 f1:0.8926\n",
      "[sklearn_metrics] Epoch:16 loss:0.2337 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:16 loss:0.5137 accuracy:0.8926 precision:0.8926 recall:0.8926 f1:0.8926\n",
      "[sklearn_metrics] Epoch:17 loss:0.2318 accuracy:0.8906 precision:0.8906 recall:0.8906 f1:0.8906\n",
      "[sklearn_metrics] Epoch:17 loss:0.5090 accuracy:0.8884 precision:0.8884 recall:0.8884 f1:0.8884\n",
      "[sklearn_metrics] Epoch:18 loss:0.2419 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:18 loss:0.5060 accuracy:0.8843 precision:0.8843 recall:0.8843 f1:0.8843\n",
      "[sklearn_metrics] Epoch:19 loss:0.2565 accuracy:0.8906 precision:0.8906 recall:0.8906 f1:0.8906\n",
      "[sklearn_metrics] Epoch:19 loss:0.5006 accuracy:0.8926 precision:0.8926 recall:0.8926 f1:0.8926\n",
      "[sklearn_metrics] Epoch:20 loss:0.2244 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:20 loss:0.5010 accuracy:0.8967 precision:0.8967 recall:0.8967 f1:0.8967\n",
      "[sklearn_metrics] Epoch:21 loss:0.2767 accuracy:0.8672 precision:0.8672 recall:0.8672 f1:0.8672\n",
      "[sklearn_metrics] Epoch:21 loss:0.4908 accuracy:0.8926 precision:0.8926 recall:0.8926 f1:0.8926\n",
      "[sklearn_metrics] Epoch:22 loss:0.2449 accuracy:0.8828 precision:0.8828 recall:0.8828 f1:0.8828\n",
      "[sklearn_metrics] Epoch:22 loss:0.4933 accuracy:0.8926 precision:0.8926 recall:0.8926 f1:0.8926\n",
      "[sklearn_metrics] Epoch:23 loss:0.2278 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:23 loss:0.4932 accuracy:0.8967 precision:0.8967 recall:0.8967 f1:0.8967\n",
      "[sklearn_metrics] Epoch:24 loss:0.2390 accuracy:0.9062 precision:0.9062 recall:0.9062 f1:0.9062\n",
      "[sklearn_metrics] Epoch:24 loss:0.4868 accuracy:0.8967 precision:0.8967 recall:0.8967 f1:0.8967\n",
      "[sklearn_metrics] Epoch:25 loss:0.2370 accuracy:0.8828 precision:0.8828 recall:0.8828 f1:0.8828\n",
      "[sklearn_metrics] Epoch:25 loss:0.4817 accuracy:0.8967 precision:0.8967 recall:0.8967 f1:0.8967\n",
      "[sklearn_metrics] Epoch:26 loss:0.2366 accuracy:0.9062 precision:0.9062 recall:0.9062 f1:0.9062\n",
      "[sklearn_metrics] Epoch:26 loss:0.4838 accuracy:0.8967 precision:0.8967 recall:0.8967 f1:0.8967\n",
      "[sklearn_metrics] Epoch:27 loss:0.2001 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:27 loss:0.4821 accuracy:0.9008 precision:0.9008 recall:0.9008 f1:0.9008\n",
      "[sklearn_metrics] Epoch:28 loss:0.2323 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:28 loss:0.4755 accuracy:0.8967 precision:0.8967 recall:0.8967 f1:0.8967\n",
      "[sklearn_metrics] Epoch:29 loss:0.2308 accuracy:0.9062 precision:0.9062 recall:0.9062 f1:0.9062\n",
      "[sklearn_metrics] Epoch:29 loss:0.4737 accuracy:0.8967 precision:0.8967 recall:0.8967 f1:0.8967\n",
      "0.2896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.79      0.85        33\n",
      "           1       0.79      0.93      0.85        28\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.86      0.86      0.85        61\n",
      "weighted avg       0.86      0.85      0.85        61\n",
      "\n",
      "[[26  7]\n",
      " [ 2 26]]\n",
      "[sklearn_metrics] accuracy:0.8525 precision:0.8525 recall:0.8525 f1:0.8525\n"
     ]
    }
   ],
   "source": [
    "start=datetime.now()\n",
    "total_step = len(train_loader)\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    tot_loss = 0.0\n",
    "    tot_acc = 0.0\n",
    "    train_preds = []\n",
    "    train_trues = []\n",
    "  # model.train()\n",
    "    for i,(train_data_batch, train_label_batch) in enumerate(train_loader):\n",
    "        train_data_batch = train_data_batch.float().to(device) #from double to float\n",
    "        train_label_batch = train_label_batch.to(device)\n",
    "        outputs = model(train_data_batch)\n",
    "        # _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, train_label_batch)\n",
    "        # print(loss)\n",
    "        #backword propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # accumulate the loss of each step \n",
    "        tot_loss += loss.data\n",
    "        train_outputs = outputs.argmax(dim=1)\n",
    "        train_preds.extend(train_outputs.detach().cpu().numpy())\n",
    "        train_trues.extend(train_label_batch.detach().cpu().numpy())\n",
    "        # tot_acc += (outputs.argmax(dim=1) == train_label_batch).sum().item()\n",
    "        sklearn_accuracy = accuracy_score(train_trues, train_preds)\n",
    "        sklearn_precision = precision_score(train_trues, train_preds, average='micro')\n",
    "        sklearn_recall = recall_score(train_trues, train_preds, average='micro')\n",
    "        sklearn_f1 = f1_score(train_trues, train_preds, average='micro')\n",
    "        print(\"[sklearn_metrics] Epoch:{} loss:{:.4f} accuracy:{:.4f} precision:{:.4f} recall:{:.4f} f1:{:.4f}\".format(epoch, tot_loss, sklearn_accuracy, sklearn_precision, sklearn_recall, sklearn_f1))\n",
    "stop=datetime.now()\n",
    "execution_time_ann=(stop-start)\n",
    "training_time_ann='%.4f'%(execution_time_ann).total_seconds()\n",
    "print(training_time_ann)\n",
    "        \n",
    "test_preds = []\n",
    "test_trues = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i,(test_data_batch, test_data_label) in enumerate(test_loader):\n",
    "        test_data_batch = test_data_batch.float().to(device) #from double to float\n",
    "        test_data_label = test_data_label.to(device)\n",
    "        test_outputs = model(test_data_batch)\n",
    "        probs = F.softmax(test_outputs, dim=1) \n",
    "        test_outputs = test_outputs.argmax(dim=1)\n",
    "        testloss = criterion(probs, test_data_label)\n",
    "#         preds = torch.argmax(logits, dim=1)\n",
    "        test_preds.extend(test_outputs.detach().cpu().numpy())\n",
    "        test_trues.extend(test_data_label.detach().cpu().numpy())\n",
    "        sklearn_accuracy = accuracy_score(test_trues, test_preds)\n",
    "        sklearn_precision = precision_score(test_trues, test_preds, average='micro')\n",
    "        sklearn_recall = recall_score(test_trues, test_preds, average='micro')\n",
    "        sklearn_f1 = f1_score(test_trues, test_preds, average='micro')\n",
    "        print(classification_report(test_trues, test_preds))\n",
    "        conf_matrix = confusion_matrix(test_trues, test_preds)\n",
    "        print(conf_matrix)\n",
    "#         plot_confusion_matrix(conf_matrix)\n",
    "        print(\"[sklearn_metrics] accuracy:{:.4f} precision:{:.4f} recall:{:.4f} f1:{:.4f}\".format(sklearn_accuracy, sklearn_precision, sklearn_recall, sklearn_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08470beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2896'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time_ann"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
