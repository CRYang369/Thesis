{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d99d256",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a9cc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import sort\n",
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score  \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,roc_auc_score,accuracy_score, plot_confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import log_loss\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper,DeltaYStopper\n",
    "from skopt.space import Real,Categorical,Integer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6716dc",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9096eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>QRS duration</th>\n",
       "      <th>P-R interval</th>\n",
       "      <th>Q-T interval</th>\n",
       "      <th>T interval</th>\n",
       "      <th>P interval</th>\n",
       "      <th>QRS</th>\n",
       "      <th>...</th>\n",
       "      <th>Q wave V6</th>\n",
       "      <th>R wave V6</th>\n",
       "      <th>S wave V6</th>\n",
       "      <th>R' wave V6</th>\n",
       "      <th>S' wave V6</th>\n",
       "      <th>P wave V6</th>\n",
       "      <th>T wave V6</th>\n",
       "      <th>QRSA V6</th>\n",
       "      <th>QRSTA V6</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>52</td>\n",
       "      <td>77</td>\n",
       "      <td>129</td>\n",
       "      <td>377</td>\n",
       "      <td>133</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>54</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>376</td>\n",
       "      <td>157</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  Height  Weight  QRS duration  P-R interval  Q-T interval  \\\n",
       "0   56    1     165      64            81           174           401   \n",
       "1   54    0     172      95           138           163           386   \n",
       "2   55    0     175      94           100           202           380   \n",
       "3   40    1     160      52            77           129           377   \n",
       "4   49    1     162      54            78             0           376   \n",
       "\n",
       "   T interval  P interval  QRS  ...  Q wave V6  R wave V6  S wave V6  \\\n",
       "0         149          39   25  ...        0.0        8.5        0.0   \n",
       "1         185         102   96  ...        0.0        9.5       -2.4   \n",
       "2         179         143   28  ...        0.0       12.2       -2.2   \n",
       "3         133          77   77  ...        0.0        6.5        0.0   \n",
       "4         157          70   67  ...        0.0        8.2       -1.9   \n",
       "\n",
       "   R' wave V6  S' wave V6  P wave V6  T wave V6  QRSA V6  QRSTA V6  label  \n",
       "0         0.0         0.0        0.2        2.1     20.4      38.8      5  \n",
       "1         0.0         0.0        0.3        3.4     12.3      49.0      7  \n",
       "2         0.0         0.0        0.4        2.6     34.6      61.6      0  \n",
       "3         0.0         0.0        0.4        1.0     14.3      20.5      0  \n",
       "4         0.0         0.0        0.1        0.5     15.8      19.8      0  \n",
       "\n",
       "[5 rows x 279 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrhyData=pd.read_csv('Arrhythmia cleaned data.csv')\n",
    "arrhyData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f759182",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrhyData01=arrhyData.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ef8427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=arrhyData01.drop(labels=['label'],axis=1)\n",
    "\n",
    "y=arrhyData01['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861ca02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stanardilization\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb374ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 =PCA(n_components=None, copy=True, whiten=False)\n",
    "pcamodel1 = pca1.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cabe4903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: \n",
      "[[ 6.73351726e-02 -1.90862962e-02  1.72037300e-03 ... -9.14346524e-02\n",
      "  -8.66927095e-02 -1.30482728e-01]\n",
      " [ 5.88844957e-02  8.46249319e-03 -3.67779384e-02 ... -8.23138154e-02\n",
      "   1.85551382e-01  6.68947820e-02]\n",
      " [-1.02524819e-02 -4.55955088e-02  2.09373517e-02 ... -6.23684539e-02\n",
      "  -1.86015633e-02 -6.03188860e-02]\n",
      " ...\n",
      " [ 0.00000000e+00  1.45728434e-17  2.12146261e-16 ... -1.73472348e-17\n",
      "  -3.37403716e-16  1.79977561e-17]\n",
      " [ 0.00000000e+00 -1.74153893e-31 -3.80182235e-31 ... -4.03674916e-31\n",
      "  -8.24298016e-32  4.16963833e-31]\n",
      " [-0.00000000e+00 -1.35134848e-31 -9.38973165e-32 ... -3.29719206e-31\n",
      "  -2.08867102e-31  4.00978614e-31]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained Variance: \") \n",
    "print(pcamodel1.components_)\n",
    "\n",
    "pcamodel1.n_components_\n",
    "\n",
    "newMat1=pcamodel1.fit_transform(X) \n",
    "X_pca1 = DataFrame(newMat1)\n",
    "X31_train, X31_test,y31_train,y31_test= train_test_split(X_pca1,y,test_size=0.2,shuffle=True,stratify=y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c3c7634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM execution time is: 0:00:01.405229\n",
      "SVM execution time is: 0:00:00.111081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.98      0.79        49\n",
      "           1       1.00      0.33      0.50         9\n",
      "           2       1.00      0.67      0.80         3\n",
      "           3       0.67      0.67      0.67         3\n",
      "           4       1.00      0.00      0.00         3\n",
      "           5       1.00      0.00      0.00         5\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       0.83      0.50      0.62        10\n",
      "           8       1.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.70        88\n",
      "   macro avg       0.91      0.46      0.49        88\n",
      "weighted avg       0.78      0.70      0.64        88\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82        49\n",
      "           1       0.42      0.56      0.48         9\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       0.75      1.00      0.86         3\n",
      "           4       0.50      0.33      0.40         3\n",
      "           5       0.50      0.40      0.44         5\n",
      "           6       1.00      0.50      0.67         2\n",
      "           7       0.75      0.30      0.43        10\n",
      "           8       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.68        88\n",
      "   macro avg       0.63      0.55      0.57        88\n",
      "weighted avg       0.69      0.68      0.67        88\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.72        49\n",
      "           1       1.00      0.00      0.00         9\n",
      "           2       1.00      0.00      0.00         3\n",
      "           3       1.00      0.00      0.00         3\n",
      "           4       1.00      0.00      0.00         3\n",
      "           5       1.00      0.00      0.00         5\n",
      "           6       1.00      0.00      0.00         2\n",
      "           7       1.00      0.00      0.00        10\n",
      "           8       1.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.56        88\n",
      "   macro avg       0.95      0.11      0.08        88\n",
      "weighted avg       0.75      0.56      0.40        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_lgbm_pca=LGBMClassifier()\n",
    "\n",
    "classifier_svm_pca=SVC(kernel='rbf',gamma=0.001,decision_function_shape='ovr',C=100,degree=1,probability=True)\n",
    "classifier_rf_pca= RFC(random_state=42, max_features='log2', n_estimators= 150,\n",
    "                                     max_depth=11, \n",
    "                                     criterion='gini')\n",
    "\n",
    "start=datetime.now()\n",
    "classifier_lgbm_pca.fit(X31_train,y31_train.ravel())\n",
    "stop=datetime.now()\n",
    "execution_time_svm=stop-start\n",
    "print(\"LGBM execution time is:\",execution_time_svm)\n",
    "\n",
    "\n",
    "start=datetime.now()\n",
    "classifier_svm_pca.fit(X31_train,y31_train.ravel())\n",
    "stop=datetime.now()\n",
    "execution_time_svm=stop-start\n",
    "print(\"SVM execution time is:\",execution_time_svm)\n",
    "\n",
    "classifier_rf_pca.fit(X31_train,y31_train.ravel())\n",
    "\n",
    "#prediction on test data\n",
    "y_pred_lgbm=classifier_lgbm_pca.predict(X31_test)\n",
    "y_pred_svm=classifier_svm_pca.predict(X31_test)\n",
    "y_pred_rf=classifier_rf_pca.predict(X31_test)\n",
    "# y2_pred_svm=[list(x).index(max(x))for x in y2_pred_svm]\n",
    "\n",
    "print(classification_report(y31_test, y_pred_lgbm,zero_division=1))\n",
    "print(classification_report(y31_test, y_pred_svm,zero_division=1))\n",
    "print(classification_report(y31_test, y_pred_rf,zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7b18ef",
   "metadata": {},
   "source": [
    "## PCA----SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c333f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y, train_size = 0.8,stratify=y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c986de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "svcpca = PCA(n_components=0.7429)\n",
    "\n",
    "svcpca.fit(X_train)    \n",
    "  \n",
    "X_train_pca_svc = svcpca.transform(X_train)\n",
    "X_test_pca_svc = svcpca.transform(X_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "202a0bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_svm_pca1=SVC(random_state=42\n",
    "           ,C= 1\n",
    "           ,kernel='poly'\n",
    "           ,degree= 1\n",
    "          ,gamma=0.01\n",
    "          , probability=True)\n",
    "# SVC(kernel='rbf',gamma=0.001,decision_function_shape='ovr',C=100,degree=1,probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a0fb3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7045454545454546"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_svm_pca1.fit(X_train_pca_svc,y_train)\n",
    "y_predict_svc = classifier_svm_pca1.predict(X_test_pca_svc)\n",
    "classifier_svm_pca1.score(X_test_pca_svc, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e6d49a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0365\n"
     ]
    }
   ],
   "source": [
    "start=datetime.now()\n",
    "pca_svm_arrhthymia=classifier_svm_pca1.fit(X_train_pca_svc,y_train)\n",
    "stop=datetime.now()\n",
    "pca_training_time_svm='%.4f'%(stop-start).total_seconds()\n",
    "print(pca_training_time_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da9c50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_svm = classifier_svm_pca1.predict(X_test_pca_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e2eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_svm=classifier_svm_pca1.predict_proba(X_test_pca_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4271f6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7045\n",
      "0.7045\n",
      "0.7999\n",
      "1.0093\n"
     ]
    }
   ],
   "source": [
    "pca_svm_accuracy1='%.4f'%accuracy_score(y_test, y_predict_svm)\n",
    "pca_svm_f11='%.4f'%f1_score(y_test, y_predict_svm,average='micro')\n",
    "pca_svm_roc_auc1='%.4f'% roc_auc_score(y_test,y_prob_svm,multi_class='ovo',labels=np.unique(y_test))\n",
    "pca_svm_loss1='%.4f'%log_loss(y_test,y_prob_svm)\n",
    "print(pca_svm_accuracy1)\n",
    "print(pca_svm_f11)\n",
    "print(pca_svm_roc_auc1)\n",
    "print(pca_svm_loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "073f5108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pca_svm_arrhthymia.model']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pca_svm_arrhthymia,'pca_svm_arrhthymia.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a82fbf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7045454545454546"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfpca_svm_arrhthymia=joblib.load('pca_svm_arrhthymia.model')\n",
    "   #应用模型进行预测\n",
    "rfresultsvm=rfpca_svm_arrhthymia.score(X_test_pca_svc,y_test)\n",
    "rfresultsvm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b23e6",
   "metadata": {},
   "source": [
    "##  PCA----Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ed6da7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3576\n"
     ]
    }
   ],
   "source": [
    "clf_lgbmtest = LGBMClassifier()\n",
    "\n",
    "start=datetime.now()\n",
    "pca_lgbm_arrhthymia=clf_lgbmtest.fit(X31_train, y31_train)\n",
    "stop=datetime.now()\n",
    "pca_training_time_lgbm='%.4f'%(stop-start).total_seconds()\n",
    "print(pca_training_time_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2904b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_lgbm = clf_lgbmtest.predict(X31_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cef9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_lgbm = clf_lgbmtest.predict_proba(X31_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cd96791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7045454545454546"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lgbmtest.score(X31_test,y31_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f13781b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7045\n",
      "0.7045\n",
      "0.7685\n",
      "1.9033\n"
     ]
    }
   ],
   "source": [
    "pca_lgbm_accuracy='%.4f'%accuracy_score(y31_test, y_predict_lgbm)\n",
    "pca_lgbm_f1='%.4f'%f1_score(y31_test, y_predict_lgbm,average='micro')\n",
    "pca_lgbm_roc_auc='%.4f'% roc_auc_score(y31_test,y_prob_lgbm,multi_class='ovr',labels=np.unique(y31_test))\n",
    "pca_lgbm_loss='%.4f'%log_loss(y31_test,y_prob_lgbm)\n",
    "print(pca_lgbm_accuracy)\n",
    "print(pca_lgbm_f1)\n",
    "print(pca_lgbm_roc_auc)\n",
    "print(pca_lgbm_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41f4c65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pca_lgbm_arrhthymia.model']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pca_lgbm_arrhthymia,'pca_lgbm_arrhthymia.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1f4982c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7045454545454546"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfpca_lgbm_arrhthymia=joblib.load('pca_lgbm_arrhthymia.model')\n",
    "  \n",
    "rfresultlgbm=rfpca_lgbm_arrhthymia.score(X31_test,y31_test)\n",
    "rfresultlgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1fa626",
   "metadata": {},
   "source": [
    "##  PCA----RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "658b06bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpca = PCA(n_components=0.4786)\n",
    "\n",
    "rfpca.fit(X_train)    \n",
    "  \n",
    "X_train_pca_rf = rfpca.transform(X_train)\n",
    "X_test_pca_rf = rfpca.transform(X_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "877b3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf_pca1=SVC(kernel='rbf',gamma=0.001,decision_function_shape='ovr',C=100,degree=1,probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef0d5673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6704545454545454"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_rf_pca1.fit(X_train_pca_rf,y_train)\n",
    "y_predict_rf = classifier_rf_pca1.predict(X_test_pca_rf)\n",
    "classifier_rf_pca1.score(X_test_pca_rf, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09ac4f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0582\n"
     ]
    }
   ],
   "source": [
    "start=datetime.now()\n",
    "pca_rf_arrhthymia=classifier_rf_pca1.fit(X_train_pca_rf,y_train)\n",
    "stop=datetime.now()\n",
    "pca_training_time_rf='%.4f'%(stop-start).total_seconds()\n",
    "print(pca_training_time_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "729f1904",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf_pca1.score(X_test_pca_rf,y_test)\n",
    "y_predict_rf=classifier_rf_pca1.predict(X_test_pca_rf)\n",
    "y_prob_rf=classifier_rf_pca1.predict_proba(X_test_pca_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5325d684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6705\n",
      "0.6705\n",
      "0.8243\n",
      "1.0626\n"
     ]
    }
   ],
   "source": [
    "pca_rf_accuracy1='%.4f'%accuracy_score(y_test, y_predict_rf)\n",
    "pca_rf_f11='%.4f'%f1_score(y_test, y_predict_rf,average='micro')\n",
    "pca_rf_roc_auc1='%.4f'% roc_auc_score(y_test,y_prob_rf,multi_class='ovr',labels=np.unique(y31_test))\n",
    "pca_rf_loss1='%.4f'%log_loss(y_test,y_prob_rf)\n",
    "print(pca_rf_accuracy1)\n",
    "print(pca_rf_f11)\n",
    "print(pca_rf_roc_auc1)\n",
    "print(pca_rf_loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8313874d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pca_rf_arrhthymia.model']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pca_rf_arrhthymia,'pca_rf_arrhthymia.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c585030",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpca_rf_arrhthymia=joblib.load('pca_rf_arrhthymia.model')\n",
    "   #应用模型进行预测\n",
    "rfresultrf=rfpca_rf_arrhthymia.score(X_test_pca_rf,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4407e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6704545454545454"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfresultrf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9382cd9",
   "metadata": {},
   "source": [
    "## PCA--ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdf2cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X31_train.values)\n",
    "y_train = torch.from_numpy(y31_train ).type(torch.LongTensor)\n",
    "\n",
    "X_test  = torch.from_numpy(X31_test.values )\n",
    "y_test= torch.from_numpy(y31_test).type(torch.LongTensor)\n",
    "\n",
    "batch_size = 128\n",
    "train = torch.utils.data.TensorDataset(X_train, y_train )\n",
    "test = torch.utils.data.TensorDataset(X_test , y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46db6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1,hidden_dim2, output_dim):\n",
    "        super(ANNModel, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.relu1 = nn.ReLU() \n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75dd0df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =30\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = X_pca1.shape[1]\n",
    "hidden_dim1 = 55 #hidden layer1\n",
    "hidden_dim2 = 123 #hidden layer2 \n",
    "output_dim = len(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26910e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANNModel(input_dim, hidden_dim1,hidden_dim2,output_dim)\n",
    "\n",
    "\n",
    "learning_rate = 0.0067\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "33a7eacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn_metrics] Epoch:0 loss:2.1876 accuracy:0.1094 precision:0.1094 recall:0.1094 f1:0.1094\n",
      "[sklearn_metrics] Epoch:0 loss:4.2202 accuracy:0.3359 precision:0.3359 recall:0.3359 f1:0.3359\n",
      "[sklearn_metrics] Epoch:0 loss:6.0919 accuracy:0.4000 precision:0.4000 recall:0.4000 f1:0.4000\n",
      "[sklearn_metrics] Epoch:1 loss:1.6533 accuracy:0.5547 precision:0.5547 recall:0.5547 f1:0.5547\n",
      "[sklearn_metrics] Epoch:1 loss:3.2069 accuracy:0.5547 precision:0.5547 recall:0.5547 f1:0.5547\n",
      "[sklearn_metrics] Epoch:1 loss:4.6045 accuracy:0.5600 precision:0.5600 recall:0.5600 f1:0.5600\n",
      "[sklearn_metrics] Epoch:2 loss:1.2928 accuracy:0.5469 precision:0.5469 recall:0.5469 f1:0.5469\n",
      "[sklearn_metrics] Epoch:2 loss:2.3889 accuracy:0.5547 precision:0.5547 recall:0.5547 f1:0.5547\n",
      "[sklearn_metrics] Epoch:2 loss:3.5661 accuracy:0.5629 precision:0.5629 recall:0.5629 f1:0.5629\n",
      "[sklearn_metrics] Epoch:3 loss:0.9881 accuracy:0.6953 precision:0.6953 recall:0.6953 f1:0.6953\n",
      "[sklearn_metrics] Epoch:3 loss:1.8659 accuracy:0.7031 precision:0.7031 recall:0.7031 f1:0.7031\n",
      "[sklearn_metrics] Epoch:3 loss:2.6147 accuracy:0.7200 precision:0.7200 recall:0.7200 f1:0.7200\n",
      "[sklearn_metrics] Epoch:4 loss:0.7630 accuracy:0.7500 precision:0.7500 recall:0.7500 f1:0.7500\n",
      "[sklearn_metrics] Epoch:4 loss:1.4400 accuracy:0.7695 precision:0.7695 recall:0.7695 f1:0.7695\n",
      "[sklearn_metrics] Epoch:4 loss:1.9751 accuracy:0.7857 precision:0.7857 recall:0.7857 f1:0.7857\n",
      "[sklearn_metrics] Epoch:5 loss:0.5052 accuracy:0.8359 precision:0.8359 recall:0.8359 f1:0.8359\n",
      "[sklearn_metrics] Epoch:5 loss:1.0033 accuracy:0.8438 precision:0.8438 recall:0.8438 f1:0.8438\n",
      "[sklearn_metrics] Epoch:5 loss:1.4748 accuracy:0.8486 precision:0.8486 recall:0.8486 f1:0.8486\n",
      "[sklearn_metrics] Epoch:6 loss:0.3375 accuracy:0.8906 precision:0.8906 recall:0.8906 f1:0.8906\n",
      "[sklearn_metrics] Epoch:6 loss:0.7655 accuracy:0.8867 precision:0.8867 recall:0.8867 f1:0.8867\n",
      "[sklearn_metrics] Epoch:6 loss:1.0228 accuracy:0.9029 precision:0.9029 recall:0.9029 f1:0.9029\n",
      "[sklearn_metrics] Epoch:7 loss:0.2741 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:7 loss:0.5028 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:7 loss:0.6672 accuracy:0.9400 precision:0.9400 recall:0.9400 f1:0.9400\n",
      "[sklearn_metrics] Epoch:8 loss:0.1296 accuracy:0.9766 precision:0.9766 recall:0.9766 f1:0.9766\n",
      "[sklearn_metrics] Epoch:8 loss:0.2831 accuracy:0.9688 precision:0.9688 recall:0.9688 f1:0.9688\n",
      "[sklearn_metrics] Epoch:8 loss:0.4129 accuracy:0.9657 precision:0.9657 recall:0.9657 f1:0.9657\n",
      "[sklearn_metrics] Epoch:9 loss:0.0883 accuracy:0.9844 precision:0.9844 recall:0.9844 f1:0.9844\n",
      "[sklearn_metrics] Epoch:9 loss:0.1653 accuracy:0.9844 precision:0.9844 recall:0.9844 f1:0.9844\n",
      "[sklearn_metrics] Epoch:9 loss:0.2335 accuracy:0.9829 precision:0.9829 recall:0.9829 f1:0.9829\n",
      "[sklearn_metrics] Epoch:10 loss:0.0422 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:10 loss:0.0759 accuracy:0.9961 precision:0.9961 recall:0.9961 f1:0.9961\n",
      "[sklearn_metrics] Epoch:10 loss:0.1097 accuracy:0.9971 precision:0.9971 recall:0.9971 f1:0.9971\n",
      "[sklearn_metrics] Epoch:11 loss:0.0155 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:11 loss:0.0416 accuracy:0.9961 precision:0.9961 recall:0.9961 f1:0.9961\n",
      "[sklearn_metrics] Epoch:11 loss:0.0523 accuracy:0.9971 precision:0.9971 recall:0.9971 f1:0.9971\n",
      "[sklearn_metrics] Epoch:12 loss:0.0088 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:12 loss:0.0134 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:12 loss:0.0308 accuracy:0.9971 precision:0.9971 recall:0.9971 f1:0.9971\n",
      "[sklearn_metrics] Epoch:13 loss:0.0043 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:13 loss:0.0076 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:13 loss:0.0170 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:14 loss:0.0020 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:14 loss:0.0042 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:14 loss:0.0087 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:15 loss:0.0032 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:15 loss:0.0043 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:15 loss:0.0052 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:16 loss:0.0008 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:16 loss:0.0016 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:16 loss:0.0027 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:17 loss:0.0006 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:17 loss:0.0014 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:17 loss:0.0018 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:18 loss:0.0004 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:18 loss:0.0010 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:18 loss:0.0013 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:19 loss:0.0003 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:19 loss:0.0008 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:19 loss:0.0010 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:20 loss:0.0003 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:20 loss:0.0007 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:20 loss:0.0008 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:21 loss:0.0003 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:21 loss:0.0005 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:21 loss:0.0007 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:22 loss:0.0002 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:22 loss:0.0004 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:22 loss:0.0006 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:23 loss:0.0001 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:23 loss:0.0003 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:23 loss:0.0005 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:24 loss:0.0002 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:24 loss:0.0003 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:24 loss:0.0005 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:25 loss:0.0002 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:25 loss:0.0003 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:25 loss:0.0005 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:26 loss:0.0002 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:26 loss:0.0003 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:26 loss:0.0004 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:27 loss:0.0001 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:27 loss:0.0003 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:27 loss:0.0004 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:28 loss:0.0001 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:28 loss:0.0003 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:28 loss:0.0004 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:29 loss:0.0001 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:29 loss:0.0002 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:29 loss:0.0004 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "0.5180\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83        49\n",
      "           1       0.55      0.67      0.60         9\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       0.67      0.67      0.67         3\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.67      0.40      0.50         5\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       0.75      0.60      0.67        10\n",
      "           8       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        88\n",
      "   macro avg       0.60      0.58      0.58        88\n",
      "weighted avg       0.69      0.73      0.71        88\n",
      "\n",
      "[[43  2  0  1  1  1  0  1  0]\n",
      " [ 3  6  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  1  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  2  0  0  1]\n",
      " [ 0  0  0  0  0  0  2  0  0]\n",
      " [ 2  2  0  0  0  0  0  6  0]\n",
      " [ 2  1  0  0  0  0  0  1  0]]\n",
      "[sklearn_metrics] accuracy:0.7273 precision:0.7273 recall:0.7273 f1:0.7273\n"
     ]
    }
   ],
   "source": [
    "start=datetime.now()\n",
    "total_step = len(train_loader)\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    tot_loss = 0.0\n",
    "    tot_acc = 0.0\n",
    "    train_preds = []\n",
    "    train_trues = []\n",
    "  # model.train()\n",
    "    for i,(train_data_batch, train_label_batch) in enumerate(train_loader):\n",
    "        train_data_batch = train_data_batch.float().to(device) # 将double数据转换为float\n",
    "        train_label_batch = train_label_batch.to(device)\n",
    "        outputs = model(train_data_batch)\n",
    "        # _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, train_label_batch)\n",
    "        # print(loss)\n",
    "       \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "   \n",
    "        tot_loss += loss.data\n",
    "        train_outputs = outputs.argmax(dim=1)\n",
    "        train_preds.extend(train_outputs.detach().cpu().numpy())\n",
    "        train_trues.extend(train_label_batch.detach().cpu().numpy())\n",
    "        # tot_acc += (outputs.argmax(dim=1) == train_label_batch).sum().item()\n",
    "        sklearn_accuracy = accuracy_score(train_trues, train_preds)\n",
    "        sklearn_precision = precision_score(train_trues, train_preds, average='micro')\n",
    "        sklearn_recall = recall_score(train_trues, train_preds, average='micro')\n",
    "        sklearn_f1 = f1_score(train_trues, train_preds, average='micro')\n",
    "        print(\"[sklearn_metrics] Epoch:{} loss:{:.4f} accuracy:{:.4f} precision:{:.4f} recall:{:.4f} f1:{:.4f}\".format(epoch, tot_loss, sklearn_accuracy, sklearn_precision, sklearn_recall, sklearn_f1))\n",
    "stop=datetime.now()\n",
    "execution_time_ann=(stop-start)\n",
    "pca_training_time_ann='%.4f'%(execution_time_ann).total_seconds()\n",
    "print(pca_training_time_ann)\n",
    "        \n",
    "test_preds = []\n",
    "test_trues = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i,(test_data_batch, test_data_label) in enumerate(test_loader):\n",
    "        test_data_batch = test_data_batch.float().to(device) # 将double数据转换为float\n",
    "        test_data_label = test_data_label.to(device)\n",
    "        test_outputs = model(test_data_batch)\n",
    "        probs = F.softmax(test_outputs, dim=1) \n",
    "        test_outputs = test_outputs.argmax(dim=1)\n",
    "        testloss = criterion(probs, test_data_label)\n",
    "#         preds = torch.argmax(logits, dim=1)\n",
    "        test_preds.extend(test_outputs.detach().cpu().numpy())\n",
    "        test_trues.extend(test_data_label.detach().cpu().numpy())\n",
    "        sklearn_accuracy = accuracy_score(test_trues, test_preds)\n",
    "        sklearn_precision = precision_score(test_trues, test_preds, average='micro')\n",
    "        sklearn_recall = recall_score(test_trues, test_preds, average='micro')\n",
    "        sklearn_f1 = f1_score(test_trues, test_preds, average='micro')\n",
    "        print(classification_report(test_trues, test_preds))\n",
    "        conf_matrix = confusion_matrix(test_trues, test_preds)\n",
    "        print(conf_matrix)\n",
    "#         plot_confusion_matrix(conf_matrix)\n",
    "        print(\"[sklearn_metrics] accuracy:{:.4f} precision:{:.4f} recall:{:.4f} f1:{:.4f}\".format(sklearn_accuracy, sklearn_precision, sklearn_recall, sklearn_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0630dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_ann_loss='%.4f'% testloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed6ab31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_ann_f1='%.4f'% f1_score(test_trues, test_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61f5865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_ann_accuracy='%.4f'% accuracy_score(test_trues, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "301bd229",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_ann_roc_auc='%.4f'% roc_auc_score(test_data_label,probs,multi_class='ovr',labels=np.unique(test_data_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f75c06f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>cross_entropy_loss</th>\n",
       "      <th>training_time[s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Light GBM</th>\n",
       "      <td>0.7045</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>0.7685</td>\n",
       "      <td>1.9033</td>\n",
       "      <td>1.3576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.7045</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>0.7999</td>\n",
       "      <td>1.0093</td>\n",
       "      <td>0.0365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>1.0626</td>\n",
       "      <td>0.0582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PyTorch ANN</th>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.8239</td>\n",
       "      <td>1.6606</td>\n",
       "      <td>0.5180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy f1_score roc_auc cross_entropy_loss training_time[s]\n",
       "Light GBM       0.7045   0.7045  0.7685             1.9033           1.3576\n",
       "SVM             0.7045   0.7045  0.7999             1.0093           0.0365\n",
       "Random Forest   0.6705   0.6705  0.8243             1.0626           0.0582\n",
       "PyTorch ANN     0.7273   0.7273  0.8239             1.6606           0.5180"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_dict = { \n",
    "              'accuracy':[pca_lgbm_accuracy\n",
    "                          ,pca_svm_accuracy1,pca_rf_accuracy1,pca_ann_accuracy],\n",
    "               'f1_score': [pca_lgbm_f1\n",
    "                            ,pca_svm_f11,pca_rf_f11,pca_ann_f1],\n",
    "               'roc_auc': [pca_lgbm_roc_auc\n",
    "                           ,pca_svm_roc_auc1,pca_rf_roc_auc1,pca_ann_roc_auc],\n",
    "               'cross_entropy_loss': [pca_lgbm_loss\n",
    "                                      ,pca_svm_loss1,pca_rf_loss1,pca_ann_loss],\n",
    "                'training_time[s]':[pca_training_time_lgbm\n",
    "                                    ,pca_training_time_svm,pca_training_time_rf,pca_training_time_ann]\n",
    "               }\n",
    "pr_df_pca = pd.DataFrame(PCA_dict,index=['Light GBM','SVM','Random Forest','PyTorch ANN'])\n",
    "pr_df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f76c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_df_pca.to_csv('Arrhthymia PCA Score.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
