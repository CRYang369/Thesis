{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec95d66f",
   "metadata": {},
   "source": [
    "# Import the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a9cc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score  \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,roc_auc_score,accuracy_score, plot_confusion_matrix,classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12583cbc",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8c97c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>QRS duration</th>\n",
       "      <th>Q-T interval</th>\n",
       "      <th>Heart rate</th>\n",
       "      <th>Q wavechannel   DIIII</th>\n",
       "      <th>R wavechannel   DIIII</th>\n",
       "      <th>Number of intrinsic deflectionschannel   V1</th>\n",
       "      <th>Q wavechannel   V3</th>\n",
       "      <th>T wave</th>\n",
       "      <th>P wave DII</th>\n",
       "      <th>...</th>\n",
       "      <th>S wave V3</th>\n",
       "      <th>QRSTA V3</th>\n",
       "      <th>R wave V4</th>\n",
       "      <th>T wave V4</th>\n",
       "      <th>QRSTA V4</th>\n",
       "      <th>JJ wave V5</th>\n",
       "      <th>T wave V5</th>\n",
       "      <th>QRSTA V5</th>\n",
       "      <th>T wave V6</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>401</td>\n",
       "      <td>53</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.7</td>\n",
       "      <td>27.7</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>43.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>386</td>\n",
       "      <td>75</td>\n",
       "      <td>28</td>\n",
       "      <td>116</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>23.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>20.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>48.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>380</td>\n",
       "      <td>71</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>51.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>63.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>77</td>\n",
       "      <td>377</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>78</td>\n",
       "      <td>376</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>14.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight  QRS duration  Q-T interval  Heart rate  Q wavechannel   DIIII   \\\n",
       "0      64            81           401          53                      32   \n",
       "1      95           138           386          75                      28   \n",
       "2      94           100           380          71                      20   \n",
       "3      52            77           377          70                       0   \n",
       "4      54            78           376          67                       0   \n",
       "\n",
       "   R wavechannel   DIIII   Number of intrinsic deflectionschannel   V1  \\\n",
       "0                      24                                           16   \n",
       "1                     116                                          100   \n",
       "2                      52                                            0   \n",
       "3                      44                                           12   \n",
       "4                      56                                            8   \n",
       "\n",
       "   Q wavechannel   V3  T wave  P wave DII  ...  S wave V3  QRSTA V3  \\\n",
       "0                   0     1.5         0.1  ...       -7.7      27.7   \n",
       "1                   0     2.5         0.7  ...       -4.1      23.3   \n",
       "2                   0     1.9         0.4  ...       -7.9      51.0   \n",
       "3                   0     1.0         0.5  ...      -11.0      21.2   \n",
       "4                   0     1.0         0.6  ...       -9.0      21.1   \n",
       "\n",
       "   R wave V4  T wave V4  QRSTA V4  JJ wave V5  T wave V5  QRSTA V5  T wave V6  \\\n",
       "0        9.5        2.6      34.6        -0.4        2.6      43.4        2.1   \n",
       "1       10.0        2.2      20.7         1.3        3.4      48.2        3.4   \n",
       "2       15.0        3.3      63.1         0.1        3.0      68.0        2.6   \n",
       "3        7.7        1.9      15.4         0.0        1.3      18.9        1.0   \n",
       "4        6.6        1.4      14.2        -0.2        0.8      20.9        0.5   \n",
       "\n",
       "   label  \n",
       "0      5  \n",
       "1      7  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrhyData=pd.read_csv('Arrhthymia selected 28 features.csv')\n",
    "arrhyData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0db571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAARhElEQVR4nO3df6zddX3H8edLij9AnRCurLZgmWFEcA70hjlJ/MWm6FTQgCmZjjgXTAZONrNFNJlsSxeXic44NUFB6kRYBZm4GJWh0+kysUUUSmV2glCptP7YQLOhxff+ON/74QC35Vj6Pd/T3ucjuTnnfM73e7+vNLf3db+/PidVhSRJAI8YOoAkaXZYCpKkxlKQJDWWgiSpsRQkSc2yoQM8HIccckitWrVq6BiStFfZsGHD96tqbrH39upSWLVqFevXrx86hiTtVZJ8Z2fvefhIktT0VgpJDkvy+SSbkmxM8sZu/Lwk301yfff1krF1zk2yOcnNSV7UVzZJ0uL6PHy0A3hTVV2X5HHAhiRXd++9q6reMb5wkqOB1cAxwJOAf0nyq1V1b48ZJUljettTqKqtVXVd9/xuYBOwYhernAxcVlX3VNUtwGbg+L7ySZIebCrnFJKsAo4DvtINnZ3kG0kuSnJQN7YCuH1stS0sUiJJzkyyPsn67du39xlbkpac3kshyWOBK4Bzquou4P3AU4Bjga3A+QuLLrL6g2brq6oLqmq+qubn5ha9okqStJt6LYUk+zMqhEuq6uMAVXVnVd1bVT8HPsB9h4i2AIeNrb4SuKPPfJKk++vz6qMAFwKbquqdY+PLxxZ7BXBj9/wqYHWSRyU5AjgSuLavfJKkB+vz6qMTgNcANyS5vht7C3B6kmMZHRq6FXg9QFVtTLIOuInRlUtneeWRJE1Xb6VQVV9i8fMEn9rFOmuANbu7zWf+6Yd3d9WHZcPf/t4g25WkPc07miVJjaUgSWosBUlSYylIkhpLQZLUWAqSpMZSkCQ1loIkqbEUJEmNpSBJaiwFSVJjKUiSGktBktRYCpKkxlKQJDWWgiSpsRQkSY2lIElqLAVJUmMpSJIaS0GS1FgKkqTGUpAkNZaCJKmxFCRJjaUgSWosBUlSYylIkhpLQZLUWAqSpMZSkCQ1loIkqbEUJEmNpSBJanorhSSHJfl8kk1JNiZ5Yzd+cJKrk3yrezxobJ1zk2xOcnOSF/WVTZK0uD73FHYAb6qqpwLPAs5KcjTwZuCaqjoSuKZ7TffeauAY4CTgfUn26zGfJOkBeiuFqtpaVdd1z+8GNgErgJOBtd1ia4FTuucnA5dV1T1VdQuwGTi+r3ySpAebyjmFJKuA44CvAIdW1VYYFQfwxG6xFcDtY6tt6cYe+L3OTLI+yfrt27f3mluSlpreSyHJY4ErgHOq6q5dLbrIWD1ooOqCqpqvqvm5ubk9FVOSRM+lkGR/RoVwSVV9vBu+M8ny7v3lwLZufAtw2NjqK4E7+swnSbq/Pq8+CnAhsKmq3jn21lXAGd3zM4BPjI2vTvKoJEcARwLX9pVPkvRgy3r83icArwFuSHJ9N/YW4O3AuiSvA24DTgOoqo1J1gE3Mbpy6ayqurfHfJKkB+itFKrqSyx+ngDgxJ2sswZY01cmSdKueUezJKmxFCRJjaUgSWosBUlSYylIkhpLQZLUWAqSpMZSkCQ1loIkqbEUJEmNpSBJaiwFSVJjKUiSGktBktRYCpKkxlKQJDWWgiSpsRQkSY2lIElqLAVJUmMpSJIaS0GS1FgKkqTGUpAkNZaCJKmxFCRJjaUgSWosBUlSYylIkhpLQZLUWAqSpMZSkCQ1loIkqemtFJJclGRbkhvHxs5L8t0k13dfLxl779wkm5PcnORFfeWSJO1cn3sKFwMnLTL+rqo6tvv6FECSo4HVwDHdOu9Lsl+P2SRJi+itFKrqi8APJ1z8ZOCyqrqnqm4BNgPH95VNkrS4Ic4pnJ3kG93hpYO6sRXA7WPLbOnGHiTJmUnWJ1m/ffv2vrNK0pIy7VJ4P/AU4FhgK3B+N55Flq3FvkFVXVBV81U1Pzc310tISVqqploKVXVnVd1bVT8HPsB9h4i2AIeNLboSuGOa2SRJUy6FJMvHXr4CWLgy6SpgdZJHJTkCOBK4dprZJEmwrK9vnORS4HnAIUm2AG8DnpfkWEaHhm4FXg9QVRuTrANuAnYAZ1XVvX1lkyQtrrdSqKrTFxm+cBfLrwHW9JVHkvTQvKNZktRMVApJrplkTJK0d9vl4aMkjwYOYHRe4CDuu3T08cCTes4mSZqyhzqn8HrgHEYFsIH7SuEu4L39xZIkDWGXpVBV7wbeneQNVfWeKWWSJA1koquPquo9SZ4NrBpfp6o+3FMuSdIAJiqFJP/AaHqK64GF+wcKsBQkaR8y6X0K88DRVbXofESSpH3DpPcp3Aj8cp9BJEnDm3RP4RDgpiTXAvcsDFbVy3tJJUkaxKSlcF6fISRJs2HSq4++0HcQSdLwJr366G7u+9CbRwL7Az+pqsf3FUySNH2T7ik8bvx1klPwM5QlaZ+zW7OkVtU/AS/Ys1EkSUOb9PDRK8dePoLRfQvesyBJ+5hJrz562djzHYw+Ne3kPZ5GkjSoSc8pvLbvIJKk4U36ITsrk1yZZFuSO5NckWRl3+EkSdM16YnmDwFXMfpchRXAJ7sxSdI+ZNJSmKuqD1XVju7rYmCux1ySpAFMWgrfT/LqJPt1X68GftBnMEnS9E1aCr8PvAr4HrAVOBXw5LMk7WMmvST1r4AzqupHAEkOBt7BqCwkSfuISfcUnr5QCABV9UPguH4iSZKGMmkpPCLJQQsvuj2FSfcyJEl7iUl/sZ8P/HuSyxlNb/EqYE1vqSRJg5j0juYPJ1nPaBK8AK+sqpt6TSZJmrqJDwF1JWARSNI+bLemzpYk7ZssBUlSYylIkhpLQZLU9FYKSS7qptq+cWzs4CRXJ/lW9zh+78O5STYnuTnJi/rKJUnauT73FC4GTnrA2JuBa6rqSOCa7jVJjgZWA8d067wvyX49ZpMkLaK3UqiqLwI/fMDwycDa7vla4JSx8cuq6p6qugXYDBzfVzZJ0uKmfU7h0KraCtA9PrEbXwHcPrbclm7sQZKcmWR9kvXbt2/vNawkLTWzcqI5i4zVYgtW1QVVNV9V83Nzfs6PJO1J0y6FO5MsB+get3XjW4DDxpZbCdwx5WyStORNuxSuAs7onp8BfGJsfHWSRyU5AjgSuHbK2SRpyett+usklwLPAw5JsgV4G/B2YF2S1wG3AacBVNXGJOsYza20Azirqu7tK5skaXG9lUJVnb6Tt07cyfJrcDpuSRrUrJxoliTNAEtBktRYCpKkxlKQJDWWgiSpsRQkSY2lIElqLAVJUmMpSJIaS0GS1FgKkqTGUpAkNZaCJKmxFCRJjaUgSWosBUlSYylIkhpLQZLUWAqSpMZSkCQ1loIkqbEUJEmNpSBJaiwFSVJjKUiSGktBktRYCpKkxlKQJDWWgiSpsRQkSY2lIElqLAVJUmMpSJKaZUNsNMmtwN3AvcCOqppPcjDwj8Aq4FbgVVX1oyHySdJSNeSewvOr6tiqmu9evxm4pqqOBK7pXkuSpmiWDh+dDKztnq8FThkuiiQtTUOVQgGfTbIhyZnd2KFVtRWge3ziQNkkacka5JwCcEJV3ZHkicDVSb456YpdiZwJcPjhh/eVT9Je7rzzzltS291TBtlTqKo7usdtwJXA8cCdSZYDdI/bdrLuBVU1X1Xzc3Nz04osSUvC1EshyYFJHrfwHHghcCNwFXBGt9gZwCemnU2SlrohDh8dClyZZGH7H62qTyf5KrAuyeuA24DTBsgmSUva1Euhqr4N/Poi4z8ATpx2HknSfYY60bxk3PaXvzbIdg//8xsG2a6kvdss3acgSRqYpSBJaiwFSVJjKUiSGktBktRYCpKkxlKQJDWWgiSpsRQkSY2lIElqLAVJUmMpSJIaS0GS1FgKkqTGUpAkNX6egrSXWfPqUwfZ7ls/cvkg29V0uacgSWrcU5CkKVr3seOnvs1XnXbtxMu6pyBJaiwFSVJjKUiSGktBktRYCpKkxquPlqAT3nPCINv98hu+vMv3v/Cc504pyX2e+8UvTH2b0ixzT0GS1LinIO3C37/pk4Ns9+zzXzbIdiX3FCRJjaUgSWo8fCTpYdu05nODbPepb33BINvdl7mnIElqLAVJUmMpSJIaS0GS1MxcKSQ5KcnNSTYnefPQeSRpKZmpUkiyH/Be4MXA0cDpSY4eNpUkLR0zVQrA8cDmqvp2Vf0UuAw4eeBMkrRkpKqGztAkORU4qar+oHv9GuA3qurssWXOBM7sXh4F3LyHNn8I8P099L32FDNNbhZzmWkyZprcnsr15KqaW+yNWbt5LYuM3a+1quoC4II9vuFkfVXN7+nv+3CYaXKzmMtMkzHT5KaRa9YOH20BDht7vRK4Y6AskrTkzFopfBU4MskRSR4JrAauGjiTJC0ZM3X4qKp2JDkb+AywH3BRVW2c0ub3+CGpPcBMk5vFXGaajJkm13uumTrRLEka1qwdPpIkDchSkCQ1S74UZnFajSQXJdmW5MahsyxIcliSzyfZlGRjkjfOQKZHJ7k2yde7TH8xdKYFSfZL8rUk/zx0lgVJbk1yQ5Lrk6wfOg9AkickuTzJN7ufrd8cOM9R3b/PwtddSc4ZMlOX64+7n/Ebk1ya5NG9bWspn1PoptX4T+C3GV0O+1Xg9Kq6aeBczwF+DHy4qp42ZJYFSZYDy6vquiSPAzYApwz5b5UkwIFV9eMk+wNfAt5YVf8xVKYFSf4EmAceX1UvHToPjEoBmK+qmbkpK8la4N+q6oPdFYcHVNV/DxwLaL8fvsvoBtrvDJhjBaOf7aOr6n+TrAM+VVUX97G9pb6nMJPTalTVF4EfDp1jXFVtrarruud3A5uAFQNnqqr6cfdy/+5r8L9ykqwEfgf44NBZZlmSxwPPAS4EqKqfzkohdE4E/mvIQhizDHhMkmXAAfR4/9ZSL4UVwO1jr7cw8C+6vUGSVcBxwFcGjrJwmOZ6YBtwdVUNngn4O+DPgJ8PnOOBCvhskg3ddDFD+xVgO/Ch7lDbB5McOHSoMauBS4cOUVXfBd4B3AZsBf6nqj7b1/aWeik85LQaur8kjwWuAM6pqruGzlNV91bVsYzufj8+yaCH25K8FNhWVRuGzLETJ1TVMxjNQnxWd5hySMuAZwDvr6rjgJ8As3Je75HAy4GPzUCWgxgdwTgCeBJwYJJX97W9pV4KTqvxC+iO218BXFJVHx86z7jusMO/AicNm4QTgJd3x+8vA16Q5CPDRhqpqju6x23AlYwOnw5pC7BlbO/uckYlMQteDFxXVXcOHQT4LeCWqtpeVT8DPg48u6+NLfVScFqNCXUndS8ENlXVO4fOA5BkLskTuuePYfSf55tDZqqqc6tqZVWtYvTz9Lmq6u2vukklObC7QIDuEM0LgUGvbquq7wG3JzmqGzoRGPQijzGnMwOHjjq3Ac9KckD3//BERuf0ejFT01xM28DTauxUkkuB5wGHJNkCvK2qLhw2FScArwFu6I7hA7ylqj41XCSWA2u7q0QeAayrqpm5BHTGHApcOfqdwjLgo1X16WEjAfAG4JLuj7JvA68dOA9JDmB0ReLrh84CUFVfSXI5cB2wA/gaPU53saQvSZUk3d9SP3wkSRpjKUiSGktBktRYCpKkxlKQJDWWgvQLSPLjh3h/1S86u22Si5Oc+vCSSXuGpSBJaiwFaTckeWySa5Jc131GwfjsusuSrE3yje6zAg7o1nlmki90E9J9ppuOXJoploK0e/4PeEU3wdzzgfO7KQgAjgIuqKqnA3cBf9jNG/Ue4NSqeiZwEbBmgNzSLi3paS6khyHAX3czjf6c0ZTrh3bv3V5VX+6efwT4I+DTwNOAq7vu2I/RNMjSTLEUpN3zu8Ac8Myq+lk3K+rCRyQ+cO6YYlQiG6tq0I+blB6Kh4+k3fNLjD434WdJng88eey9w8c+a/h0Rh+leDMwtzCeZP8kx0w1sTQBS0HaPZcA80nWM9prGJ+yexNwRpJvAAcz+hCZnwKnAn+T5OvA9fQ4J760u5wlVZLUuKcgSWosBUlSYylIkhpLQZLUWAqSpMZSkCQ1loIkqfl/n6GmiP6Y6A8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='label',data=arrhyData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee8cd2",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b09ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438, 29)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrhyData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d5b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrhyData01=arrhyData.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0164e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=arrhyData01.drop(labels=['label'],axis=1)\n",
    "\n",
    "y1=arrhyData01['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed2ad0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stanardilization\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X1)\n",
    "X1=scaler.transform(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe46089",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c359dfcf",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a45779f",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape : (350, 28)\n",
      "X_test.shape : (88, 28)\n"
     ]
    }
   ],
   "source": [
    "#split train dataset and test dataset\n",
    "X1_train, X1_test,y1_train,y1_test= train_test_split(X1,y1,test_size=0.2, shuffle = True,stratify=y1,random_state=42)\n",
    "print(\"X_train.shape :\",X1_train.shape)\n",
    "print(\"X_test.shape :\",X1_test.shape)\n",
    "# print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e17518",
   "metadata": {},
   "source": [
    "Define the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12db8e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X1_train = torch.from_numpy(X1_train)\n",
    "y1_train = torch.from_numpy(y1_train ).type(torch.LongTensor)\n",
    "\n",
    "X1_test  = torch.from_numpy(X1_test )\n",
    "y1_test= torch.from_numpy(y1_test).type(torch.LongTensor)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train = torch.utils.data.TensorDataset(X1_train, y1_train )\n",
    "test = torch.utils.data.TensorDataset(X1_test , y1_test)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a2d920",
   "metadata": {},
   "source": [
    "Define the Optuna  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e43e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-09 13:37:46,619]\u001b[0m A new study created in memory with name: no-name-3d468bb0-9d93-46c3-9f4b-e902e2f6a14c\u001b[0m\n",
      "C:\\Users\\COOLER~1\\AppData\\Local\\Temp/ipykernel_16504/3823230556.py:96: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2022-09-09 13:37:46,787]\u001b[0m Trial 0 finished with value: 0.7954545454545454 and parameters: {'learning_rate': 0.01850375101853908, 'optimizer': 'RMSprop', 'n_layers': 1, 'n_units_l0': 54}. Best is trial 0 with value: 0.7954545454545454.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:46,984]\u001b[0m Trial 1 finished with value: 0.7840909090909091 and parameters: {'learning_rate': 0.011549802270898298, 'optimizer': 'Adam', 'n_layers': 2, 'n_units_l0': 44, 'n_units_l1': 22}. Best is trial 0 with value: 0.7954545454545454.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:47,213]\u001b[0m Trial 2 finished with value: 0.5909090909090909 and parameters: {'learning_rate': 0.06222577416794749, 'optimizer': 'RMSprop', 'n_layers': 3, 'n_units_l0': 106, 'n_units_l1': 40, 'n_units_l2': 91}. Best is trial 0 with value: 0.7954545454545454.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:47,392]\u001b[0m Trial 3 finished with value: 0.7045454545454546 and parameters: {'learning_rate': 0.046421188969744176, 'optimizer': 'RMSprop', 'n_layers': 1, 'n_units_l0': 109}. Best is trial 0 with value: 0.7954545454545454.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:47,586]\u001b[0m Trial 4 finished with value: 0.06818181818181818 and parameters: {'learning_rate': 0.0004805959846274438, 'optimizer': 'SGD', 'n_layers': 2, 'n_units_l0': 77, 'n_units_l1': 97}. Best is trial 0 with value: 0.7954545454545454.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:47,598]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:47,783]\u001b[0m Trial 6 finished with value: 0.7159090909090909 and parameters: {'learning_rate': 0.012887198744371695, 'optimizer': 'RMSprop', 'n_layers': 1, 'n_units_l0': 117}. Best is trial 0 with value: 0.7954545454545454.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:47,806]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:47,818]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:47,828]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:47,855]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:47,880]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:47,925]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:47,944]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:47,974]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:47,994]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:48,029]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:48,052]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:48,072]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:48,095]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:48,118]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:48,307]\u001b[0m Trial 21 finished with value: 0.7159090909090909 and parameters: {'learning_rate': 0.011978338601274816, 'optimizer': 'RMSprop', 'n_layers': 1, 'n_units_l0': 87}. Best is trial 0 with value: 0.7954545454545454.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:48,495]\u001b[0m Trial 22 finished with value: 0.7045454545454546 and parameters: {'learning_rate': 0.007690176878886973, 'optimizer': 'RMSprop', 'n_layers': 1, 'n_units_l0': 64}. Best is trial 0 with value: 0.7954545454545454.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:48,520]\u001b[0m Trial 23 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:48,581]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:48,757]\u001b[0m Trial 25 finished with value: 0.7159090909090909 and parameters: {'learning_rate': 0.016868212152511095, 'optimizer': 'RMSprop', 'n_layers': 1, 'n_units_l0': 52}. Best is trial 0 with value: 0.7954545454545454.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:48,788]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:48,806]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:48,839]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 13:37:48,876]\u001b[0m Trial 29 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a model by implementing define-by-run design from Optuna\n",
    "def build_model_custom(trial):\n",
    "    \n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28\n",
    "# looping to determine the number of layers and nodes in each layer     \n",
    "    for i in range(n_layers):\n",
    "#         the number of nodes in each layer.\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        \n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "#         p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "#         layers.append(nn.Dropout(p))\n",
    "        \n",
    "        in_features = out_features\n",
    "        \n",
    "    layers.append(nn.Linear(in_features, 9))\n",
    "#     layers.append(nn.ReLU())\n",
    "    \n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# Train and evaluate the accuracy of neural network with the addition of pruning mechanism\n",
    "def train_and_evaluate(param, model, trial):\n",
    "    \n",
    "\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = getattr(optim, param['optimizer'])(model.parameters(), lr= param['learning_rate'])\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(EPOCHS):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in train_loader:\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                train_input = train_input.to(device)\n",
    "\n",
    "                output = model(train_input.float())\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in test_loader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    val_input = val_input.to(device)\n",
    "\n",
    "                    output = model(val_input.float())\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            accuracy = total_acc_val/len(test)\n",
    "            \n",
    "            # Add prune mechanism\n",
    "            trial.report(accuracy, epoch_num)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "  \n",
    "# Define a set of hyperparameter values, build the model, train the model, and evaluate the accuracy\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "              'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "              'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
    "              }\n",
    "    \n",
    "    model = build_model_custom(trial)\n",
    "\n",
    "    accuracy = train_and_evaluate(params, model, trial)\n",
    "\n",
    "    return accuracy\n",
    "  \n",
    "EPOCHS = 30\n",
    "    \n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614a06db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.01850375101853908\n",
      "optimizer: RMSprop\n",
      "n_layers: 1\n",
      "n_units_l0: 54\n"
     ]
    }
   ],
   "source": [
    "best_trial = study.best_trial\n",
    "\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f205e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.7954545454545454.\n",
    "# learning_rate: 0.0097004585501901\n",
    "# optimizer: Adam\n",
    "# n_layers: 2\n",
    "# n_units_l0: 40\n",
    "# n_units_l1: 128\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f8a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1,hidden_dim2, output_dim):\n",
    "        super(ANNModel, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.relu1 = nn.ReLU() \n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98edefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =30\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = X1.shape[1]\n",
    "hidden_dim1 = 40 #hidden layer1\n",
    "hidden_dim2 = 128 #hidden layer2 \n",
    "output_dim = len(set(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a447bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANNModel(input_dim, hidden_dim1,hidden_dim2,output_dim)\n",
    "\n",
    "\n",
    "learning_rate = 0.0097\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e313495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn_metrics] Epoch:0 loss:2.1475 accuracy:0.4922 precision:0.4922 recall:0.4922 f1:0.4922\n",
      "[sklearn_metrics] Epoch:0 loss:6.3937 accuracy:0.5469 precision:0.5469 recall:0.5469 f1:0.5469\n",
      "[sklearn_metrics] Epoch:0 loss:9.0285 accuracy:0.4486 precision:0.4486 recall:0.4486 f1:0.4486\n",
      "[sklearn_metrics] Epoch:1 loss:1.9530 accuracy:0.4297 precision:0.4297 recall:0.4297 f1:0.4297\n",
      "[sklearn_metrics] Epoch:1 loss:3.4651 accuracy:0.5508 precision:0.5508 recall:0.5508 f1:0.5508\n",
      "[sklearn_metrics] Epoch:1 loss:4.7976 accuracy:0.5714 precision:0.5714 recall:0.5714 f1:0.5714\n",
      "[sklearn_metrics] Epoch:2 loss:1.0845 accuracy:0.7266 precision:0.7266 recall:0.7266 f1:0.7266\n",
      "[sklearn_metrics] Epoch:2 loss:2.1579 accuracy:0.7188 precision:0.7188 recall:0.7188 f1:0.7188\n",
      "[sklearn_metrics] Epoch:2 loss:3.1244 accuracy:0.7114 precision:0.7114 recall:0.7114 f1:0.7114\n",
      "[sklearn_metrics] Epoch:3 loss:0.8303 accuracy:0.7188 precision:0.7188 recall:0.7188 f1:0.7188\n",
      "[sklearn_metrics] Epoch:3 loss:1.8297 accuracy:0.6953 precision:0.6953 recall:0.6953 f1:0.6953\n",
      "[sklearn_metrics] Epoch:3 loss:3.0422 accuracy:0.6829 precision:0.6829 recall:0.6829 f1:0.6829\n",
      "[sklearn_metrics] Epoch:4 loss:0.8067 accuracy:0.7344 precision:0.7344 recall:0.7344 f1:0.7344\n",
      "[sklearn_metrics] Epoch:4 loss:1.5157 accuracy:0.7422 precision:0.7422 recall:0.7422 f1:0.7422\n",
      "[sklearn_metrics] Epoch:4 loss:2.1004 accuracy:0.7543 precision:0.7543 recall:0.7543 f1:0.7543\n",
      "[sklearn_metrics] Epoch:5 loss:0.5313 accuracy:0.8281 precision:0.8281 recall:0.8281 f1:0.8281\n",
      "[sklearn_metrics] Epoch:5 loss:1.1712 accuracy:0.8281 precision:0.8281 recall:0.8281 f1:0.8281\n",
      "[sklearn_metrics] Epoch:5 loss:1.9444 accuracy:0.8029 precision:0.8029 recall:0.8029 f1:0.8029\n",
      "[sklearn_metrics] Epoch:6 loss:0.7435 accuracy:0.7578 precision:0.7578 recall:0.7578 f1:0.7578\n",
      "[sklearn_metrics] Epoch:6 loss:1.3935 accuracy:0.7852 precision:0.7852 recall:0.7852 f1:0.7852\n",
      "[sklearn_metrics] Epoch:6 loss:2.1326 accuracy:0.7771 precision:0.7771 recall:0.7771 f1:0.7771\n",
      "[sklearn_metrics] Epoch:7 loss:0.4357 accuracy:0.8359 precision:0.8359 recall:0.8359 f1:0.8359\n",
      "[sklearn_metrics] Epoch:7 loss:1.0292 accuracy:0.8203 precision:0.8203 recall:0.8203 f1:0.8203\n",
      "[sklearn_metrics] Epoch:7 loss:1.5090 accuracy:0.8286 precision:0.8286 recall:0.8286 f1:0.8286\n",
      "[sklearn_metrics] Epoch:8 loss:0.3220 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:8 loss:0.7316 accuracy:0.8789 precision:0.8789 recall:0.8789 f1:0.8789\n",
      "[sklearn_metrics] Epoch:8 loss:1.1612 accuracy:0.8657 precision:0.8657 recall:0.8657 f1:0.8657\n",
      "[sklearn_metrics] Epoch:9 loss:0.3807 accuracy:0.8906 precision:0.8906 recall:0.8906 f1:0.8906\n",
      "[sklearn_metrics] Epoch:9 loss:0.7515 accuracy:0.8789 precision:0.8789 recall:0.8789 f1:0.8789\n",
      "[sklearn_metrics] Epoch:9 loss:1.1776 accuracy:0.8800 precision:0.8800 recall:0.8800 f1:0.8800\n",
      "[sklearn_metrics] Epoch:10 loss:0.3082 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:10 loss:0.6590 accuracy:0.8945 precision:0.8945 recall:0.8945 f1:0.8945\n",
      "[sklearn_metrics] Epoch:10 loss:0.9645 accuracy:0.9057 precision:0.9057 recall:0.9057 f1:0.9057\n",
      "[sklearn_metrics] Epoch:11 loss:0.3191 accuracy:0.8906 precision:0.8906 recall:0.8906 f1:0.8906\n",
      "[sklearn_metrics] Epoch:11 loss:0.5865 accuracy:0.9102 precision:0.9102 recall:0.9102 f1:0.9102\n",
      "[sklearn_metrics] Epoch:11 loss:0.8386 accuracy:0.9229 precision:0.9229 recall:0.9229 f1:0.9229\n",
      "[sklearn_metrics] Epoch:12 loss:0.2669 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:12 loss:0.6352 accuracy:0.8906 precision:0.8906 recall:0.8906 f1:0.8906\n",
      "[sklearn_metrics] Epoch:12 loss:0.9217 accuracy:0.8886 precision:0.8886 recall:0.8886 f1:0.8886\n",
      "[sklearn_metrics] Epoch:13 loss:0.2134 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:13 loss:0.3892 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:13 loss:0.7286 accuracy:0.9314 precision:0.9314 recall:0.9314 f1:0.9314\n",
      "[sklearn_metrics] Epoch:14 loss:0.2153 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:14 loss:0.3752 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:14 loss:0.5770 accuracy:0.9429 precision:0.9429 recall:0.9429 f1:0.9429\n",
      "[sklearn_metrics] Epoch:15 loss:0.1283 accuracy:0.9766 precision:0.9766 recall:0.9766 f1:0.9766\n",
      "[sklearn_metrics] Epoch:15 loss:0.2994 accuracy:0.9688 precision:0.9688 recall:0.9688 f1:0.9688\n",
      "[sklearn_metrics] Epoch:15 loss:0.5155 accuracy:0.9571 precision:0.9571 recall:0.9571 f1:0.9571\n",
      "[sklearn_metrics] Epoch:16 loss:0.1817 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:16 loss:0.3178 accuracy:0.9531 precision:0.9531 recall:0.9531 f1:0.9531\n",
      "[sklearn_metrics] Epoch:16 loss:0.4612 accuracy:0.9543 precision:0.9543 recall:0.9543 f1:0.9543\n",
      "[sklearn_metrics] Epoch:17 loss:0.1125 accuracy:0.9766 precision:0.9766 recall:0.9766 f1:0.9766\n",
      "[sklearn_metrics] Epoch:17 loss:0.2447 accuracy:0.9648 precision:0.9648 recall:0.9648 f1:0.9648\n",
      "[sklearn_metrics] Epoch:17 loss:0.4287 accuracy:0.9600 precision:0.9600 recall:0.9600 f1:0.9600\n",
      "[sklearn_metrics] Epoch:18 loss:0.2451 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:18 loss:0.5182 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:18 loss:0.7178 accuracy:0.9171 precision:0.9171 recall:0.9171 f1:0.9171\n",
      "[sklearn_metrics] Epoch:19 loss:0.2129 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:19 loss:0.3586 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:19 loss:0.4673 accuracy:0.9543 precision:0.9543 recall:0.9543 f1:0.9543\n",
      "[sklearn_metrics] Epoch:20 loss:0.1084 accuracy:0.9766 precision:0.9766 recall:0.9766 f1:0.9766\n",
      "[sklearn_metrics] Epoch:20 loss:0.1805 accuracy:0.9766 precision:0.9766 recall:0.9766 f1:0.9766\n",
      "[sklearn_metrics] Epoch:20 loss:0.2890 accuracy:0.9771 precision:0.9771 recall:0.9771 f1:0.9771\n",
      "[sklearn_metrics] Epoch:21 loss:0.0802 accuracy:0.9922 precision:0.9922 recall:0.9922 f1:0.9922\n",
      "[sklearn_metrics] Epoch:21 loss:0.2079 accuracy:0.9805 precision:0.9805 recall:0.9805 f1:0.9805\n",
      "[sklearn_metrics] Epoch:21 loss:0.3481 accuracy:0.9743 precision:0.9743 recall:0.9743 f1:0.9743\n",
      "[sklearn_metrics] Epoch:22 loss:0.1400 accuracy:0.9531 precision:0.9531 recall:0.9531 f1:0.9531\n",
      "[sklearn_metrics] Epoch:22 loss:0.2351 accuracy:0.9688 precision:0.9688 recall:0.9688 f1:0.9688\n",
      "[sklearn_metrics] Epoch:22 loss:0.3361 accuracy:0.9743 precision:0.9743 recall:0.9743 f1:0.9743\n",
      "[sklearn_metrics] Epoch:23 loss:0.0666 accuracy:0.9844 precision:0.9844 recall:0.9844 f1:0.9844\n",
      "[sklearn_metrics] Epoch:23 loss:0.1085 accuracy:0.9883 precision:0.9883 recall:0.9883 f1:0.9883\n",
      "[sklearn_metrics] Epoch:23 loss:0.1627 accuracy:0.9886 precision:0.9886 recall:0.9886 f1:0.9886\n",
      "[sklearn_metrics] Epoch:24 loss:0.0354 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:24 loss:0.0856 accuracy:0.9961 precision:0.9961 recall:0.9961 f1:0.9961\n",
      "[sklearn_metrics] Epoch:24 loss:0.1296 accuracy:0.9943 precision:0.9943 recall:0.9943 f1:0.9943\n",
      "[sklearn_metrics] Epoch:25 loss:0.0413 accuracy:0.9922 precision:0.9922 recall:0.9922 f1:0.9922\n",
      "[sklearn_metrics] Epoch:25 loss:0.0829 accuracy:0.9961 precision:0.9961 recall:0.9961 f1:0.9961\n",
      "[sklearn_metrics] Epoch:25 loss:0.1263 accuracy:0.9971 precision:0.9971 recall:0.9971 f1:0.9971\n",
      "[sklearn_metrics] Epoch:26 loss:0.0328 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:26 loss:0.0607 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:26 loss:0.0968 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:27 loss:0.0271 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:27 loss:0.0504 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:27 loss:0.0761 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:28 loss:0.0257 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:28 loss:0.0481 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:28 loss:0.0681 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn_metrics] Epoch:29 loss:0.0224 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:29 loss:0.0431 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "[sklearn_metrics] Epoch:29 loss:0.0569 accuracy:1.0000 precision:1.0000 recall:1.0000 f1:1.0000\n",
      "0.4627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83        49\n",
      "           1       0.58      0.78      0.67         9\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       0.67      0.67      0.67         3\n",
      "           4       0.33      0.33      0.33         3\n",
      "           5       0.50      0.40      0.44         5\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       0.50      0.30      0.37        10\n",
      "           8       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.72        88\n",
      "   macro avg       0.60      0.60      0.59        88\n",
      "weighted avg       0.67      0.72      0.69        88\n",
      "\n",
      "[[43  1  0  1  1  2  0  1  0]\n",
      " [ 2  7  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0  0  0  0]\n",
      " [ 1  0  0  2  0  0  0  0  0]\n",
      " [ 2  0  0  0  1  0  0  0  0]\n",
      " [ 2  0  0  0  0  2  0  1  0]\n",
      " [ 0  0  0  0  0  0  2  0  0]\n",
      " [ 4  2  0  0  1  0  0  3  0]\n",
      " [ 1  2  0  0  0  0  0  1  0]]\n",
      "[sklearn_metrics] accuracy:0.7159 precision:0.7159 recall:0.7159 f1:0.7159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "B:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "B:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "start=datetime.now()\n",
    "total_step = len(train_loader)\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    tot_loss = 0.0\n",
    "    tot_acc = 0.0\n",
    "    train_preds = []\n",
    "    train_trues = []\n",
    "  # model.train()\n",
    "    for i,(train_data_batch, train_label_batch) in enumerate(train_loader):\n",
    "        train_data_batch = train_data_batch.float().to(device) #from double to float\n",
    "        train_label_batch = train_label_batch.to(device)\n",
    "        outputs = model(train_data_batch)\n",
    "        # _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, train_label_batch)\n",
    "        # print(loss)\n",
    "        #backword propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # accumulate the loss of each step \n",
    "        tot_loss += loss.data\n",
    "        train_outputs = outputs.argmax(dim=1)\n",
    "        train_preds.extend(train_outputs.detach().cpu().numpy())\n",
    "        train_trues.extend(train_label_batch.detach().cpu().numpy())\n",
    "        # tot_acc += (outputs.argmax(dim=1) == train_label_batch).sum().item()\n",
    "        sklearn_accuracy = accuracy_score(train_trues, train_preds)\n",
    "        sklearn_precision = precision_score(train_trues, train_preds, average='micro')\n",
    "        sklearn_recall = recall_score(train_trues, train_preds, average='micro')\n",
    "        sklearn_f1 = f1_score(train_trues, train_preds, average='micro')\n",
    "        print(\"[sklearn_metrics] Epoch:{} loss:{:.4f} accuracy:{:.4f} precision:{:.4f} recall:{:.4f} f1:{:.4f}\".format(epoch, tot_loss, sklearn_accuracy, sklearn_precision, sklearn_recall, sklearn_f1))\n",
    "stop=datetime.now()\n",
    "execution_time_ann=(stop-start)\n",
    "training_time_ann='%.4f'%(execution_time_ann).total_seconds()\n",
    "print(training_time_ann)\n",
    "        \n",
    "test_preds = []\n",
    "test_trues = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i,(test_data_batch, test_data_label) in enumerate(test_loader):\n",
    "        test_data_batch = test_data_batch.float().to(device) #from double to float\n",
    "        test_data_label = test_data_label.to(device)\n",
    "        test_outputs = model(test_data_batch)\n",
    "        probs = F.softmax(test_outputs, dim=1) \n",
    "        test_outputs = test_outputs.argmax(dim=1)\n",
    "        testloss = criterion(probs, test_data_label)\n",
    "#         preds = torch.argmax(logits, dim=1)\n",
    "        test_preds.extend(test_outputs.detach().cpu().numpy())\n",
    "        test_trues.extend(test_data_label.detach().cpu().numpy())\n",
    "        sklearn_accuracy = accuracy_score(test_trues, test_preds)\n",
    "        sklearn_precision = precision_score(test_trues, test_preds, average='micro')\n",
    "        sklearn_recall = recall_score(test_trues, test_preds, average='micro')\n",
    "        sklearn_f1 = f1_score(test_trues, test_preds, average='micro')\n",
    "        print(classification_report(test_trues, test_preds))\n",
    "        conf_matrix = confusion_matrix(test_trues, test_preds)\n",
    "        print(conf_matrix)\n",
    "#         plot_confusion_matrix(conf_matrix)\n",
    "        print(\"[sklearn_metrics] accuracy:{:.4f} precision:{:.4f} recall:{:.4f} f1:{:.4f}\".format(sklearn_accuracy, sklearn_precision, sklearn_recall, sklearn_f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
