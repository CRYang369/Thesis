{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ee2c8a",
   "metadata": {},
   "source": [
    "# Import the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a9cc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score  \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,roc_auc_score,accuracy_score, plot_confusion_matrix,classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12583cbc",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8c97c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>137</td>\n",
       "      <td>121</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>198</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>136</td>\n",
       "      <td>140</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>198</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>135</td>\n",
       "      <td>138</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>170</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>134</td>\n",
       "      <td>137</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>136</td>\n",
       "      <td>138</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LB        AC   FM        UC        DL   DP  ASTV  MSTV  ALTV  MLTV  ...  \\\n",
       "0  120  0.000000  0.0  0.000000  0.000000  0.0    73   0.5    43   2.4  ...   \n",
       "1  132  0.006380  0.0  0.006380  0.003190  0.0    17   2.1     0  10.4  ...   \n",
       "2  133  0.003322  0.0  0.008306  0.003322  0.0    16   2.1     0  13.4  ...   \n",
       "3  134  0.002561  0.0  0.007682  0.002561  0.0    16   2.4     0  23.0  ...   \n",
       "4  132  0.006515  0.0  0.008143  0.000000  0.0    16   2.4     0  19.9  ...   \n",
       "\n",
       "   Min  Max  Nmax  Nzeros  Mode  Mean  Median  Variance  Tendency  label  \n",
       "0   62  126     2       0   120   137     121        73         1      1  \n",
       "1   68  198     6       1   141   136     140        12         0      0  \n",
       "2   68  198     5       1   141   135     138        13         0      0  \n",
       "3   53  170    11       0   137   134     137        13         1      0  \n",
       "4   53  170     9       0   137   136     138        11         1      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTGData=pd.read_csv('CTGNSP selected 20 features.csv')\n",
    "CTGData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0db571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='label',data=CTGData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee8cd2",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b09ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTGData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d5b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CTGData01=CTGData.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0164e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=CTGData01.drop(labels=['label'],axis=1)\n",
    "\n",
    "y1=CTGData01['label'].values\n",
    "y1 = LabelEncoder().fit_transform(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed2ad0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stanardilization\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X1)\n",
    "X1=scaler.transform(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe46089",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c359dfcf",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a45779f",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape : (1700, 20)\n",
      "X_test.shape : (426, 20)\n"
     ]
    }
   ],
   "source": [
    "#split train dataset and test dataset\n",
    "X1_train, X1_test,y1_train,y1_test= train_test_split(X1,y1,test_size=0.2, shuffle = True,stratify=y1,random_state=42)\n",
    "print(\"X_train.shape :\",X1_train.shape)\n",
    "print(\"X_test.shape :\",X1_test.shape)\n",
    "# print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e17518",
   "metadata": {},
   "source": [
    "Define the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12db8e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X1_train = torch.from_numpy(X1_train)\n",
    "y1_train = torch.from_numpy(y1_train ).type(torch.LongTensor)\n",
    "\n",
    "X1_test  = torch.from_numpy(X1_test )\n",
    "y1_test= torch.from_numpy(y1_test).type(torch.LongTensor)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train = torch.utils.data.TensorDataset(X1_train, y1_train )\n",
    "test = torch.utils.data.TensorDataset(X1_test , y1_test)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a2d920",
   "metadata": {},
   "source": [
    "Define the Optuna  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e43e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-09 15:02:28,461]\u001b[0m A new study created in memory with name: no-name-c1f9f528-1525-4829-8ff9-c963c03041a4\u001b[0m\n",
      "C:\\Users\\COOLER~1\\AppData\\Local\\Temp/ipykernel_12528/2944855679.py:96: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2022-09-09 15:02:29,225]\u001b[0m Trial 0 finished with value: 0.9131455399061033 and parameters: {'learning_rate': 0.004036439181109626, 'optimizer': 'RMSprop', 'n_layers': 1, 'n_units_l0': 86}. Best is trial 0 with value: 0.9131455399061033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:30,208]\u001b[0m Trial 1 finished with value: 0.8896713615023474 and parameters: {'learning_rate': 0.0005904648395527698, 'optimizer': 'RMSprop', 'n_layers': 3, 'n_units_l0': 125, 'n_units_l1': 76, 'n_units_l2': 12}. Best is trial 0 with value: 0.9131455399061033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:30,920]\u001b[0m Trial 2 finished with value: 0.8262910798122066 and parameters: {'learning_rate': 7.7866854502816e-05, 'optimizer': 'RMSprop', 'n_layers': 1, 'n_units_l0': 46}. Best is trial 0 with value: 0.9131455399061033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:31,953]\u001b[0m Trial 3 finished with value: 0.7511737089201878 and parameters: {'learning_rate': 1.774882036851549e-05, 'optimizer': 'Adam', 'n_layers': 3, 'n_units_l0': 90, 'n_units_l1': 34, 'n_units_l2': 62}. Best is trial 0 with value: 0.9131455399061033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:32,946]\u001b[0m Trial 4 finished with value: 0.8967136150234741 and parameters: {'learning_rate': 0.004207660104993377, 'optimizer': 'RMSprop', 'n_layers': 3, 'n_units_l0': 75, 'n_units_l1': 59, 'n_units_l2': 77}. Best is trial 0 with value: 0.9131455399061033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:32,986]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:33,959]\u001b[0m Trial 6 finished with value: 0.8990610328638498 and parameters: {'learning_rate': 0.034904111065905664, 'optimizer': 'Adam', 'n_layers': 2, 'n_units_l0': 101, 'n_units_l1': 66}. Best is trial 0 with value: 0.9131455399061033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:35,104]\u001b[0m Trial 7 finished with value: 0.8990610328638498 and parameters: {'learning_rate': 0.013966317037166874, 'optimizer': 'Adam', 'n_layers': 2, 'n_units_l0': 121, 'n_units_l1': 110}. Best is trial 0 with value: 0.9131455399061033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:35,142]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:35,174]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:35,215]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:35,265]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:35,308]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:36,257]\u001b[0m Trial 13 finished with value: 0.8779342723004695 and parameters: {'learning_rate': 0.0056385268773401455, 'optimizer': 'RMSprop', 'n_layers': 2, 'n_units_l0': 67, 'n_units_l1': 68}. Best is trial 0 with value: 0.9131455399061033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:36,297]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:36,410]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:36,450]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:37,545]\u001b[0m Trial 17 finished with value: 0.8896713615023474 and parameters: {'learning_rate': 0.01210445674417594, 'optimizer': 'Adam', 'n_layers': 2, 'n_units_l0': 108, 'n_units_l1': 87}. Best is trial 0 with value: 0.9131455399061033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:37,603]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:37,635]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:37,685]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:37,744]\u001b[0m Trial 21 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:37,967]\u001b[0m Trial 22 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:38,025]\u001b[0m Trial 23 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:39,132]\u001b[0m Trial 24 finished with value: 0.8826291079812206 and parameters: {'learning_rate': 0.02628991940261637, 'optimizer': 'Adam', 'n_layers': 2, 'n_units_l0': 77, 'n_units_l1': 81}. Best is trial 0 with value: 0.9131455399061033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:39,180]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:39,231]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:39,291]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:39,333]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 15:02:39,393]\u001b[0m Trial 29 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a model by implementing define-by-run design from Optuna\n",
    "def build_model_custom(trial):\n",
    "    \n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 20\n",
    "# looping to determine the number of layers and nodes in each layer     \n",
    "    for i in range(n_layers):\n",
    "#         the number of nodes in each layer.\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        \n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "#         p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "#         layers.append(nn.Dropout(p))\n",
    "        \n",
    "        in_features = out_features\n",
    "        \n",
    "    layers.append(nn.Linear(in_features, 10))\n",
    "#     layers.append(nn.ReLU())\n",
    "    \n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# Train and evaluate the accuracy of neural network with the addition of pruning mechanism\n",
    "def train_and_evaluate(param, model, trial):\n",
    "    \n",
    "\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = getattr(optim, param['optimizer'])(model.parameters(), lr= param['learning_rate'])\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(EPOCHS):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in train_loader:\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                train_input = train_input.to(device)\n",
    "\n",
    "                output = model(train_input.float())\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in test_loader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    val_input = val_input.to(device)\n",
    "\n",
    "                    output = model(val_input.float())\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            accuracy = total_acc_val/len(test)\n",
    "            \n",
    "            # Add prune mechanism\n",
    "            trial.report(accuracy, epoch_num)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "  \n",
    "# Define a set of hyperparameter values, build the model, train the model, and evaluate the accuracy\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "              'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "              'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
    "              }\n",
    "    \n",
    "    model = build_model_custom(trial)\n",
    "\n",
    "    accuracy = train_and_evaluate(params, model, trial)\n",
    "\n",
    "    return accuracy\n",
    "  \n",
    "EPOCHS = 30\n",
    "    \n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "494ce74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.004036439181109626\n",
      "optimizer: RMSprop\n",
      "n_layers: 1\n",
      "n_units_l0: 86\n"
     ]
    }
   ],
   "source": [
    "best_trial = study.best_trial\n",
    "\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0386e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  0.9154929577464789.\n",
    "# learning_rate: 0.041866941177386055\n",
    "# optimizer: Adam\n",
    "# n_layers: 1\n",
    "# n_units_l0: 39\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f205e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  0.9178403755868545.\n",
    "#     learning_rate: 0.009804596280962207\n",
    "# optimizer: Adam\n",
    "# n_layers: 1\n",
    "# n_units_l0: 102\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86f8a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(ANNModel, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu1 = nn.ReLU() \n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a67eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =30\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = X1.shape[1]\n",
    "hidden_dim =39 #hidden layer1\n",
    "\n",
    "output_dim = len(set(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a447bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANNModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "learning_rate =0.042\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e313495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn_metrics] Epoch:0 loss:1.1217 accuracy:0.1094 precision:0.1094 recall:0.1094 f1:0.1094\n",
      "[sklearn_metrics] Epoch:0 loss:1.8611 accuracy:0.4688 precision:0.4688 recall:0.4688 f1:0.4688\n",
      "[sklearn_metrics] Epoch:0 loss:2.5995 accuracy:0.5677 precision:0.5677 recall:0.5677 f1:0.5677\n",
      "[sklearn_metrics] Epoch:0 loss:3.2038 accuracy:0.6113 precision:0.6113 recall:0.6113 f1:0.6113\n",
      "[sklearn_metrics] Epoch:0 loss:3.6236 accuracy:0.6562 precision:0.6562 recall:0.6562 f1:0.6562\n",
      "[sklearn_metrics] Epoch:0 loss:4.0026 accuracy:0.6966 precision:0.6966 recall:0.6966 f1:0.6966\n",
      "[sklearn_metrics] Epoch:0 loss:4.3388 accuracy:0.7277 precision:0.7277 recall:0.7277 f1:0.7277\n",
      "[sklearn_metrics] Epoch:0 loss:4.7137 accuracy:0.7422 precision:0.7422 recall:0.7422 f1:0.7422\n",
      "[sklearn_metrics] Epoch:0 loss:5.1060 accuracy:0.7500 precision:0.7500 recall:0.7500 f1:0.7500\n",
      "[sklearn_metrics] Epoch:0 loss:5.4625 accuracy:0.7586 precision:0.7586 recall:0.7586 f1:0.7586\n",
      "[sklearn_metrics] Epoch:0 loss:5.8121 accuracy:0.7699 precision:0.7699 recall:0.7699 f1:0.7699\n",
      "[sklearn_metrics] Epoch:0 loss:6.0702 accuracy:0.7806 precision:0.7806 recall:0.7806 f1:0.7806\n",
      "[sklearn_metrics] Epoch:0 loss:6.3939 accuracy:0.7861 precision:0.7861 recall:0.7861 f1:0.7861\n",
      "[sklearn_metrics] Epoch:0 loss:6.9963 accuracy:0.7859 precision:0.7859 recall:0.7859 f1:0.7859\n",
      "[sklearn_metrics] Epoch:1 loss:0.4425 accuracy:0.8516 precision:0.8516 recall:0.8516 f1:0.8516\n",
      "[sklearn_metrics] Epoch:1 loss:0.7065 accuracy:0.8672 precision:0.8672 recall:0.8672 f1:0.8672\n",
      "[sklearn_metrics] Epoch:1 loss:0.9256 accuracy:0.8776 precision:0.8776 recall:0.8776 f1:0.8776\n",
      "[sklearn_metrics] Epoch:1 loss:1.2429 accuracy:0.8652 precision:0.8652 recall:0.8652 f1:0.8652\n",
      "[sklearn_metrics] Epoch:1 loss:1.5753 accuracy:0.8531 precision:0.8531 recall:0.8531 f1:0.8531\n",
      "[sklearn_metrics] Epoch:1 loss:1.9064 accuracy:0.8464 precision:0.8464 recall:0.8464 f1:0.8464\n",
      "[sklearn_metrics] Epoch:1 loss:2.2189 accuracy:0.8449 precision:0.8449 recall:0.8449 f1:0.8449\n",
      "[sklearn_metrics] Epoch:1 loss:2.5190 accuracy:0.8496 precision:0.8496 recall:0.8496 f1:0.8496\n",
      "[sklearn_metrics] Epoch:1 loss:2.7895 accuracy:0.8524 precision:0.8524 recall:0.8524 f1:0.8524\n",
      "[sklearn_metrics] Epoch:1 loss:3.0599 accuracy:0.8570 precision:0.8570 recall:0.8570 f1:0.8570\n",
      "[sklearn_metrics] Epoch:1 loss:3.3444 accuracy:0.8594 precision:0.8594 recall:0.8594 f1:0.8594\n",
      "[sklearn_metrics] Epoch:1 loss:3.6961 accuracy:0.8587 precision:0.8587 recall:0.8587 f1:0.8587\n",
      "[sklearn_metrics] Epoch:1 loss:3.9975 accuracy:0.8600 precision:0.8600 recall:0.8600 f1:0.8600\n",
      "[sklearn_metrics] Epoch:1 loss:4.1730 accuracy:0.8618 precision:0.8618 recall:0.8618 f1:0.8618\n",
      "[sklearn_metrics] Epoch:2 loss:0.1936 accuracy:0.9062 precision:0.9062 recall:0.9062 f1:0.9062\n",
      "[sklearn_metrics] Epoch:2 loss:0.6354 accuracy:0.8750 precision:0.8750 recall:0.8750 f1:0.8750\n",
      "[sklearn_metrics] Epoch:2 loss:0.8712 accuracy:0.8880 precision:0.8880 recall:0.8880 f1:0.8880\n",
      "[sklearn_metrics] Epoch:2 loss:1.1771 accuracy:0.8887 precision:0.8887 recall:0.8887 f1:0.8887\n",
      "[sklearn_metrics] Epoch:2 loss:1.3954 accuracy:0.8938 precision:0.8938 recall:0.8938 f1:0.8938\n",
      "[sklearn_metrics] Epoch:2 loss:1.5978 accuracy:0.8971 precision:0.8971 recall:0.8971 f1:0.8971\n",
      "[sklearn_metrics] Epoch:2 loss:1.8673 accuracy:0.8951 precision:0.8951 recall:0.8951 f1:0.8951\n",
      "[sklearn_metrics] Epoch:2 loss:2.1484 accuracy:0.8945 precision:0.8945 recall:0.8945 f1:0.8945\n",
      "[sklearn_metrics] Epoch:2 loss:2.3303 accuracy:0.8993 precision:0.8993 recall:0.8993 f1:0.8993\n",
      "[sklearn_metrics] Epoch:2 loss:2.5221 accuracy:0.9016 precision:0.9016 recall:0.9016 f1:0.9016\n",
      "[sklearn_metrics] Epoch:2 loss:2.7388 accuracy:0.9013 precision:0.9013 recall:0.9013 f1:0.9013\n",
      "[sklearn_metrics] Epoch:2 loss:2.9652 accuracy:0.9010 precision:0.9010 recall:0.9010 f1:0.9010\n",
      "[sklearn_metrics] Epoch:2 loss:3.1973 accuracy:0.9008 precision:0.9008 recall:0.9008 f1:0.9008\n",
      "[sklearn_metrics] Epoch:2 loss:3.3574 accuracy:0.9012 precision:0.9012 recall:0.9012 f1:0.9012\n",
      "[sklearn_metrics] Epoch:3 loss:0.1780 accuracy:0.9062 precision:0.9062 recall:0.9062 f1:0.9062\n",
      "[sklearn_metrics] Epoch:3 loss:0.4415 accuracy:0.8906 precision:0.8906 recall:0.8906 f1:0.8906\n",
      "[sklearn_metrics] Epoch:3 loss:0.6805 accuracy:0.8828 precision:0.8828 recall:0.8828 f1:0.8828\n",
      "[sklearn_metrics] Epoch:3 loss:0.9221 accuracy:0.8770 precision:0.8770 recall:0.8770 f1:0.8770\n",
      "[sklearn_metrics] Epoch:3 loss:1.1140 accuracy:0.8875 precision:0.8875 recall:0.8875 f1:0.8875\n",
      "[sklearn_metrics] Epoch:3 loss:1.2873 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:3 loss:1.4587 accuracy:0.9040 precision:0.9040 recall:0.9040 f1:0.9040\n",
      "[sklearn_metrics] Epoch:3 loss:1.6609 accuracy:0.9033 precision:0.9033 recall:0.9033 f1:0.9033\n",
      "[sklearn_metrics] Epoch:3 loss:1.8892 accuracy:0.9010 precision:0.9010 recall:0.9010 f1:0.9010\n",
      "[sklearn_metrics] Epoch:3 loss:2.0841 accuracy:0.9023 precision:0.9023 recall:0.9023 f1:0.9023\n",
      "[sklearn_metrics] Epoch:3 loss:2.2566 accuracy:0.9041 precision:0.9041 recall:0.9041 f1:0.9041\n",
      "[sklearn_metrics] Epoch:3 loss:2.5107 accuracy:0.9036 precision:0.9036 recall:0.9036 f1:0.9036\n",
      "[sklearn_metrics] Epoch:3 loss:2.7375 accuracy:0.9008 precision:0.9008 recall:0.9008 f1:0.9008\n",
      "[sklearn_metrics] Epoch:3 loss:2.9679 accuracy:0.8994 precision:0.8994 recall:0.8994 f1:0.8994\n",
      "[sklearn_metrics] Epoch:4 loss:0.1793 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:4 loss:0.3143 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:4 loss:0.4654 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:4 loss:0.6988 accuracy:0.9160 precision:0.9160 recall:0.9160 f1:0.9160\n",
      "[sklearn_metrics] Epoch:4 loss:0.9081 accuracy:0.9156 precision:0.9156 recall:0.9156 f1:0.9156\n",
      "[sklearn_metrics] Epoch:4 loss:1.0958 accuracy:0.9154 precision:0.9154 recall:0.9154 f1:0.9154\n",
      "[sklearn_metrics] Epoch:4 loss:1.3340 accuracy:0.9129 precision:0.9129 recall:0.9129 f1:0.9129\n",
      "[sklearn_metrics] Epoch:4 loss:1.5131 accuracy:0.9150 precision:0.9150 recall:0.9150 f1:0.9150\n",
      "[sklearn_metrics] Epoch:4 loss:1.7178 accuracy:0.9167 precision:0.9167 recall:0.9167 f1:0.9167\n",
      "[sklearn_metrics] Epoch:4 loss:1.9298 accuracy:0.9133 precision:0.9133 recall:0.9133 f1:0.9133\n",
      "[sklearn_metrics] Epoch:4 loss:2.1178 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:4 loss:2.3397 accuracy:0.9134 precision:0.9134 recall:0.9134 f1:0.9134\n",
      "[sklearn_metrics] Epoch:4 loss:2.5130 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:4 loss:2.6572 accuracy:0.9153 precision:0.9153 recall:0.9153 f1:0.9153\n",
      "[sklearn_metrics] Epoch:5 loss:0.1861 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:5 loss:0.3365 accuracy:0.9336 precision:0.9336 recall:0.9336 f1:0.9336\n",
      "[sklearn_metrics] Epoch:5 loss:0.4978 accuracy:0.9323 precision:0.9323 recall:0.9323 f1:0.9323\n",
      "[sklearn_metrics] Epoch:5 loss:0.6657 accuracy:0.9238 precision:0.9238 recall:0.9238 f1:0.9238\n",
      "[sklearn_metrics] Epoch:5 loss:0.8242 accuracy:0.9234 precision:0.9234 recall:0.9234 f1:0.9234\n",
      "[sklearn_metrics] Epoch:5 loss:0.9904 accuracy:0.9258 precision:0.9258 recall:0.9258 f1:0.9258\n",
      "[sklearn_metrics] Epoch:5 loss:1.1509 accuracy:0.9252 precision:0.9252 recall:0.9252 f1:0.9252\n",
      "[sklearn_metrics] Epoch:5 loss:1.3008 accuracy:0.9238 precision:0.9238 recall:0.9238 f1:0.9238\n",
      "[sklearn_metrics] Epoch:5 loss:1.5000 accuracy:0.9245 precision:0.9245 recall:0.9245 f1:0.9245\n",
      "[sklearn_metrics] Epoch:5 loss:1.6579 accuracy:0.9227 precision:0.9227 recall:0.9227 f1:0.9227\n",
      "[sklearn_metrics] Epoch:5 loss:1.8489 accuracy:0.9233 precision:0.9233 recall:0.9233 f1:0.9233\n",
      "[sklearn_metrics] Epoch:5 loss:2.0791 accuracy:0.9199 precision:0.9199 recall:0.9199 f1:0.9199\n",
      "[sklearn_metrics] Epoch:5 loss:2.2925 accuracy:0.9207 precision:0.9207 recall:0.9207 f1:0.9207\n",
      "[sklearn_metrics] Epoch:5 loss:2.5009 accuracy:0.9200 precision:0.9200 recall:0.9200 f1:0.9200\n",
      "[sklearn_metrics] Epoch:6 loss:0.0937 accuracy:0.9609 precision:0.9609 recall:0.9609 f1:0.9609\n",
      "[sklearn_metrics] Epoch:6 loss:0.2426 accuracy:0.9531 precision:0.9531 recall:0.9531 f1:0.9531\n",
      "[sklearn_metrics] Epoch:6 loss:0.4691 accuracy:0.9349 precision:0.9349 recall:0.9349 f1:0.9349\n",
      "[sklearn_metrics] Epoch:6 loss:0.6004 accuracy:0.9355 precision:0.9355 recall:0.9355 f1:0.9355\n",
      "[sklearn_metrics] Epoch:6 loss:0.8256 accuracy:0.9266 precision:0.9266 recall:0.9266 f1:0.9266\n",
      "[sklearn_metrics] Epoch:6 loss:0.9531 accuracy:0.9271 precision:0.9271 recall:0.9271 f1:0.9271\n",
      "[sklearn_metrics] Epoch:6 loss:1.1166 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn_metrics] Epoch:6 loss:1.3665 accuracy:0.9268 precision:0.9268 recall:0.9268 f1:0.9268\n",
      "[sklearn_metrics] Epoch:6 loss:1.6217 accuracy:0.9236 precision:0.9236 recall:0.9236 f1:0.9236\n",
      "[sklearn_metrics] Epoch:6 loss:1.7691 accuracy:0.9234 precision:0.9234 recall:0.9234 f1:0.9234\n",
      "[sklearn_metrics] Epoch:6 loss:1.9676 accuracy:0.9205 precision:0.9205 recall:0.9205 f1:0.9205\n",
      "[sklearn_metrics] Epoch:6 loss:2.0972 accuracy:0.9225 precision:0.9225 recall:0.9225 f1:0.9225\n",
      "[sklearn_metrics] Epoch:6 loss:2.2709 accuracy:0.9231 precision:0.9231 recall:0.9231 f1:0.9231\n",
      "[sklearn_metrics] Epoch:6 loss:2.5318 accuracy:0.9229 precision:0.9229 recall:0.9229 f1:0.9229\n",
      "[sklearn_metrics] Epoch:7 loss:0.1900 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:7 loss:0.3263 accuracy:0.9180 precision:0.9180 recall:0.9180 f1:0.9180\n",
      "[sklearn_metrics] Epoch:7 loss:0.4544 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:7 loss:0.7328 accuracy:0.9180 precision:0.9180 recall:0.9180 f1:0.9180\n",
      "[sklearn_metrics] Epoch:7 loss:0.8803 accuracy:0.9203 precision:0.9203 recall:0.9203 f1:0.9203\n",
      "[sklearn_metrics] Epoch:7 loss:1.0447 accuracy:0.9232 precision:0.9232 recall:0.9232 f1:0.9232\n",
      "[sklearn_metrics] Epoch:7 loss:1.2270 accuracy:0.9208 precision:0.9208 recall:0.9208 f1:0.9208\n",
      "[sklearn_metrics] Epoch:7 loss:1.3910 accuracy:0.9229 precision:0.9229 recall:0.9229 f1:0.9229\n",
      "[sklearn_metrics] Epoch:7 loss:1.6289 accuracy:0.9193 precision:0.9193 recall:0.9193 f1:0.9193\n",
      "[sklearn_metrics] Epoch:7 loss:1.8030 accuracy:0.9211 precision:0.9211 recall:0.9211 f1:0.9211\n",
      "[sklearn_metrics] Epoch:7 loss:1.9991 accuracy:0.9212 precision:0.9212 recall:0.9212 f1:0.9212\n",
      "[sklearn_metrics] Epoch:7 loss:2.1684 accuracy:0.9206 precision:0.9206 recall:0.9206 f1:0.9206\n",
      "[sklearn_metrics] Epoch:7 loss:2.3651 accuracy:0.9213 precision:0.9213 recall:0.9213 f1:0.9213\n",
      "[sklearn_metrics] Epoch:7 loss:2.5289 accuracy:0.9224 precision:0.9224 recall:0.9224 f1:0.9224\n",
      "[sklearn_metrics] Epoch:8 loss:0.1698 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:8 loss:0.2677 accuracy:0.9492 precision:0.9492 recall:0.9492 f1:0.9492\n",
      "[sklearn_metrics] Epoch:8 loss:0.4557 accuracy:0.9427 precision:0.9427 recall:0.9427 f1:0.9427\n",
      "[sklearn_metrics] Epoch:8 loss:0.6402 accuracy:0.9355 precision:0.9355 recall:0.9355 f1:0.9355\n",
      "[sklearn_metrics] Epoch:8 loss:0.7927 accuracy:0.9328 precision:0.9328 recall:0.9328 f1:0.9328\n",
      "[sklearn_metrics] Epoch:8 loss:0.8967 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:8 loss:1.1743 accuracy:0.9319 precision:0.9319 recall:0.9319 f1:0.9319\n",
      "[sklearn_metrics] Epoch:8 loss:1.3365 accuracy:0.9326 precision:0.9326 recall:0.9326 f1:0.9326\n",
      "[sklearn_metrics] Epoch:8 loss:1.5259 accuracy:0.9306 precision:0.9306 recall:0.9306 f1:0.9306\n",
      "[sklearn_metrics] Epoch:8 loss:1.6852 accuracy:0.9281 precision:0.9281 recall:0.9281 f1:0.9281\n",
      "[sklearn_metrics] Epoch:8 loss:1.8239 accuracy:0.9311 precision:0.9311 recall:0.9311 f1:0.9311\n",
      "[sklearn_metrics] Epoch:8 loss:1.9811 accuracy:0.9310 precision:0.9310 recall:0.9310 f1:0.9310\n",
      "[sklearn_metrics] Epoch:8 loss:2.1144 accuracy:0.9327 precision:0.9327 recall:0.9327 f1:0.9327\n",
      "[sklearn_metrics] Epoch:8 loss:2.2104 accuracy:0.9329 precision:0.9329 recall:0.9329 f1:0.9329\n",
      "[sklearn_metrics] Epoch:9 loss:0.2849 accuracy:0.8906 precision:0.8906 recall:0.8906 f1:0.8906\n",
      "[sklearn_metrics] Epoch:9 loss:0.4728 accuracy:0.8945 precision:0.8945 recall:0.8945 f1:0.8945\n",
      "[sklearn_metrics] Epoch:9 loss:0.6735 accuracy:0.9010 precision:0.9010 recall:0.9010 f1:0.9010\n",
      "[sklearn_metrics] Epoch:9 loss:0.7847 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:9 loss:0.9410 accuracy:0.9172 precision:0.9172 recall:0.9172 f1:0.9172\n",
      "[sklearn_metrics] Epoch:9 loss:1.0533 accuracy:0.9206 precision:0.9206 recall:0.9206 f1:0.9206\n",
      "[sklearn_metrics] Epoch:9 loss:1.2019 accuracy:0.9208 precision:0.9208 recall:0.9208 f1:0.9208\n",
      "[sklearn_metrics] Epoch:9 loss:1.4260 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:9 loss:1.5943 accuracy:0.9227 precision:0.9227 recall:0.9227 f1:0.9227\n",
      "[sklearn_metrics] Epoch:9 loss:1.7976 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:9 loss:1.9208 accuracy:0.9240 precision:0.9240 recall:0.9240 f1:0.9240\n",
      "[sklearn_metrics] Epoch:9 loss:2.1034 accuracy:0.9232 precision:0.9232 recall:0.9232 f1:0.9232\n",
      "[sklearn_metrics] Epoch:9 loss:2.3046 accuracy:0.9237 precision:0.9237 recall:0.9237 f1:0.9237\n",
      "[sklearn_metrics] Epoch:9 loss:2.4073 accuracy:0.9247 precision:0.9247 recall:0.9247 f1:0.9247\n",
      "[sklearn_metrics] Epoch:10 loss:0.1974 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:10 loss:0.3037 accuracy:0.9336 precision:0.9336 recall:0.9336 f1:0.9336\n",
      "[sklearn_metrics] Epoch:10 loss:0.3683 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:10 loss:0.5026 accuracy:0.9414 precision:0.9414 recall:0.9414 f1:0.9414\n",
      "[sklearn_metrics] Epoch:10 loss:0.6767 accuracy:0.9391 precision:0.9391 recall:0.9391 f1:0.9391\n",
      "[sklearn_metrics] Epoch:10 loss:0.8490 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:10 loss:0.9601 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:10 loss:1.1187 accuracy:0.9346 precision:0.9346 recall:0.9346 f1:0.9346\n",
      "[sklearn_metrics] Epoch:10 loss:1.3080 accuracy:0.9332 precision:0.9332 recall:0.9332 f1:0.9332\n",
      "[sklearn_metrics] Epoch:10 loss:1.4899 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:10 loss:1.7371 accuracy:0.9276 precision:0.9276 recall:0.9276 f1:0.9276\n",
      "[sklearn_metrics] Epoch:10 loss:1.8840 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:10 loss:1.9659 accuracy:0.9321 precision:0.9321 recall:0.9321 f1:0.9321\n",
      "[sklearn_metrics] Epoch:10 loss:2.1873 accuracy:0.9300 precision:0.9300 recall:0.9300 f1:0.9300\n",
      "[sklearn_metrics] Epoch:11 loss:0.1451 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:11 loss:0.2656 accuracy:0.9648 precision:0.9648 recall:0.9648 f1:0.9648\n",
      "[sklearn_metrics] Epoch:11 loss:0.3622 accuracy:0.9583 precision:0.9583 recall:0.9583 f1:0.9583\n",
      "[sklearn_metrics] Epoch:11 loss:0.5027 accuracy:0.9512 precision:0.9512 recall:0.9512 f1:0.9512\n",
      "[sklearn_metrics] Epoch:11 loss:0.6422 accuracy:0.9437 precision:0.9437 recall:0.9437 f1:0.9437\n",
      "[sklearn_metrics] Epoch:11 loss:0.7507 accuracy:0.9427 precision:0.9427 recall:0.9427 f1:0.9427\n",
      "[sklearn_metrics] Epoch:11 loss:0.8410 accuracy:0.9475 precision:0.9475 recall:0.9475 f1:0.9475\n",
      "[sklearn_metrics] Epoch:11 loss:0.9683 accuracy:0.9473 precision:0.9473 recall:0.9473 f1:0.9473\n",
      "[sklearn_metrics] Epoch:11 loss:1.1872 accuracy:0.9418 precision:0.9418 recall:0.9418 f1:0.9418\n",
      "[sklearn_metrics] Epoch:11 loss:1.4017 accuracy:0.9391 precision:0.9391 recall:0.9391 f1:0.9391\n",
      "[sklearn_metrics] Epoch:11 loss:1.5337 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:11 loss:1.7473 accuracy:0.9349 precision:0.9349 recall:0.9349 f1:0.9349\n",
      "[sklearn_metrics] Epoch:11 loss:1.9438 accuracy:0.9333 precision:0.9333 recall:0.9333 f1:0.9333\n",
      "[sklearn_metrics] Epoch:11 loss:1.9830 accuracy:0.9341 precision:0.9341 recall:0.9341 f1:0.9341\n",
      "[sklearn_metrics] Epoch:12 loss:0.0865 accuracy:0.9531 precision:0.9531 recall:0.9531 f1:0.9531\n",
      "[sklearn_metrics] Epoch:12 loss:0.2631 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:12 loss:0.4051 accuracy:0.9427 precision:0.9427 recall:0.9427 f1:0.9427\n",
      "[sklearn_metrics] Epoch:12 loss:0.5975 accuracy:0.9414 precision:0.9414 recall:0.9414 f1:0.9414\n",
      "[sklearn_metrics] Epoch:12 loss:0.7668 accuracy:0.9328 precision:0.9328 recall:0.9328 f1:0.9328\n",
      "[sklearn_metrics] Epoch:12 loss:0.8959 accuracy:0.9362 precision:0.9362 recall:0.9362 f1:0.9362\n",
      "[sklearn_metrics] Epoch:12 loss:1.0339 accuracy:0.9397 precision:0.9397 recall:0.9397 f1:0.9397\n",
      "[sklearn_metrics] Epoch:12 loss:1.2121 accuracy:0.9395 precision:0.9395 recall:0.9395 f1:0.9395\n",
      "[sklearn_metrics] Epoch:12 loss:1.3193 accuracy:0.9427 precision:0.9427 recall:0.9427 f1:0.9427\n",
      "[sklearn_metrics] Epoch:12 loss:1.4512 accuracy:0.9437 precision:0.9437 recall:0.9437 f1:0.9437\n",
      "[sklearn_metrics] Epoch:12 loss:1.6511 accuracy:0.9403 precision:0.9403 recall:0.9403 f1:0.9403\n",
      "[sklearn_metrics] Epoch:12 loss:2.0703 accuracy:0.9362 precision:0.9362 recall:0.9362 f1:0.9362\n",
      "[sklearn_metrics] Epoch:12 loss:2.2603 accuracy:0.9351 precision:0.9351 recall:0.9351 f1:0.9351\n",
      "[sklearn_metrics] Epoch:12 loss:2.7068 accuracy:0.9329 precision:0.9329 recall:0.9329 f1:0.9329\n",
      "[sklearn_metrics] Epoch:13 loss:0.1211 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:13 loss:0.2345 accuracy:0.9414 precision:0.9414 recall:0.9414 f1:0.9414\n",
      "[sklearn_metrics] Epoch:13 loss:0.4637 accuracy:0.9245 precision:0.9245 recall:0.9245 f1:0.9245\n",
      "[sklearn_metrics] Epoch:13 loss:0.6159 accuracy:0.9258 precision:0.9258 recall:0.9258 f1:0.9258\n",
      "[sklearn_metrics] Epoch:13 loss:0.8205 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:13 loss:1.1019 accuracy:0.9115 precision:0.9115 recall:0.9115 f1:0.9115\n",
      "[sklearn_metrics] Epoch:13 loss:1.2736 accuracy:0.9196 precision:0.9196 recall:0.9196 f1:0.9196\n",
      "[sklearn_metrics] Epoch:13 loss:1.4717 accuracy:0.9180 precision:0.9180 recall:0.9180 f1:0.9180\n",
      "[sklearn_metrics] Epoch:13 loss:1.6227 accuracy:0.9193 precision:0.9193 recall:0.9193 f1:0.9193\n",
      "[sklearn_metrics] Epoch:13 loss:1.8406 accuracy:0.9187 precision:0.9187 recall:0.9187 f1:0.9187\n",
      "[sklearn_metrics] Epoch:13 loss:2.0692 accuracy:0.9183 precision:0.9183 recall:0.9183 f1:0.9183\n",
      "[sklearn_metrics] Epoch:13 loss:2.3010 accuracy:0.9167 precision:0.9167 recall:0.9167 f1:0.9167\n",
      "[sklearn_metrics] Epoch:13 loss:2.4282 accuracy:0.9201 precision:0.9201 recall:0.9201 f1:0.9201\n",
      "[sklearn_metrics] Epoch:13 loss:2.6656 accuracy:0.9194 precision:0.9194 recall:0.9194 f1:0.9194\n",
      "[sklearn_metrics] Epoch:14 loss:0.1462 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:14 loss:0.2922 accuracy:0.9336 precision:0.9336 recall:0.9336 f1:0.9336\n",
      "[sklearn_metrics] Epoch:14 loss:0.5683 accuracy:0.9089 precision:0.9089 recall:0.9089 f1:0.9089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn_metrics] Epoch:14 loss:0.7147 accuracy:0.9121 precision:0.9121 recall:0.9121 f1:0.9121\n",
      "[sklearn_metrics] Epoch:14 loss:0.8733 accuracy:0.9172 precision:0.9172 recall:0.9172 f1:0.9172\n",
      "[sklearn_metrics] Epoch:14 loss:1.0873 accuracy:0.9167 precision:0.9167 recall:0.9167 f1:0.9167\n",
      "[sklearn_metrics] Epoch:14 loss:1.2588 accuracy:0.9174 precision:0.9174 recall:0.9174 f1:0.9174\n",
      "[sklearn_metrics] Epoch:14 loss:1.3849 accuracy:0.9199 precision:0.9199 recall:0.9199 f1:0.9199\n",
      "[sklearn_metrics] Epoch:14 loss:1.5148 accuracy:0.9236 precision:0.9236 recall:0.9236 f1:0.9236\n",
      "[sklearn_metrics] Epoch:14 loss:1.6510 accuracy:0.9250 precision:0.9250 recall:0.9250 f1:0.9250\n",
      "[sklearn_metrics] Epoch:14 loss:1.8423 accuracy:0.9261 precision:0.9261 recall:0.9261 f1:0.9261\n",
      "[sklearn_metrics] Epoch:14 loss:1.9652 accuracy:0.9284 precision:0.9284 recall:0.9284 f1:0.9284\n",
      "[sklearn_metrics] Epoch:14 loss:2.1301 accuracy:0.9285 precision:0.9285 recall:0.9285 f1:0.9285\n",
      "[sklearn_metrics] Epoch:14 loss:2.2604 accuracy:0.9282 precision:0.9282 recall:0.9282 f1:0.9282\n",
      "[sklearn_metrics] Epoch:15 loss:0.1619 accuracy:0.9062 precision:0.9062 recall:0.9062 f1:0.9062\n",
      "[sklearn_metrics] Epoch:15 loss:0.3095 accuracy:0.9258 precision:0.9258 recall:0.9258 f1:0.9258\n",
      "[sklearn_metrics] Epoch:15 loss:0.4218 accuracy:0.9401 precision:0.9401 recall:0.9401 f1:0.9401\n",
      "[sklearn_metrics] Epoch:15 loss:0.5088 accuracy:0.9492 precision:0.9492 recall:0.9492 f1:0.9492\n",
      "[sklearn_metrics] Epoch:15 loss:0.7646 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:15 loss:0.9125 accuracy:0.9427 precision:0.9427 recall:0.9427 f1:0.9427\n",
      "[sklearn_metrics] Epoch:15 loss:1.0415 accuracy:0.9431 precision:0.9431 recall:0.9431 f1:0.9431\n",
      "[sklearn_metrics] Epoch:15 loss:1.1627 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:15 loss:1.3073 accuracy:0.9436 precision:0.9436 recall:0.9436 f1:0.9436\n",
      "[sklearn_metrics] Epoch:15 loss:1.3935 accuracy:0.9437 precision:0.9437 recall:0.9437 f1:0.9437\n",
      "[sklearn_metrics] Epoch:15 loss:1.5447 accuracy:0.9403 precision:0.9403 recall:0.9403 f1:0.9403\n",
      "[sklearn_metrics] Epoch:15 loss:1.6979 accuracy:0.9408 precision:0.9408 recall:0.9408 f1:0.9408\n",
      "[sklearn_metrics] Epoch:15 loss:1.8081 accuracy:0.9429 precision:0.9429 recall:0.9429 f1:0.9429\n",
      "[sklearn_metrics] Epoch:15 loss:2.0149 accuracy:0.9424 precision:0.9424 recall:0.9424 f1:0.9424\n",
      "[sklearn_metrics] Epoch:16 loss:0.0852 accuracy:0.9688 precision:0.9688 recall:0.9688 f1:0.9688\n",
      "[sklearn_metrics] Epoch:16 loss:0.1603 accuracy:0.9688 precision:0.9688 recall:0.9688 f1:0.9688\n",
      "[sklearn_metrics] Epoch:16 loss:0.4372 accuracy:0.9479 precision:0.9479 recall:0.9479 f1:0.9479\n",
      "[sklearn_metrics] Epoch:16 loss:0.5873 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:16 loss:0.7155 accuracy:0.9469 precision:0.9469 recall:0.9469 f1:0.9469\n",
      "[sklearn_metrics] Epoch:16 loss:0.9186 accuracy:0.9401 precision:0.9401 recall:0.9401 f1:0.9401\n",
      "[sklearn_metrics] Epoch:16 loss:1.0464 accuracy:0.9386 precision:0.9386 recall:0.9386 f1:0.9386\n",
      "[sklearn_metrics] Epoch:16 loss:1.1888 accuracy:0.9355 precision:0.9355 recall:0.9355 f1:0.9355\n",
      "[sklearn_metrics] Epoch:16 loss:1.3870 accuracy:0.9306 precision:0.9306 recall:0.9306 f1:0.9306\n",
      "[sklearn_metrics] Epoch:16 loss:1.5355 accuracy:0.9328 precision:0.9328 recall:0.9328 f1:0.9328\n",
      "[sklearn_metrics] Epoch:16 loss:1.6534 accuracy:0.9332 precision:0.9332 recall:0.9332 f1:0.9332\n",
      "[sklearn_metrics] Epoch:16 loss:1.8301 accuracy:0.9316 precision:0.9316 recall:0.9316 f1:0.9316\n",
      "[sklearn_metrics] Epoch:16 loss:1.9559 accuracy:0.9315 precision:0.9315 recall:0.9315 f1:0.9315\n",
      "[sklearn_metrics] Epoch:16 loss:2.0204 accuracy:0.9318 precision:0.9318 recall:0.9318 f1:0.9318\n",
      "[sklearn_metrics] Epoch:17 loss:0.0737 accuracy:0.9844 precision:0.9844 recall:0.9844 f1:0.9844\n",
      "[sklearn_metrics] Epoch:17 loss:0.2347 accuracy:0.9570 precision:0.9570 recall:0.9570 f1:0.9570\n",
      "[sklearn_metrics] Epoch:17 loss:0.3890 accuracy:0.9505 precision:0.9505 recall:0.9505 f1:0.9505\n",
      "[sklearn_metrics] Epoch:17 loss:0.4920 accuracy:0.9531 precision:0.9531 recall:0.9531 f1:0.9531\n",
      "[sklearn_metrics] Epoch:17 loss:0.6936 accuracy:0.9484 precision:0.9484 recall:0.9484 f1:0.9484\n",
      "[sklearn_metrics] Epoch:17 loss:0.8633 accuracy:0.9440 precision:0.9440 recall:0.9440 f1:0.9440\n",
      "[sklearn_metrics] Epoch:17 loss:0.9809 accuracy:0.9431 precision:0.9431 recall:0.9431 f1:0.9431\n",
      "[sklearn_metrics] Epoch:17 loss:1.0915 accuracy:0.9443 precision:0.9443 recall:0.9443 f1:0.9443\n",
      "[sklearn_metrics] Epoch:17 loss:1.2343 accuracy:0.9427 precision:0.9427 recall:0.9427 f1:0.9427\n",
      "[sklearn_metrics] Epoch:17 loss:1.3455 accuracy:0.9430 precision:0.9430 recall:0.9430 f1:0.9430\n",
      "[sklearn_metrics] Epoch:17 loss:1.4735 accuracy:0.9418 precision:0.9418 recall:0.9418 f1:0.9418\n",
      "[sklearn_metrics] Epoch:17 loss:1.6919 accuracy:0.9395 precision:0.9395 recall:0.9395 f1:0.9395\n",
      "[sklearn_metrics] Epoch:17 loss:1.8191 accuracy:0.9405 precision:0.9405 recall:0.9405 f1:0.9405\n",
      "[sklearn_metrics] Epoch:17 loss:1.9524 accuracy:0.9406 precision:0.9406 recall:0.9406 f1:0.9406\n",
      "[sklearn_metrics] Epoch:18 loss:0.1161 accuracy:0.9609 precision:0.9609 recall:0.9609 f1:0.9609\n",
      "[sklearn_metrics] Epoch:18 loss:0.3129 accuracy:0.9414 precision:0.9414 recall:0.9414 f1:0.9414\n",
      "[sklearn_metrics] Epoch:18 loss:0.4660 accuracy:0.9427 precision:0.9427 recall:0.9427 f1:0.9427\n",
      "[sklearn_metrics] Epoch:18 loss:0.5686 accuracy:0.9492 precision:0.9492 recall:0.9492 f1:0.9492\n",
      "[sklearn_metrics] Epoch:18 loss:0.6922 accuracy:0.9484 precision:0.9484 recall:0.9484 f1:0.9484\n",
      "[sklearn_metrics] Epoch:18 loss:0.8163 accuracy:0.9505 precision:0.9505 recall:0.9505 f1:0.9505\n",
      "[sklearn_metrics] Epoch:18 loss:0.8964 accuracy:0.9509 precision:0.9509 recall:0.9509 f1:0.9509\n",
      "[sklearn_metrics] Epoch:18 loss:0.9911 accuracy:0.9512 precision:0.9512 recall:0.9512 f1:0.9512\n",
      "[sklearn_metrics] Epoch:18 loss:1.1856 accuracy:0.9488 precision:0.9488 recall:0.9488 f1:0.9488\n",
      "[sklearn_metrics] Epoch:18 loss:1.3347 accuracy:0.9484 precision:0.9484 recall:0.9484 f1:0.9484\n",
      "[sklearn_metrics] Epoch:18 loss:1.4787 accuracy:0.9467 precision:0.9467 recall:0.9467 f1:0.9467\n",
      "[sklearn_metrics] Epoch:18 loss:1.6117 accuracy:0.9466 precision:0.9466 recall:0.9466 f1:0.9466\n",
      "[sklearn_metrics] Epoch:18 loss:1.7032 accuracy:0.9471 precision:0.9471 recall:0.9471 f1:0.9471\n",
      "[sklearn_metrics] Epoch:18 loss:1.9544 accuracy:0.9465 precision:0.9465 recall:0.9465 f1:0.9465\n",
      "[sklearn_metrics] Epoch:19 loss:0.1131 accuracy:0.9531 precision:0.9531 recall:0.9531 f1:0.9531\n",
      "[sklearn_metrics] Epoch:19 loss:0.1836 accuracy:0.9609 precision:0.9609 recall:0.9609 f1:0.9609\n",
      "[sklearn_metrics] Epoch:19 loss:0.7040 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:19 loss:0.8511 accuracy:0.9414 precision:0.9414 recall:0.9414 f1:0.9414\n",
      "[sklearn_metrics] Epoch:19 loss:0.9608 accuracy:0.9437 precision:0.9437 recall:0.9437 f1:0.9437\n",
      "[sklearn_metrics] Epoch:19 loss:1.0696 accuracy:0.9466 precision:0.9466 recall:0.9466 f1:0.9466\n",
      "[sklearn_metrics] Epoch:19 loss:1.2148 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:19 loss:1.3238 accuracy:0.9443 precision:0.9443 recall:0.9443 f1:0.9443\n",
      "[sklearn_metrics] Epoch:19 loss:1.4416 accuracy:0.9462 precision:0.9462 recall:0.9462 f1:0.9462\n",
      "[sklearn_metrics] Epoch:19 loss:1.5948 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:19 loss:1.7418 accuracy:0.9482 precision:0.9482 recall:0.9482 f1:0.9482\n",
      "[sklearn_metrics] Epoch:19 loss:1.9682 accuracy:0.9466 precision:0.9466 recall:0.9466 f1:0.9466\n",
      "[sklearn_metrics] Epoch:19 loss:2.0984 accuracy:0.9465 precision:0.9465 recall:0.9465 f1:0.9465\n",
      "[sklearn_metrics] Epoch:19 loss:2.2920 accuracy:0.9459 precision:0.9459 recall:0.9459 f1:0.9459\n",
      "[sklearn_metrics] Epoch:20 loss:0.1518 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:20 loss:0.2403 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:20 loss:0.3722 accuracy:0.9427 precision:0.9427 recall:0.9427 f1:0.9427\n",
      "[sklearn_metrics] Epoch:20 loss:0.5201 accuracy:0.9414 precision:0.9414 recall:0.9414 f1:0.9414\n",
      "[sklearn_metrics] Epoch:20 loss:0.6336 accuracy:0.9437 precision:0.9437 recall:0.9437 f1:0.9437\n",
      "[sklearn_metrics] Epoch:20 loss:0.7728 accuracy:0.9414 precision:0.9414 recall:0.9414 f1:0.9414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn_metrics] Epoch:20 loss:0.8998 accuracy:0.9408 precision:0.9408 recall:0.9408 f1:0.9408\n",
      "[sklearn_metrics] Epoch:20 loss:0.9918 accuracy:0.9424 precision:0.9424 recall:0.9424 f1:0.9424\n",
      "[sklearn_metrics] Epoch:20 loss:1.0640 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:20 loss:1.1852 accuracy:0.9469 precision:0.9469 recall:0.9469 f1:0.9469\n",
      "[sklearn_metrics] Epoch:20 loss:1.2672 accuracy:0.9489 precision:0.9489 recall:0.9489 f1:0.9489\n",
      "[sklearn_metrics] Epoch:20 loss:1.4186 accuracy:0.9486 precision:0.9486 recall:0.9486 f1:0.9486\n",
      "[sklearn_metrics] Epoch:20 loss:1.5783 accuracy:0.9477 precision:0.9477 recall:0.9477 f1:0.9477\n",
      "[sklearn_metrics] Epoch:20 loss:1.6427 accuracy:0.9482 precision:0.9482 recall:0.9482 f1:0.9482\n",
      "[sklearn_metrics] Epoch:21 loss:0.1601 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:21 loss:0.2857 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:21 loss:0.4045 accuracy:0.9479 precision:0.9479 recall:0.9479 f1:0.9479\n",
      "[sklearn_metrics] Epoch:21 loss:0.4967 accuracy:0.9551 precision:0.9551 recall:0.9551 f1:0.9551\n",
      "[sklearn_metrics] Epoch:21 loss:0.5564 accuracy:0.9594 precision:0.9594 recall:0.9594 f1:0.9594\n",
      "[sklearn_metrics] Epoch:21 loss:0.6621 accuracy:0.9609 precision:0.9609 recall:0.9609 f1:0.9609\n",
      "[sklearn_metrics] Epoch:21 loss:0.7800 accuracy:0.9609 precision:0.9609 recall:0.9609 f1:0.9609\n",
      "[sklearn_metrics] Epoch:21 loss:0.8704 accuracy:0.9619 precision:0.9619 recall:0.9619 f1:0.9619\n",
      "[sklearn_metrics] Epoch:21 loss:1.0212 accuracy:0.9601 precision:0.9601 recall:0.9601 f1:0.9601\n",
      "[sklearn_metrics] Epoch:21 loss:1.1609 accuracy:0.9570 precision:0.9570 recall:0.9570 f1:0.9570\n",
      "[sklearn_metrics] Epoch:21 loss:1.2413 accuracy:0.9574 precision:0.9574 recall:0.9574 f1:0.9574\n",
      "[sklearn_metrics] Epoch:21 loss:1.4062 accuracy:0.9544 precision:0.9544 recall:0.9544 f1:0.9544\n",
      "[sklearn_metrics] Epoch:21 loss:1.5271 accuracy:0.9549 precision:0.9549 recall:0.9549 f1:0.9549\n",
      "[sklearn_metrics] Epoch:21 loss:1.5976 accuracy:0.9553 precision:0.9553 recall:0.9553 f1:0.9553\n",
      "[sklearn_metrics] Epoch:22 loss:0.0957 accuracy:0.9688 precision:0.9688 recall:0.9688 f1:0.9688\n",
      "[sklearn_metrics] Epoch:22 loss:0.1616 accuracy:0.9766 precision:0.9766 recall:0.9766 f1:0.9766\n",
      "[sklearn_metrics] Epoch:22 loss:0.2662 accuracy:0.9635 precision:0.9635 recall:0.9635 f1:0.9635\n",
      "[sklearn_metrics] Epoch:22 loss:0.4078 accuracy:0.9590 precision:0.9590 recall:0.9590 f1:0.9590\n",
      "[sklearn_metrics] Epoch:22 loss:0.5223 accuracy:0.9563 precision:0.9563 recall:0.9563 f1:0.9563\n",
      "[sklearn_metrics] Epoch:22 loss:0.6541 accuracy:0.9531 precision:0.9531 recall:0.9531 f1:0.9531\n",
      "[sklearn_metrics] Epoch:22 loss:0.7564 accuracy:0.9520 precision:0.9520 recall:0.9520 f1:0.9520\n",
      "[sklearn_metrics] Epoch:22 loss:0.8399 accuracy:0.9541 precision:0.9541 recall:0.9541 f1:0.9541\n",
      "[sklearn_metrics] Epoch:22 loss:0.9953 accuracy:0.9540 precision:0.9540 recall:0.9540 f1:0.9540\n",
      "[sklearn_metrics] Epoch:22 loss:1.1091 accuracy:0.9547 precision:0.9547 recall:0.9547 f1:0.9547\n",
      "[sklearn_metrics] Epoch:22 loss:1.2302 accuracy:0.9545 precision:0.9545 recall:0.9545 f1:0.9545\n",
      "[sklearn_metrics] Epoch:22 loss:1.4069 accuracy:0.9505 precision:0.9505 recall:0.9505 f1:0.9505\n",
      "[sklearn_metrics] Epoch:22 loss:1.4773 accuracy:0.9513 precision:0.9513 recall:0.9513 f1:0.9513\n",
      "[sklearn_metrics] Epoch:22 loss:1.6540 accuracy:0.9500 precision:0.9500 recall:0.9500 f1:0.9500\n",
      "[sklearn_metrics] Epoch:23 loss:0.0834 accuracy:0.9688 precision:0.9688 recall:0.9688 f1:0.9688\n",
      "[sklearn_metrics] Epoch:23 loss:0.1997 accuracy:0.9648 precision:0.9648 recall:0.9648 f1:0.9648\n",
      "[sklearn_metrics] Epoch:23 loss:0.3020 accuracy:0.9583 precision:0.9583 recall:0.9583 f1:0.9583\n",
      "[sklearn_metrics] Epoch:23 loss:0.4272 accuracy:0.9570 precision:0.9570 recall:0.9570 f1:0.9570\n",
      "[sklearn_metrics] Epoch:23 loss:0.5116 accuracy:0.9563 precision:0.9563 recall:0.9563 f1:0.9563\n",
      "[sklearn_metrics] Epoch:23 loss:0.6241 accuracy:0.9557 precision:0.9557 recall:0.9557 f1:0.9557\n",
      "[sklearn_metrics] Epoch:23 loss:0.7523 accuracy:0.9542 precision:0.9542 recall:0.9542 f1:0.9542\n",
      "[sklearn_metrics] Epoch:23 loss:0.8686 accuracy:0.9531 precision:0.9531 recall:0.9531 f1:0.9531\n",
      "[sklearn_metrics] Epoch:23 loss:0.9873 accuracy:0.9514 precision:0.9514 recall:0.9514 f1:0.9514\n",
      "[sklearn_metrics] Epoch:23 loss:1.1033 accuracy:0.9508 precision:0.9508 recall:0.9508 f1:0.9508\n",
      "[sklearn_metrics] Epoch:23 loss:1.2388 accuracy:0.9496 precision:0.9496 recall:0.9496 f1:0.9496\n",
      "[sklearn_metrics] Epoch:23 loss:1.3981 accuracy:0.9473 precision:0.9473 recall:0.9473 f1:0.9473\n",
      "[sklearn_metrics] Epoch:23 loss:1.5103 accuracy:0.9471 precision:0.9471 recall:0.9471 f1:0.9471\n",
      "[sklearn_metrics] Epoch:23 loss:1.6231 accuracy:0.9471 precision:0.9471 recall:0.9471 f1:0.9471\n",
      "[sklearn_metrics] Epoch:24 loss:0.1277 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:24 loss:0.2002 accuracy:0.9531 precision:0.9531 recall:0.9531 f1:0.9531\n",
      "[sklearn_metrics] Epoch:24 loss:0.2862 accuracy:0.9609 precision:0.9609 recall:0.9609 f1:0.9609\n",
      "[sklearn_metrics] Epoch:24 loss:0.3725 accuracy:0.9629 precision:0.9629 recall:0.9629 f1:0.9629\n",
      "[sklearn_metrics] Epoch:24 loss:0.5006 accuracy:0.9609 precision:0.9609 recall:0.9609 f1:0.9609\n",
      "[sklearn_metrics] Epoch:24 loss:0.6070 accuracy:0.9609 precision:0.9609 recall:0.9609 f1:0.9609\n",
      "[sklearn_metrics] Epoch:24 loss:0.6830 accuracy:0.9654 precision:0.9654 recall:0.9654 f1:0.9654\n",
      "[sklearn_metrics] Epoch:24 loss:0.7383 accuracy:0.9668 precision:0.9668 recall:0.9668 f1:0.9668\n",
      "[sklearn_metrics] Epoch:24 loss:0.8022 accuracy:0.9688 precision:0.9688 recall:0.9688 f1:0.9688\n",
      "[sklearn_metrics] Epoch:24 loss:0.8586 accuracy:0.9688 precision:0.9688 recall:0.9688 f1:0.9688\n",
      "[sklearn_metrics] Epoch:24 loss:1.0056 accuracy:0.9666 precision:0.9666 recall:0.9666 f1:0.9666\n",
      "[sklearn_metrics] Epoch:24 loss:1.0683 accuracy:0.9668 precision:0.9668 recall:0.9668 f1:0.9668\n",
      "[sklearn_metrics] Epoch:24 loss:1.1516 accuracy:0.9663 precision:0.9663 recall:0.9663 f1:0.9663\n",
      "[sklearn_metrics] Epoch:24 loss:1.2328 accuracy:0.9665 precision:0.9665 recall:0.9665 f1:0.9665\n",
      "[sklearn_metrics] Epoch:25 loss:0.0850 accuracy:0.9688 precision:0.9688 recall:0.9688 f1:0.9688\n",
      "[sklearn_metrics] Epoch:25 loss:0.2156 accuracy:0.9570 precision:0.9570 recall:0.9570 f1:0.9570\n",
      "[sklearn_metrics] Epoch:25 loss:0.2957 accuracy:0.9583 precision:0.9583 recall:0.9583 f1:0.9583\n",
      "[sklearn_metrics] Epoch:25 loss:0.3797 accuracy:0.9609 precision:0.9609 recall:0.9609 f1:0.9609\n",
      "[sklearn_metrics] Epoch:25 loss:0.4491 accuracy:0.9641 precision:0.9641 recall:0.9641 f1:0.9641\n",
      "[sklearn_metrics] Epoch:25 loss:0.5252 accuracy:0.9622 precision:0.9622 recall:0.9622 f1:0.9622\n",
      "[sklearn_metrics] Epoch:25 loss:0.6233 accuracy:0.9587 precision:0.9587 recall:0.9587 f1:0.9587\n",
      "[sklearn_metrics] Epoch:25 loss:0.7630 accuracy:0.9561 precision:0.9561 recall:0.9561 f1:0.9561\n",
      "[sklearn_metrics] Epoch:25 loss:0.8431 accuracy:0.9557 precision:0.9557 recall:0.9557 f1:0.9557\n",
      "[sklearn_metrics] Epoch:25 loss:0.8912 accuracy:0.9578 precision:0.9578 recall:0.9578 f1:0.9578\n",
      "[sklearn_metrics] Epoch:25 loss:0.9997 accuracy:0.9567 precision:0.9567 recall:0.9567 f1:0.9567\n",
      "[sklearn_metrics] Epoch:25 loss:1.0707 accuracy:0.9590 precision:0.9590 recall:0.9590 f1:0.9590\n",
      "[sklearn_metrics] Epoch:25 loss:1.2141 accuracy:0.9567 precision:0.9567 recall:0.9567 f1:0.9567\n",
      "[sklearn_metrics] Epoch:25 loss:1.3354 accuracy:0.9553 precision:0.9553 recall:0.9553 f1:0.9553\n",
      "[sklearn_metrics] Epoch:26 loss:0.1595 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:26 loss:0.2632 accuracy:0.9336 precision:0.9336 recall:0.9336 f1:0.9336\n",
      "[sklearn_metrics] Epoch:26 loss:0.4260 accuracy:0.9323 precision:0.9323 recall:0.9323 f1:0.9323\n",
      "[sklearn_metrics] Epoch:26 loss:0.4767 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:26 loss:0.5745 accuracy:0.9469 precision:0.9469 recall:0.9469 f1:0.9469\n",
      "[sklearn_metrics] Epoch:26 loss:0.6924 accuracy:0.9479 precision:0.9479 recall:0.9479 f1:0.9479\n",
      "[sklearn_metrics] Epoch:26 loss:0.8031 accuracy:0.9498 precision:0.9498 recall:0.9498 f1:0.9498\n",
      "[sklearn_metrics] Epoch:26 loss:0.9459 accuracy:0.9492 precision:0.9492 recall:0.9492 f1:0.9492\n",
      "[sklearn_metrics] Epoch:26 loss:1.0959 accuracy:0.9462 precision:0.9462 recall:0.9462 f1:0.9462\n",
      "[sklearn_metrics] Epoch:26 loss:1.2013 accuracy:0.9469 precision:0.9469 recall:0.9469 f1:0.9469\n",
      "[sklearn_metrics] Epoch:26 loss:1.3345 accuracy:0.9467 precision:0.9467 recall:0.9467 f1:0.9467\n",
      "[sklearn_metrics] Epoch:26 loss:1.4594 accuracy:0.9466 precision:0.9466 recall:0.9466 f1:0.9466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn_metrics] Epoch:26 loss:1.5270 accuracy:0.9489 precision:0.9489 recall:0.9489 f1:0.9489\n",
      "[sklearn_metrics] Epoch:26 loss:1.6094 accuracy:0.9488 precision:0.9488 recall:0.9488 f1:0.9488\n",
      "[sklearn_metrics] Epoch:27 loss:0.1329 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:27 loss:0.2222 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:27 loss:0.3506 accuracy:0.9505 precision:0.9505 recall:0.9505 f1:0.9505\n",
      "[sklearn_metrics] Epoch:27 loss:0.5086 accuracy:0.9414 precision:0.9414 recall:0.9414 f1:0.9414\n",
      "[sklearn_metrics] Epoch:27 loss:0.5944 accuracy:0.9484 precision:0.9484 recall:0.9484 f1:0.9484\n",
      "[sklearn_metrics] Epoch:27 loss:0.6977 accuracy:0.9479 precision:0.9479 recall:0.9479 f1:0.9479\n",
      "[sklearn_metrics] Epoch:27 loss:0.8189 accuracy:0.9442 precision:0.9442 recall:0.9442 f1:0.9442\n",
      "[sklearn_metrics] Epoch:27 loss:0.9120 accuracy:0.9463 precision:0.9463 recall:0.9463 f1:0.9463\n",
      "[sklearn_metrics] Epoch:27 loss:1.0853 accuracy:0.9401 precision:0.9401 recall:0.9401 f1:0.9401\n",
      "[sklearn_metrics] Epoch:27 loss:1.2031 accuracy:0.9398 precision:0.9398 recall:0.9398 f1:0.9398\n",
      "[sklearn_metrics] Epoch:27 loss:1.2515 accuracy:0.9425 precision:0.9425 recall:0.9425 f1:0.9425\n",
      "[sklearn_metrics] Epoch:27 loss:1.3447 accuracy:0.9447 precision:0.9447 recall:0.9447 f1:0.9447\n",
      "[sklearn_metrics] Epoch:27 loss:1.4177 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:27 loss:1.4634 accuracy:0.9465 precision:0.9465 recall:0.9465 f1:0.9465\n",
      "[sklearn_metrics] Epoch:28 loss:0.0690 accuracy:0.9609 precision:0.9609 recall:0.9609 f1:0.9609\n",
      "[sklearn_metrics] Epoch:28 loss:0.1356 accuracy:0.9570 precision:0.9570 recall:0.9570 f1:0.9570\n",
      "[sklearn_metrics] Epoch:28 loss:0.2040 accuracy:0.9583 precision:0.9583 recall:0.9583 f1:0.9583\n",
      "[sklearn_metrics] Epoch:28 loss:0.3460 accuracy:0.9551 precision:0.9551 recall:0.9551 f1:0.9551\n",
      "[sklearn_metrics] Epoch:28 loss:0.4494 accuracy:0.9547 precision:0.9547 recall:0.9547 f1:0.9547\n",
      "[sklearn_metrics] Epoch:28 loss:0.5063 accuracy:0.9609 precision:0.9609 recall:0.9609 f1:0.9609\n",
      "[sklearn_metrics] Epoch:28 loss:0.7364 accuracy:0.9531 precision:0.9531 recall:0.9531 f1:0.9531\n",
      "[sklearn_metrics] Epoch:28 loss:0.8976 accuracy:0.9502 precision:0.9502 recall:0.9502 f1:0.9502\n",
      "[sklearn_metrics] Epoch:28 loss:1.0177 accuracy:0.9488 precision:0.9488 recall:0.9488 f1:0.9488\n",
      "[sklearn_metrics] Epoch:28 loss:1.1040 accuracy:0.9492 precision:0.9492 recall:0.9492 f1:0.9492\n",
      "[sklearn_metrics] Epoch:28 loss:1.2072 accuracy:0.9489 precision:0.9489 recall:0.9489 f1:0.9489\n",
      "[sklearn_metrics] Epoch:28 loss:1.3181 accuracy:0.9479 precision:0.9479 recall:0.9479 f1:0.9479\n",
      "[sklearn_metrics] Epoch:28 loss:1.4565 accuracy:0.9471 precision:0.9471 recall:0.9471 f1:0.9471\n",
      "[sklearn_metrics] Epoch:28 loss:1.5848 accuracy:0.9465 precision:0.9465 recall:0.9465 f1:0.9465\n",
      "[sklearn_metrics] Epoch:29 loss:0.0613 accuracy:0.9688 precision:0.9688 recall:0.9688 f1:0.9688\n",
      "[sklearn_metrics] Epoch:29 loss:0.1935 accuracy:0.9492 precision:0.9492 recall:0.9492 f1:0.9492\n",
      "[sklearn_metrics] Epoch:29 loss:0.3148 accuracy:0.9479 precision:0.9479 recall:0.9479 f1:0.9479\n",
      "[sklearn_metrics] Epoch:29 loss:0.3824 accuracy:0.9473 precision:0.9473 recall:0.9473 f1:0.9473\n",
      "[sklearn_metrics] Epoch:29 loss:0.5006 accuracy:0.9484 precision:0.9484 recall:0.9484 f1:0.9484\n",
      "[sklearn_metrics] Epoch:29 loss:0.6069 accuracy:0.9492 precision:0.9492 recall:0.9492 f1:0.9492\n",
      "[sklearn_metrics] Epoch:29 loss:0.6926 accuracy:0.9509 precision:0.9509 recall:0.9509 f1:0.9509\n",
      "[sklearn_metrics] Epoch:29 loss:0.8208 accuracy:0.9502 precision:0.9502 recall:0.9502 f1:0.9502\n",
      "[sklearn_metrics] Epoch:29 loss:0.9220 accuracy:0.9479 precision:0.9479 recall:0.9479 f1:0.9479\n",
      "[sklearn_metrics] Epoch:29 loss:1.0648 accuracy:0.9461 precision:0.9461 recall:0.9461 f1:0.9461\n",
      "[sklearn_metrics] Epoch:29 loss:1.1390 accuracy:0.9467 precision:0.9467 recall:0.9467 f1:0.9467\n",
      "[sklearn_metrics] Epoch:29 loss:1.2662 accuracy:0.9466 precision:0.9466 recall:0.9466 f1:0.9466\n",
      "[sklearn_metrics] Epoch:29 loss:1.3833 accuracy:0.9465 precision:0.9465 recall:0.9465 f1:0.9465\n",
      "[sklearn_metrics] Epoch:29 loss:1.4782 accuracy:0.9459 precision:0.9459 recall:0.9459 f1:0.9459\n",
      "2.7906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        98\n",
      "           1       0.50      0.28      0.36        18\n",
      "           2       0.77      0.83      0.80        12\n",
      "\n",
      "    accuracy                           0.85       128\n",
      "   macro avg       0.72      0.69      0.69       128\n",
      "weighted avg       0.83      0.85      0.83       128\n",
      "\n",
      "[[94  4  0]\n",
      " [10  5  3]\n",
      " [ 1  1 10]]\n",
      "[sklearn_metrics] accuracy:0.8516 precision:0.8516 recall:0.8516 f1:0.8516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       201\n",
      "           1       0.73      0.56      0.63        34\n",
      "           2       0.83      0.90      0.86        21\n",
      "\n",
      "    accuracy                           0.91       256\n",
      "   macro avg       0.83      0.81      0.82       256\n",
      "weighted avg       0.90      0.91      0.91       256\n",
      "\n",
      "[[195   6   0]\n",
      " [ 11  19   4]\n",
      " [  1   1  19]]\n",
      "[sklearn_metrics] accuracy:0.9102 precision:0.9102 recall:0.9102 f1:0.9102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       301\n",
      "           1       0.68      0.53      0.59        51\n",
      "           2       0.82      0.88      0.85        32\n",
      "\n",
      "    accuracy                           0.90       384\n",
      "   macro avg       0.81      0.79      0.80       384\n",
      "weighted avg       0.89      0.90      0.89       384\n",
      "\n",
      "[[290  11   0]\n",
      " [ 18  27   6]\n",
      " [  2   2  28]]\n",
      "[sklearn_metrics] accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       332\n",
      "           1       0.70      0.56      0.62        59\n",
      "           2       0.79      0.89      0.84        35\n",
      "\n",
      "    accuracy                           0.90       426\n",
      "   macro avg       0.81      0.80      0.80       426\n",
      "weighted avg       0.90      0.90      0.90       426\n",
      "\n",
      "[[320  12   0]\n",
      " [ 18  33   8]\n",
      " [  2   2  31]]\n",
      "[sklearn_metrics] accuracy:0.9014 precision:0.9014 recall:0.9014 f1:0.9014\n"
     ]
    }
   ],
   "source": [
    "start=datetime.now()\n",
    "total_step = len(train_loader)\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    tot_loss = 0.0\n",
    "    tot_acc = 0.0\n",
    "    train_preds = []\n",
    "    train_trues = []\n",
    "  # model.train()\n",
    "    for i,(train_data_batch, train_label_batch) in enumerate(train_loader):\n",
    "        train_data_batch = train_data_batch.float().to(device) #from double to float\n",
    "        train_label_batch = train_label_batch.to(device)\n",
    "        outputs = model(train_data_batch)\n",
    "        # _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, train_label_batch)\n",
    "        # print(loss)\n",
    "        #backword propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # accumulate the loss of each step \n",
    "        tot_loss += loss.data\n",
    "        train_outputs = outputs.argmax(dim=1)\n",
    "        train_preds.extend(train_outputs.detach().cpu().numpy())\n",
    "        train_trues.extend(train_label_batch.detach().cpu().numpy())\n",
    "        # tot_acc += (outputs.argmax(dim=1) == train_label_batch).sum().item()\n",
    "        sklearn_accuracy = accuracy_score(train_trues, train_preds)\n",
    "        sklearn_precision = precision_score(train_trues, train_preds, average='micro')\n",
    "        sklearn_recall = recall_score(train_trues, train_preds, average='micro')\n",
    "        sklearn_f1 = f1_score(train_trues, train_preds, average='micro')\n",
    "        print(\"[sklearn_metrics] Epoch:{} loss:{:.4f} accuracy:{:.4f} precision:{:.4f} recall:{:.4f} f1:{:.4f}\".format(epoch, tot_loss, sklearn_accuracy, sklearn_precision, sklearn_recall, sklearn_f1))\n",
    "stop=datetime.now()\n",
    "execution_time_ann=(stop-start)\n",
    "training_time_ann='%.4f'%(execution_time_ann).total_seconds()\n",
    "print(training_time_ann)\n",
    "        \n",
    "test_preds = []\n",
    "test_trues = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i,(test_data_batch, test_data_label) in enumerate(test_loader):\n",
    "        test_data_batch = test_data_batch.float().to(device) #from double to float\n",
    "        test_data_label = test_data_label.to(device)\n",
    "        test_outputs = model(test_data_batch)\n",
    "        probs = F.softmax(test_outputs, dim=1) \n",
    "        test_outputs = test_outputs.argmax(dim=1)\n",
    "        testloss = criterion(probs, test_data_label)\n",
    "#         preds = torch.argmax(logits, dim=1)\n",
    "        test_preds.extend(test_outputs.detach().cpu().numpy())\n",
    "        test_trues.extend(test_data_label.detach().cpu().numpy())\n",
    "        sklearn_accuracy = accuracy_score(test_trues, test_preds)\n",
    "        sklearn_precision = precision_score(test_trues, test_preds, average='micro')\n",
    "        sklearn_recall = recall_score(test_trues, test_preds, average='micro')\n",
    "        sklearn_f1 = f1_score(test_trues, test_preds, average='micro')\n",
    "        print(classification_report(test_trues, test_preds))\n",
    "        conf_matrix = confusion_matrix(test_trues, test_preds)\n",
    "        print(conf_matrix)\n",
    "#         plot_confusion_matrix(conf_matrix)\n",
    "        print(\"[sklearn_metrics] accuracy:{:.4f} precision:{:.4f} recall:{:.4f} f1:{:.4f}\".format(sklearn_accuracy, sklearn_precision, sklearn_recall, sklearn_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08470beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7906'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time_ann"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
