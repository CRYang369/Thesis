{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1dfafb",
   "metadata": {},
   "source": [
    "# Import the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a9cc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score  \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,roc_auc_score,accuracy_score, plot_confusion_matrix,classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12583cbc",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8c97c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>137</td>\n",
       "      <td>121</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>198</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>136</td>\n",
       "      <td>140</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>198</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>135</td>\n",
       "      <td>138</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>170</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>134</td>\n",
       "      <td>137</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>136</td>\n",
       "      <td>138</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LB        AC   FM        UC        DL   DP  ASTV  MSTV  ALTV  MLTV  ...  \\\n",
       "0  120  0.000000  0.0  0.000000  0.000000  0.0    73   0.5    43   2.4  ...   \n",
       "1  132  0.006380  0.0  0.006380  0.003190  0.0    17   2.1     0  10.4  ...   \n",
       "2  133  0.003322  0.0  0.008306  0.003322  0.0    16   2.1     0  13.4  ...   \n",
       "3  134  0.002561  0.0  0.007682  0.002561  0.0    16   2.4     0  23.0  ...   \n",
       "4  132  0.006515  0.0  0.008143  0.000000  0.0    16   2.4     0  19.9  ...   \n",
       "\n",
       "   Min  Max  Nmax  Nzeros  Mode  Mean  Median  Variance  Tendency  label  \n",
       "0   62  126     2       0   120   137     121        73         1      8  \n",
       "1   68  198     6       1   141   136     140        12         0      5  \n",
       "2   68  198     5       1   141   135     138        13         0      5  \n",
       "3   53  170    11       0   137   134     137        13         1      5  \n",
       "4   53  170     9       0   137   136     138        11         1      1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTGData=pd.read_csv('CTGPattern selected 20 features.csv')\n",
    "CTGData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0db571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEHCAYAAABBW1qbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAT30lEQVR4nO3df7BfdX3n8eeLBFFQFyghGxJscDcyBtoK3sm6ZYZW0y30l6EOMHEWN7V06ExRcbezNdiZ1d2d7NDZ2mmHamcyoMYVoSnqkjq7IsaKq9tCbxCFEFlSYcndRHL9tWh3iia+94/vycdvkptwCTnf7yX3+Zj5zvecz/ec7+edm3vv657POefzTVUhSRLASeMuQJI0dxgKkqTGUJAkNYaCJKkxFCRJjaEgSWoW9vnmSU4HbgEuBAr4TeBR4M+B5cATwNVV9Z1u+xuBa4H9wDuq6u6jvf9ZZ51Vy5cv76d4STpBbdu27ZtVtWim19LnfQpJNgH/o6puSfIi4FTg3cC3q+qmJOuBM6rqXUlWArcDq4BzgM8Cr6qq/Ud6/4mJiZqcnOytfkk6ESXZVlUTM73W2/BRkpcDlwK3AlTVD6rqu8AaYFO32Sbgim55DXBHVT1TVY8DOxkEhCRpRPo8p/BKYBr4UJIvJ7klyWnA4qraA9A9n91tvxTYNbT/VNd2kCTXJZlMMjk9Pd1j+ZI0//QZCguBi4E/q6qLgL8H1h9l+8zQdtjYVlVtrKqJqppYtGjGITFJ0jHqMxSmgKmquq9bv5NBSDyVZAlA97x3aPtzh/ZfBuzusT5J0iF6C4Wq+gawK8n5XdNq4BFgC7Cua1sH3NUtbwHWJjklyXnACuD+vuqTJB2u10tSgbcDt3VXHn0deCuDINqc5FrgSeAqgKranmQzg+DYB1x/tCuPJEnHX6+hUFUPAjNd9rT6CNtvADb0WZMk6ci8o1mS1BgKkqSm73MK886T/+GnRtbXK/7dQyPrS9L84JGCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNb2GQpInkjyU5MEkk13bmUnuSfJY93zG0PY3JtmZ5NEkl/VZmyTpcKM4Unh9Vb2mqia69fXA1qpaAWzt1kmyElgLXABcDnwgyYIR1CdJ6oxj+GgNsKlb3gRcMdR+R1U9U1WPAzuBVaMvT5Lmr75DoYDPJNmW5LqubXFV7QHons/u2pcCu4b2neraDpLkuiSTSSanp6d7LF2S5p+FPb//JVW1O8nZwD1JvnaUbTNDWx3WULUR2AgwMTFx2OuSpGPX65FCVe3unvcCn2QwHPRUkiUA3fPebvMp4Nyh3ZcBu/usT5J0sN5CIclpSV52YBn4ReBhYAuwrttsHXBXt7wFWJvklCTnASuA+/uqT5J0uD6HjxYDn0xyoJ+PVdWnk/wtsDnJtcCTwFUAVbU9yWbgEWAfcH1V7e+xPknSIXoLhar6OvAzM7R/C1h9hH02ABv6qkmSdHTe0SxJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSmt5DIcmCJF9O8qlu/cwk9yR5rHs+Y2jbG5PsTPJoksv6rk2SdLBRHCncAOwYWl8PbK2qFcDWbp0kK4G1wAXA5cAHkiwYQX2SpE6voZBkGfArwC1DzWuATd3yJuCKofY7quqZqnoc2Ams6rM+SdLB+j5S+GPg94AfDbUtrqo9AN3z2V37UmDX0HZTXdtBklyXZDLJ5PT0dC9FS9J81VsoJPlVYG9VbZvtLjO01WENVRuraqKqJhYtWvS8apQkHWxhj+99CfDGJL8MvBh4eZKPAk8lWVJVe5IsAfZ2208B5w7tvwzY3WN9kqRD9HakUFU3VtWyqlrO4ATy56rqGmALsK7bbB1wV7e8BVib5JQk5wErgPv7qk+SdLg+jxSO5CZgc5JrgSeBqwCqanuSzcAjwD7g+qraP4b6JGneGkkoVNXngc93y98CVh9huw3AhmPt57X/9iPHuutzsu0//6uR9CNJo+YdzZKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpGZWoZBk62zaJEkvbEf9OM4kLwZOBc5KcgaQ7qWXA+f0XJt0wthwzZUj6+v3P3rnyPrSiefZPqP5t4F3MgiAbfw4FJ4G3t9fWZKkcThqKFTVnwB/kuTtVXXziGqSJI3Jsx0pAFBVNyf5WWD58D5V9ZGe6pIkjcGsQiHJfwH+CfAgsL9rLsBQkKQTyKxCAZgAVlZV9VmMJGm8ZnufwsPAP+6zEEnS+M32SOEs4JEk9wPPHGisqjf2UpUkaSxmGwrvfa5v3N3j8AXglK6fO6vqPUnOBP6cwUnrJ4Crq+o73T43AtcyOG/xjqq6+7n2K0k6drO9+ujeY3jvZ4A3VNX3k5wMfDHJfwfeBGytqpuSrAfWA+9KshJYC1zA4L6IzyZ5VVXtP1IHkqTja7bTXHwvydPd4x+S7E/y9NH2qYHvd6snd48C1gCbuvZNwBXd8hrgjqp6pqoeB3YCq57bP0eS9HzM9kjhZcPrSa5gFr+wkyxgcCf0PwXeX1X3JVlcVXu6992T5Oxu86XA3wztPtW1SZJG5JhmSa2q/wq8YRbb7a+q1wDLgFVJLjzK5pmh7bBLYJNcl2QyyeT09PQsK5YkzcZsb15709DqSQzuW5j1PQtV9d0knwcuB55KsqQ7SlgC7O02mwLOHdptGbB7hvfaCGwEmJiY8L4JSTqOZnuk8GtDj8uA7zE4B3BESRYlOb1bfgnwC8DXgC3Aum6zdcBd3fIWYG2SU5KcB6wA7p/1v0SS9LzN9pzCW4/hvZcAm7rzCicBm6vqU0n+Gtic5FrgSeCqro/tSTYDjwD7gOu98kiSRmu2w0fLgJuBSxgMG30RuKGqpo60T1V9FbhohvZvAauPsM8GYMNsapIkHX+zHT76EIPhnXMYXBH0l12bJOkEMttQWFRVH6qqfd3jw8CiHuuSJI3BbEPhm0muSbKge1wDfKvPwiRJozfbUPhN4GrgG8Ae4ErgWE4+S5LmsNlOiPcfgXVDE9edCfwhg7CQJJ0gZnuk8NMHAgGgqr7NDFcWSZJe2GYbCiclOePASnekMNujDEnSC8Rsf7G/D/ifSe5kcJ/C1Xg/gSSdcGZ7R/NHkkwymAQvwJuq6pFeK5Mkjdysh4C6EDAIJOkEdkxTZ0uSTkyGgiSp8QoiaR7ZseFzI+nn1b//rJ/BpTnKIwVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqektFJKcm+SvkuxIsj3JDV37mUnuSfJY93zG0D43JtmZ5NEkl/VVmyRpZn0eKewDfreqXg28Drg+yUpgPbC1qlYAW7t1utfWAhcAlwMfSLKgx/okSYfoLRSqak9VPdAtfw/YASwF1gCbus02AVd0y2uAO6rqmap6HNgJrOqrPknS4UZyTiHJcuAi4D5gcVXtgUFwAGd3my0Fdg3tNtW1Hfpe1yWZTDI5PT3da92SNN/0/nGcSV4KfBx4Z1U9neSIm87QVoc1VG0ENgJMTEwc9rokvVD8zJ13j6yvr1w5u9O0vR4pJDmZQSDcVlWf6JqfSrKke30JsLdrnwLOHdp9GbC7z/okSQfr8+qjALcCO6rqj4Ze2gKs65bXAXcNta9NckqS84AVwP191SdJOlyfw0eXAG8BHkryYNf2buAmYHOSa4EngasAqmp7ks3AIwyuXLq+qvb3WJ8k6RC9hUJVfZGZzxMArD7CPhuADX3VJEk6Ou9oliQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJElNb6GQ5INJ9iZ5eKjtzCT3JHmsez5j6LUbk+xM8miSy/qqS5J0ZAt7fO8PA38KfGSobT2wtapuSrK+W39XkpXAWuAC4Bzgs0leVVX7e6xP0hi8973vPSH7OlH0dqRQVV8Avn1I8xpgU7e8CbhiqP2Oqnqmqh4HdgKr+qpNkjSzUZ9TWFxVewC657O79qXArqHtprq2wyS5Lslkksnp6elei5Wk+WaunGjODG0104ZVtbGqJqpqYtGiRT2XJUnzy6hD4akkSwC6571d+xRw7tB2y4DdI65Nkua9UYfCFmBdt7wOuGuofW2SU5KcB6wA7h9xbZI07/V29VGS24GfB85KMgW8B7gJ2JzkWuBJ4CqAqtqeZDPwCLAPuN4rjyRp9HoLhap68xFeWn2E7TcAG/qqR5L07ObKiWZJ0hzQ581rmufuvfTnRtbXz33h3pH1JZ3IPFKQJDWGgiSpcfhIJ7w//d2/HEk/b3vfr42kH6lPhoKkeWnzX4xmerWrr3ph3XLl8JEkqTEUJEmNoSBJagwFSVJjKEiSGq8+OkFdcvMlI+nnS2//0kj6kTQaHilIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElq5lwoJLk8yaNJdiZZP+56JGk+mVOhkGQB8H7gl4CVwJuTrBxvVZI0f8ypUABWATur6utV9QPgDmDNmGuSpHkjVTXuGpokVwKXV9VvdetvAf5ZVb1taJvrgOu61fOBR59nt2cB33ye73E8zIU65kINMDfqsIYfmwt1zIUaYG7UcTxq+MmqWjTTC3PtM5ozQ9tBqVVVG4GNx63DZLKqJo7X+72Q65gLNcyVOqxhbtUxF2qYK3X0XcNcGz6aAs4dWl8G7B5TLZI078y1UPhbYEWS85K8CFgLbBlzTZI0b8yp4aOq2pfkbcDdwALgg1W1veduj9tQ1PM0F+qYCzXA3KjDGn5sLtQxF2qAuVFHrzXMqRPNkqTxmmvDR5KkMTIUJEnNvA6FcU+pkeSDSfYmeXjUfR9Sx7lJ/irJjiTbk9wwhhpenOT+JF/pavj3o65hqJYFSb6c5FNjrOGJJA8leTDJ5BjrOD3JnUm+1n1//PMR939+9zU48Hg6yTtHWUNXx7/uvi8fTnJ7khePuoaujhu6Grb39nWoqnn5YHAi+++AVwIvAr4CrBxxDZcCFwMPj/lrsQS4uFt+GfC/xvC1CPDSbvlk4D7gdWP6evwb4GPAp8b4f/IEcNY4vy+6OjYBv9Utvwg4fYy1LAC+weDGq1H2uxR4HHhJt74Z+I0x/PsvBB4GTmVwkdBngRXHu5/5fKQw9ik1quoLwLdH2ecR6thTVQ90y98DdjD4QRhlDVVV3+9WT+4eI78KIsky4FeAW0bd91yT5OUM/nC5FaCqflBV3x1jSauBv6uq/z2GvhcCL0mykMEv5XHcP/Vq4G+q6v9V1T7gXuDXj3cn8zkUlgK7htanGPEvwrkoyXLgIgZ/qY+67wVJHgT2AvdU1chrAP4Y+D3gR2Poe1gBn0myrZvaZRxeCUwDH+qG025JctqYaoHBfUu3j7rTqvo/wB8CTwJ7gP9bVZ8ZdR0MjhIuTfITSU4FfpmDb/Y9LuZzKDzrlBrzTZKXAh8H3llVT4+6/6raX1WvYXAn+6okF46y/yS/Cuytqm2j7PcILqmqixnMGHx9kkvHUMNCBsObf1ZVFwF/D4xlOvvuZtY3An8xhr7PYDCKcB5wDnBakmtGXUdV7QD+ALgH+DSDIe99x7uf+RwKTqkxJMnJDALhtqr6xDhr6YYoPg9cPuKuLwHemOQJBsOJb0jy0RHXAEBV7e6e9wKfZDDcOWpTwNTQEdudDEJiHH4JeKCqnhpD378APF5V01X1Q+ATwM+OoQ6q6taquriqLmUw9PzY8e5jPoeCU2p0koTBuPGOqvqjMdWwKMnp3fJLGPwgfm2UNVTVjVW1rKqWM/h++FxVjfwvwiSnJXnZgWXgFxkMHYxUVX0D2JXk/K5pNfDIqOvovJkxDB11ngRel+TU7mdlNYPzbiOX5Ozu+RXAm+jhazKnprkYpRrPlBoHSXI78PPAWUmmgPdU1a2jrKFzCfAW4KFuTB/g3VX130ZYwxJgU/dBSycBm6tqbJeEjtli4JOD3z8sBD5WVZ8eUy1vB27r/nD6OvDWURfQjZ//C+C3R903QFXdl+RO4AEGwzVfZnzTXXw8yU8APwSur6rvHO8OnOZCktTM5+EjSdIhDAVJUmMoSJIaQ0GS1BgKkqTGUJCegyTff5bXlz/XWW+TfDjJlc+vMun4MBQkSY2hIB2DJC9NsjXJA93nHgzPsLswyaYkX+0+i+DUbp/XJrm3m+Tu7iRLxlS+dESGgnRs/gH49W7SutcD7+umQAA4H9hYVT8NPA38Tje31M3AlVX1WuCDwIYx1C0d1byd5kJ6ngL8p2720h8xmHZ9cffarqr6Urf8UeAdDGa1vBC4p8uOBQymYZbmFENBOjb/ElgEvLaqftjNrHrgIxoPnTumGITI9qoa6cdZSs+Vw0fSsflHDD574YdJXg/85NBrrxj6LOM3A18EHgUWHWhPcnKSC0ZasTQLhoJ0bG4DJpJMMjhqGJ7mewewLslXgTMZfEjND4ArgT9I8hXgQcY0J790NM6SKklqPFKQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1Px/3qB5gJ8OQBMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='label',data=CTGData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee8cd2",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b09ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTGData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d5b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CTGData01=CTGData.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0164e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=CTGData01.drop(labels=['label'],axis=1)\n",
    "\n",
    "y1=CTGData01['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed2ad0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stanardilization\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X1)\n",
    "X1=scaler.transform(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe46089",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c359dfcf",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a45779f",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape : (1700, 20)\n",
      "X_test.shape : (426, 20)\n"
     ]
    }
   ],
   "source": [
    "#split train dataset and test dataset\n",
    "X1_train, X1_test,y1_train,y1_test= train_test_split(X1,y1,test_size=0.2, shuffle = True,stratify=y1,random_state=42)\n",
    "print(\"X_train.shape :\",X1_train.shape)\n",
    "print(\"X_test.shape :\",X1_test.shape)\n",
    "# print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e17518",
   "metadata": {},
   "source": [
    "Define the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12db8e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X1_train = torch.from_numpy(X1_train)\n",
    "y1_train = torch.from_numpy(y1_train ).type(torch.LongTensor)\n",
    "\n",
    "X1_test  = torch.from_numpy(X1_test )\n",
    "y1_test= torch.from_numpy(y1_test).type(torch.LongTensor)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train = torch.utils.data.TensorDataset(X1_train, y1_train )\n",
    "test = torch.utils.data.TensorDataset(X1_test , y1_test)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a2d920",
   "metadata": {},
   "source": [
    "Define the Optuna  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e43e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-09 14:07:43,189]\u001b[0m A new study created in memory with name: no-name-a1562df3-ddad-4011-911e-a5da369b6b8c\u001b[0m\n",
      "C:\\Users\\COOLER~1\\AppData\\Local\\Temp/ipykernel_20272/2944855679.py:96: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2022-09-09 14:07:43,916]\u001b[0m Trial 0 finished with value: 0.42018779342723006 and parameters: {'learning_rate': 0.001923483972490575, 'optimizer': 'SGD', 'n_layers': 1, 'n_units_l0': 88}. Best is trial 0 with value: 0.42018779342723006.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:44,902]\u001b[0m Trial 1 finished with value: 0.27230046948356806 and parameters: {'learning_rate': 0.09734613468807915, 'optimizer': 'RMSprop', 'n_layers': 3, 'n_units_l0': 119, 'n_units_l1': 79, 'n_units_l2': 7}. Best is trial 0 with value: 0.42018779342723006.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:45,582]\u001b[0m Trial 2 finished with value: 0.8075117370892019 and parameters: {'learning_rate': 0.004747043085587881, 'optimizer': 'RMSprop', 'n_layers': 1, 'n_units_l0': 22}. Best is trial 2 with value: 0.8075117370892019.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:46,257]\u001b[0m Trial 3 finished with value: 0.7347417840375586 and parameters: {'learning_rate': 0.03010749423751901, 'optimizer': 'SGD', 'n_layers': 1, 'n_units_l0': 71}. Best is trial 2 with value: 0.8075117370892019.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:47,152]\u001b[0m Trial 4 finished with value: 0.8309859154929577 and parameters: {'learning_rate': 0.06402441415599916, 'optimizer': 'Adam', 'n_layers': 2, 'n_units_l0': 58, 'n_units_l1': 89}. Best is trial 4 with value: 0.8309859154929577.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:47,993]\u001b[0m Trial 5 finished with value: 0.8427230046948356 and parameters: {'learning_rate': 0.0016084348559734527, 'optimizer': 'RMSprop', 'n_layers': 2, 'n_units_l0': 57, 'n_units_l1': 60}. Best is trial 5 with value: 0.8427230046948356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:48,027]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:48,065]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:48,109]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:49,164]\u001b[0m Trial 9 finished with value: 0.812206572769953 and parameters: {'learning_rate': 0.0005434539514770474, 'optimizer': 'RMSprop', 'n_layers': 3, 'n_units_l0': 84, 'n_units_l1': 76, 'n_units_l2': 126}. Best is trial 5 with value: 0.8427230046948356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:49,212]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:50,117]\u001b[0m Trial 11 finished with value: 0.8497652582159625 and parameters: {'learning_rate': 0.011269387355876546, 'optimizer': 'Adam', 'n_layers': 2, 'n_units_l0': 56, 'n_units_l1': 45}. Best is trial 11 with value: 0.8497652582159625.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:50,163]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:51,112]\u001b[0m Trial 13 finished with value: 0.8591549295774648 and parameters: {'learning_rate': 0.009802428345571901, 'optimizer': 'Adam', 'n_layers': 2, 'n_units_l0': 104, 'n_units_l1': 46}. Best is trial 13 with value: 0.8591549295774648.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:52,062]\u001b[0m Trial 14 finished with value: 0.8497652582159625 and parameters: {'learning_rate': 0.01137899700465911, 'optimizer': 'Adam', 'n_layers': 2, 'n_units_l0': 119, 'n_units_l1': 37}. Best is trial 13 with value: 0.8591549295774648.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:52,874]\u001b[0m Trial 15 finished with value: 0.8427230046948356 and parameters: {'learning_rate': 0.02477954596287311, 'optimizer': 'Adam', 'n_layers': 1, 'n_units_l0': 101}. Best is trial 13 with value: 0.8591549295774648.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:52,923]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:53,747]\u001b[0m Trial 17 finished with value: 0.8826291079812206 and parameters: {'learning_rate': 0.018016879806179577, 'optimizer': 'Adam', 'n_layers': 1, 'n_units_l0': 128}. Best is trial 17 with value: 0.8826291079812206.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:53,787]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:54,599]\u001b[0m Trial 19 finished with value: 0.8779342723004695 and parameters: {'learning_rate': 0.03098909576018977, 'optimizer': 'Adam', 'n_layers': 1, 'n_units_l0': 102}. Best is trial 17 with value: 0.8826291079812206.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:54,693]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:55,565]\u001b[0m Trial 21 finished with value: 0.8661971830985915 and parameters: {'learning_rate': 0.04732999349406743, 'optimizer': 'Adam', 'n_layers': 1, 'n_units_l0': 106}. Best is trial 17 with value: 0.8826291079812206.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:56,381]\u001b[0m Trial 22 finished with value: 0.8802816901408451 and parameters: {'learning_rate': 0.04512075576181428, 'optimizer': 'Adam', 'n_layers': 1, 'n_units_l0': 114}. Best is trial 17 with value: 0.8826291079812206.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:57,202]\u001b[0m Trial 23 finished with value: 0.8615023474178404 and parameters: {'learning_rate': 0.0248168755284424, 'optimizer': 'Adam', 'n_layers': 1, 'n_units_l0': 116}. Best is trial 17 with value: 0.8826291079812206.\u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:57,243]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:57,282]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:57,402]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:57,444]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:57,485]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-09 14:07:57,524]\u001b[0m Trial 29 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a model by implementing define-by-run design from Optuna\n",
    "def build_model_custom(trial):\n",
    "    \n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 20\n",
    "# looping to determine the number of layers and nodes in each layer     \n",
    "    for i in range(n_layers):\n",
    "#         the number of nodes in each layer.\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        \n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "#         p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "#         layers.append(nn.Dropout(p))\n",
    "        \n",
    "        in_features = out_features\n",
    "        \n",
    "    layers.append(nn.Linear(in_features, 10))\n",
    "#     layers.append(nn.ReLU())\n",
    "    \n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# Train and evaluate the accuracy of neural network with the addition of pruning mechanism\n",
    "def train_and_evaluate(param, model, trial):\n",
    "    \n",
    "\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = getattr(optim, param['optimizer'])(model.parameters(), lr= param['learning_rate'])\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(EPOCHS):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in train_loader:\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                train_input = train_input.to(device)\n",
    "\n",
    "                output = model(train_input.float())\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in test_loader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    val_input = val_input.to(device)\n",
    "\n",
    "                    output = model(val_input.float())\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            accuracy = total_acc_val/len(test)\n",
    "            \n",
    "            # Add prune mechanism\n",
    "            trial.report(accuracy, epoch_num)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "  \n",
    "# Define a set of hyperparameter values, build the model, train the model, and evaluate the accuracy\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "              'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "              'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
    "              }\n",
    "    \n",
    "    model = build_model_custom(trial)\n",
    "\n",
    "    accuracy = train_and_evaluate(params, model, trial)\n",
    "\n",
    "    return accuracy\n",
    "  \n",
    "EPOCHS = 30\n",
    "    \n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "494ce74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.018016879806179577\n",
      "optimizer: Adam\n",
      "n_layers: 1\n",
      "n_units_l0: 128\n"
     ]
    }
   ],
   "source": [
    "best_trial = study.best_trial\n",
    "\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f205e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best is trial 3 with value:  0.8826291079812206\n",
    "# learning_rate: 0.018016879806179577\n",
    "# optimizer: Adam\n",
    "# n_layers: 1\n",
    "# n_units_l0: 128\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f8a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1,hidden_dim2, output_dim):\n",
    "        super(ANNModel, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.relu1 = nn.ReLU() \n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98edefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =30\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = X1.shape[1]\n",
    "hidden_dim1 = 104 #hidden layer1\n",
    "hidden_dim2 = 102 #hidden layer2 \n",
    "output_dim = len(set(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a447bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANNModel(input_dim, hidden_dim1,hidden_dim2,output_dim)\n",
    "\n",
    "\n",
    "learning_rate =  0.0222\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e313495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn_metrics] Epoch:0 loss:2.3294 accuracy:0.0469 precision:0.0469 recall:0.0469 f1:0.0469\n",
      "[sklearn_metrics] Epoch:0 loss:4.1715 accuracy:0.2500 precision:0.2500 recall:0.2500 f1:0.2500\n",
      "[sklearn_metrics] Epoch:0 loss:5.8976 accuracy:0.2917 precision:0.2917 recall:0.2917 f1:0.2917\n",
      "[sklearn_metrics] Epoch:0 loss:7.5092 accuracy:0.3379 precision:0.3379 recall:0.3379 f1:0.3379\n",
      "[sklearn_metrics] Epoch:0 loss:8.8938 accuracy:0.3781 precision:0.3781 recall:0.3781 f1:0.3781\n",
      "[sklearn_metrics] Epoch:0 loss:10.1256 accuracy:0.4180 precision:0.4180 recall:0.4180 f1:0.4180\n",
      "[sklearn_metrics] Epoch:0 loss:11.2774 accuracy:0.4297 precision:0.4297 recall:0.4297 f1:0.4297\n",
      "[sklearn_metrics] Epoch:0 loss:12.2488 accuracy:0.4688 precision:0.4688 recall:0.4688 f1:0.4688\n",
      "[sklearn_metrics] Epoch:0 loss:13.2030 accuracy:0.4905 precision:0.4905 recall:0.4905 f1:0.4905\n",
      "[sklearn_metrics] Epoch:0 loss:14.1869 accuracy:0.5023 precision:0.5023 recall:0.5023 f1:0.5023\n",
      "[sklearn_metrics] Epoch:0 loss:15.2392 accuracy:0.5128 precision:0.5128 recall:0.5128 f1:0.5128\n",
      "[sklearn_metrics] Epoch:0 loss:15.9278 accuracy:0.5345 precision:0.5345 recall:0.5345 f1:0.5345\n",
      "[sklearn_metrics] Epoch:0 loss:16.7234 accuracy:0.5475 precision:0.5475 recall:0.5475 f1:0.5475\n",
      "[sklearn_metrics] Epoch:0 loss:17.5343 accuracy:0.5506 precision:0.5506 recall:0.5506 f1:0.5506\n",
      "[sklearn_metrics] Epoch:1 loss:0.6856 accuracy:0.7266 precision:0.7266 recall:0.7266 f1:0.7266\n",
      "[sklearn_metrics] Epoch:1 loss:1.4854 accuracy:0.7344 precision:0.7344 recall:0.7344 f1:0.7344\n",
      "[sklearn_metrics] Epoch:1 loss:2.1138 accuracy:0.7422 precision:0.7422 recall:0.7422 f1:0.7422\n",
      "[sklearn_metrics] Epoch:1 loss:2.8218 accuracy:0.7344 precision:0.7344 recall:0.7344 f1:0.7344\n",
      "[sklearn_metrics] Epoch:1 loss:3.6591 accuracy:0.7188 precision:0.7188 recall:0.7188 f1:0.7188\n",
      "[sklearn_metrics] Epoch:1 loss:4.2337 accuracy:0.7305 precision:0.7305 recall:0.7305 f1:0.7305\n",
      "[sklearn_metrics] Epoch:1 loss:4.9790 accuracy:0.7288 precision:0.7288 recall:0.7288 f1:0.7288\n",
      "[sklearn_metrics] Epoch:1 loss:5.5822 accuracy:0.7354 precision:0.7354 recall:0.7354 f1:0.7354\n",
      "[sklearn_metrics] Epoch:1 loss:6.1628 accuracy:0.7387 precision:0.7387 recall:0.7387 f1:0.7387\n",
      "[sklearn_metrics] Epoch:1 loss:6.7896 accuracy:0.7414 precision:0.7414 recall:0.7414 f1:0.7414\n",
      "[sklearn_metrics] Epoch:1 loss:7.3098 accuracy:0.7479 precision:0.7479 recall:0.7479 f1:0.7479\n",
      "[sklearn_metrics] Epoch:1 loss:7.8996 accuracy:0.7513 precision:0.7513 recall:0.7513 f1:0.7513\n",
      "[sklearn_metrics] Epoch:1 loss:8.5441 accuracy:0.7500 precision:0.7500 recall:0.7500 f1:0.7500\n",
      "[sklearn_metrics] Epoch:1 loss:9.2761 accuracy:0.7512 precision:0.7512 recall:0.7512 f1:0.7512\n",
      "[sklearn_metrics] Epoch:2 loss:0.6940 accuracy:0.7266 precision:0.7266 recall:0.7266 f1:0.7266\n",
      "[sklearn_metrics] Epoch:2 loss:1.4195 accuracy:0.7188 precision:0.7188 recall:0.7188 f1:0.7188\n",
      "[sklearn_metrics] Epoch:2 loss:1.9222 accuracy:0.7552 precision:0.7552 recall:0.7552 f1:0.7552\n",
      "[sklearn_metrics] Epoch:2 loss:2.7026 accuracy:0.7461 precision:0.7461 recall:0.7461 f1:0.7461\n",
      "[sklearn_metrics] Epoch:2 loss:3.3279 accuracy:0.7500 precision:0.7500 recall:0.7500 f1:0.7500\n",
      "[sklearn_metrics] Epoch:2 loss:3.8539 accuracy:0.7539 precision:0.7539 recall:0.7539 f1:0.7539\n",
      "[sklearn_metrics] Epoch:2 loss:4.3629 accuracy:0.7612 precision:0.7612 recall:0.7612 f1:0.7612\n",
      "[sklearn_metrics] Epoch:2 loss:4.9013 accuracy:0.7627 precision:0.7627 recall:0.7627 f1:0.7627\n",
      "[sklearn_metrics] Epoch:2 loss:5.5343 accuracy:0.7613 precision:0.7613 recall:0.7613 f1:0.7613\n",
      "[sklearn_metrics] Epoch:2 loss:6.0692 accuracy:0.7594 precision:0.7594 recall:0.7594 f1:0.7594\n",
      "[sklearn_metrics] Epoch:2 loss:6.4824 accuracy:0.7656 precision:0.7656 recall:0.7656 f1:0.7656\n",
      "[sklearn_metrics] Epoch:2 loss:6.9092 accuracy:0.7708 precision:0.7708 recall:0.7708 f1:0.7708\n",
      "[sklearn_metrics] Epoch:2 loss:7.4415 accuracy:0.7728 precision:0.7728 recall:0.7728 f1:0.7728\n",
      "[sklearn_metrics] Epoch:2 loss:7.9866 accuracy:0.7712 precision:0.7712 recall:0.7712 f1:0.7712\n",
      "[sklearn_metrics] Epoch:3 loss:0.3913 accuracy:0.8516 precision:0.8516 recall:0.8516 f1:0.8516\n",
      "[sklearn_metrics] Epoch:3 loss:0.9056 accuracy:0.8203 precision:0.8203 recall:0.8203 f1:0.8203\n",
      "[sklearn_metrics] Epoch:3 loss:1.3425 accuracy:0.8177 precision:0.8177 recall:0.8177 f1:0.8177\n",
      "[sklearn_metrics] Epoch:3 loss:1.7063 accuracy:0.8281 precision:0.8281 recall:0.8281 f1:0.8281\n",
      "[sklearn_metrics] Epoch:3 loss:2.2852 accuracy:0.8219 precision:0.8219 recall:0.8219 f1:0.8219\n",
      "[sklearn_metrics] Epoch:3 loss:2.7903 accuracy:0.8177 precision:0.8177 recall:0.8177 f1:0.8177\n",
      "[sklearn_metrics] Epoch:3 loss:3.2774 accuracy:0.8136 precision:0.8136 recall:0.8136 f1:0.8136\n",
      "[sklearn_metrics] Epoch:3 loss:3.6907 accuracy:0.8184 precision:0.8184 recall:0.8184 f1:0.8184\n",
      "[sklearn_metrics] Epoch:3 loss:4.1844 accuracy:0.8134 precision:0.8134 recall:0.8134 f1:0.8134\n",
      "[sklearn_metrics] Epoch:3 loss:4.6558 accuracy:0.8094 precision:0.8094 recall:0.8094 f1:0.8094\n",
      "[sklearn_metrics] Epoch:3 loss:5.0922 accuracy:0.8118 precision:0.8118 recall:0.8118 f1:0.8118\n",
      "[sklearn_metrics] Epoch:3 loss:5.5451 accuracy:0.8125 precision:0.8125 recall:0.8125 f1:0.8125\n",
      "[sklearn_metrics] Epoch:3 loss:6.0735 accuracy:0.8083 precision:0.8083 recall:0.8083 f1:0.8083\n",
      "[sklearn_metrics] Epoch:3 loss:6.4324 accuracy:0.8088 precision:0.8088 recall:0.8088 f1:0.8088\n",
      "[sklearn_metrics] Epoch:4 loss:0.3632 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:4 loss:0.8797 accuracy:0.8398 precision:0.8398 recall:0.8398 f1:0.8398\n",
      "[sklearn_metrics] Epoch:4 loss:1.3275 accuracy:0.8255 precision:0.8255 recall:0.8255 f1:0.8255\n",
      "[sklearn_metrics] Epoch:4 loss:1.8214 accuracy:0.8184 precision:0.8184 recall:0.8184 f1:0.8184\n",
      "[sklearn_metrics] Epoch:4 loss:2.1245 accuracy:0.8328 precision:0.8328 recall:0.8328 f1:0.8328\n",
      "[sklearn_metrics] Epoch:4 loss:2.4827 accuracy:0.8359 precision:0.8359 recall:0.8359 f1:0.8359\n",
      "[sklearn_metrics] Epoch:4 loss:3.0829 accuracy:0.8214 precision:0.8214 recall:0.8214 f1:0.8214\n",
      "[sklearn_metrics] Epoch:4 loss:3.5188 accuracy:0.8232 precision:0.8232 recall:0.8232 f1:0.8232\n",
      "[sklearn_metrics] Epoch:4 loss:4.1342 accuracy:0.8134 precision:0.8134 recall:0.8134 f1:0.8134\n",
      "[sklearn_metrics] Epoch:4 loss:4.6103 accuracy:0.8141 precision:0.8141 recall:0.8141 f1:0.8141\n",
      "[sklearn_metrics] Epoch:4 loss:5.0638 accuracy:0.8132 precision:0.8132 recall:0.8132 f1:0.8132\n",
      "[sklearn_metrics] Epoch:4 loss:5.5943 accuracy:0.8125 precision:0.8125 recall:0.8125 f1:0.8125\n",
      "[sklearn_metrics] Epoch:4 loss:6.1788 accuracy:0.8083 precision:0.8083 recall:0.8083 f1:0.8083\n",
      "[sklearn_metrics] Epoch:4 loss:6.7810 accuracy:0.8082 precision:0.8082 recall:0.8082 f1:0.8082\n",
      "[sklearn_metrics] Epoch:5 loss:0.3784 accuracy:0.8359 precision:0.8359 recall:0.8359 f1:0.8359\n",
      "[sklearn_metrics] Epoch:5 loss:0.8815 accuracy:0.8359 precision:0.8359 recall:0.8359 f1:0.8359\n",
      "[sklearn_metrics] Epoch:5 loss:1.4110 accuracy:0.8255 precision:0.8255 recall:0.8255 f1:0.8255\n",
      "[sklearn_metrics] Epoch:5 loss:1.7619 accuracy:0.8379 precision:0.8379 recall:0.8379 f1:0.8379\n",
      "[sklearn_metrics] Epoch:5 loss:2.2910 accuracy:0.8344 precision:0.8344 recall:0.8344 f1:0.8344\n",
      "[sklearn_metrics] Epoch:5 loss:2.7568 accuracy:0.8372 precision:0.8372 recall:0.8372 f1:0.8372\n",
      "[sklearn_metrics] Epoch:5 loss:3.1647 accuracy:0.8404 precision:0.8404 recall:0.8404 f1:0.8404\n",
      "[sklearn_metrics] Epoch:5 loss:3.6137 accuracy:0.8389 precision:0.8389 recall:0.8389 f1:0.8389\n",
      "[sklearn_metrics] Epoch:5 loss:4.0173 accuracy:0.8377 precision:0.8377 recall:0.8377 f1:0.8377\n",
      "[sklearn_metrics] Epoch:5 loss:4.4346 accuracy:0.8391 precision:0.8391 recall:0.8391 f1:0.8391\n",
      "[sklearn_metrics] Epoch:5 loss:4.9673 accuracy:0.8366 precision:0.8366 recall:0.8366 f1:0.8366\n",
      "[sklearn_metrics] Epoch:5 loss:5.3110 accuracy:0.8411 precision:0.8411 recall:0.8411 f1:0.8411\n",
      "[sklearn_metrics] Epoch:5 loss:5.9247 accuracy:0.8335 precision:0.8335 recall:0.8335 f1:0.8335\n",
      "[sklearn_metrics] Epoch:5 loss:6.4956 accuracy:0.8318 precision:0.8318 recall:0.8318 f1:0.8318\n",
      "[sklearn_metrics] Epoch:6 loss:0.4132 accuracy:0.8203 precision:0.8203 recall:0.8203 f1:0.8203\n",
      "[sklearn_metrics] Epoch:6 loss:0.8488 accuracy:0.8281 precision:0.8281 recall:0.8281 f1:0.8281\n",
      "[sklearn_metrics] Epoch:6 loss:1.1783 accuracy:0.8464 precision:0.8464 recall:0.8464 f1:0.8464\n",
      "[sklearn_metrics] Epoch:6 loss:1.6282 accuracy:0.8418 precision:0.8418 recall:0.8418 f1:0.8418\n",
      "[sklearn_metrics] Epoch:6 loss:2.0936 accuracy:0.8344 precision:0.8344 recall:0.8344 f1:0.8344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn_metrics] Epoch:6 loss:2.4053 accuracy:0.8424 precision:0.8424 recall:0.8424 f1:0.8424\n",
      "[sklearn_metrics] Epoch:6 loss:2.7818 accuracy:0.8460 precision:0.8460 recall:0.8460 f1:0.8460\n",
      "[sklearn_metrics] Epoch:6 loss:3.1098 accuracy:0.8477 precision:0.8477 recall:0.8477 f1:0.8477\n",
      "[sklearn_metrics] Epoch:6 loss:3.4589 accuracy:0.8490 precision:0.8490 recall:0.8490 f1:0.8490\n",
      "[sklearn_metrics] Epoch:6 loss:3.8007 accuracy:0.8484 precision:0.8484 recall:0.8484 f1:0.8484\n",
      "[sklearn_metrics] Epoch:6 loss:4.2493 accuracy:0.8487 precision:0.8487 recall:0.8487 f1:0.8487\n",
      "[sklearn_metrics] Epoch:6 loss:4.6864 accuracy:0.8483 precision:0.8483 recall:0.8483 f1:0.8483\n",
      "[sklearn_metrics] Epoch:6 loss:5.0986 accuracy:0.8486 precision:0.8486 recall:0.8486 f1:0.8486\n",
      "[sklearn_metrics] Epoch:6 loss:5.3755 accuracy:0.8482 precision:0.8482 recall:0.8482 f1:0.8482\n",
      "[sklearn_metrics] Epoch:7 loss:0.3607 accuracy:0.8359 precision:0.8359 recall:0.8359 f1:0.8359\n",
      "[sklearn_metrics] Epoch:7 loss:0.7550 accuracy:0.8320 precision:0.8320 recall:0.8320 f1:0.8320\n",
      "[sklearn_metrics] Epoch:7 loss:1.1725 accuracy:0.8385 precision:0.8385 recall:0.8385 f1:0.8385\n",
      "[sklearn_metrics] Epoch:7 loss:1.5240 accuracy:0.8516 precision:0.8516 recall:0.8516 f1:0.8516\n",
      "[sklearn_metrics] Epoch:7 loss:1.8074 accuracy:0.8578 precision:0.8578 recall:0.8578 f1:0.8578\n",
      "[sklearn_metrics] Epoch:7 loss:2.2490 accuracy:0.8542 precision:0.8542 recall:0.8542 f1:0.8542\n",
      "[sklearn_metrics] Epoch:7 loss:2.5991 accuracy:0.8527 precision:0.8527 recall:0.8527 f1:0.8527\n",
      "[sklearn_metrics] Epoch:7 loss:3.0206 accuracy:0.8486 precision:0.8486 recall:0.8486 f1:0.8486\n",
      "[sklearn_metrics] Epoch:7 loss:3.3961 accuracy:0.8464 precision:0.8464 recall:0.8464 f1:0.8464\n",
      "[sklearn_metrics] Epoch:7 loss:3.7373 accuracy:0.8445 precision:0.8445 recall:0.8445 f1:0.8445\n",
      "[sklearn_metrics] Epoch:7 loss:4.1968 accuracy:0.8423 precision:0.8423 recall:0.8423 f1:0.8423\n",
      "[sklearn_metrics] Epoch:7 loss:4.5686 accuracy:0.8451 precision:0.8451 recall:0.8451 f1:0.8451\n",
      "[sklearn_metrics] Epoch:7 loss:4.9127 accuracy:0.8462 precision:0.8462 recall:0.8462 f1:0.8462\n",
      "[sklearn_metrics] Epoch:7 loss:5.3455 accuracy:0.8465 precision:0.8465 recall:0.8465 f1:0.8465\n",
      "[sklearn_metrics] Epoch:8 loss:0.3551 accuracy:0.8281 precision:0.8281 recall:0.8281 f1:0.8281\n",
      "[sklearn_metrics] Epoch:8 loss:0.7007 accuracy:0.8359 precision:0.8359 recall:0.8359 f1:0.8359\n",
      "[sklearn_metrics] Epoch:8 loss:1.0386 accuracy:0.8490 precision:0.8490 recall:0.8490 f1:0.8490\n",
      "[sklearn_metrics] Epoch:8 loss:1.4640 accuracy:0.8398 precision:0.8398 recall:0.8398 f1:0.8398\n",
      "[sklearn_metrics] Epoch:8 loss:1.7278 accuracy:0.8562 precision:0.8562 recall:0.8562 f1:0.8562\n",
      "[sklearn_metrics] Epoch:8 loss:1.9623 accuracy:0.8620 precision:0.8620 recall:0.8620 f1:0.8620\n",
      "[sklearn_metrics] Epoch:8 loss:2.2115 accuracy:0.8683 precision:0.8683 recall:0.8683 f1:0.8683\n",
      "[sklearn_metrics] Epoch:8 loss:2.4577 accuracy:0.8711 precision:0.8711 recall:0.8711 f1:0.8711\n",
      "[sklearn_metrics] Epoch:8 loss:2.7390 accuracy:0.8715 precision:0.8715 recall:0.8715 f1:0.8715\n",
      "[sklearn_metrics] Epoch:8 loss:3.0333 accuracy:0.8727 precision:0.8727 recall:0.8727 f1:0.8727\n",
      "[sklearn_metrics] Epoch:8 loss:3.3689 accuracy:0.8714 precision:0.8714 recall:0.8714 f1:0.8714\n",
      "[sklearn_metrics] Epoch:8 loss:3.6970 accuracy:0.8704 precision:0.8704 recall:0.8704 f1:0.8704\n",
      "[sklearn_metrics] Epoch:8 loss:4.1207 accuracy:0.8678 precision:0.8678 recall:0.8678 f1:0.8678\n",
      "[sklearn_metrics] Epoch:8 loss:4.3453 accuracy:0.8694 precision:0.8694 recall:0.8694 f1:0.8694\n",
      "[sklearn_metrics] Epoch:9 loss:0.2267 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:9 loss:0.5343 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:9 loss:0.7470 accuracy:0.9167 precision:0.9167 recall:0.9167 f1:0.9167\n",
      "[sklearn_metrics] Epoch:9 loss:1.0294 accuracy:0.9062 precision:0.9062 recall:0.9062 f1:0.9062\n",
      "[sklearn_metrics] Epoch:9 loss:1.2263 accuracy:0.9094 precision:0.9094 recall:0.9094 f1:0.9094\n",
      "[sklearn_metrics] Epoch:9 loss:1.4742 accuracy:0.9062 precision:0.9062 recall:0.9062 f1:0.9062\n",
      "[sklearn_metrics] Epoch:9 loss:1.7599 accuracy:0.9051 precision:0.9051 recall:0.9051 f1:0.9051\n",
      "[sklearn_metrics] Epoch:9 loss:2.0827 accuracy:0.9014 precision:0.9014 recall:0.9014 f1:0.9014\n",
      "[sklearn_metrics] Epoch:9 loss:2.4002 accuracy:0.9002 precision:0.9002 recall:0.9002 f1:0.9002\n",
      "[sklearn_metrics] Epoch:9 loss:2.6325 accuracy:0.9016 precision:0.9016 recall:0.9016 f1:0.9016\n",
      "[sklearn_metrics] Epoch:9 loss:2.8342 accuracy:0.9020 precision:0.9020 recall:0.9020 f1:0.9020\n",
      "[sklearn_metrics] Epoch:9 loss:3.0226 accuracy:0.9036 precision:0.9036 recall:0.9036 f1:0.9036\n",
      "[sklearn_metrics] Epoch:9 loss:3.3891 accuracy:0.8978 precision:0.8978 recall:0.8978 f1:0.8978\n",
      "[sklearn_metrics] Epoch:9 loss:3.7251 accuracy:0.8965 precision:0.8965 recall:0.8965 f1:0.8965\n",
      "[sklearn_metrics] Epoch:10 loss:0.2415 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:10 loss:0.6671 accuracy:0.8867 precision:0.8867 recall:0.8867 f1:0.8867\n",
      "[sklearn_metrics] Epoch:10 loss:0.9268 accuracy:0.8932 precision:0.8932 recall:0.8932 f1:0.8932\n",
      "[sklearn_metrics] Epoch:10 loss:1.1845 accuracy:0.8906 precision:0.8906 recall:0.8906 f1:0.8906\n",
      "[sklearn_metrics] Epoch:10 loss:1.4466 accuracy:0.8922 precision:0.8922 recall:0.8922 f1:0.8922\n",
      "[sklearn_metrics] Epoch:10 loss:1.9790 accuracy:0.8841 precision:0.8841 recall:0.8841 f1:0.8841\n",
      "[sklearn_metrics] Epoch:10 loss:2.3746 accuracy:0.8817 precision:0.8817 recall:0.8817 f1:0.8817\n",
      "[sklearn_metrics] Epoch:10 loss:2.7561 accuracy:0.8779 precision:0.8779 recall:0.8779 f1:0.8779\n",
      "[sklearn_metrics] Epoch:10 loss:2.9692 accuracy:0.8802 precision:0.8802 recall:0.8802 f1:0.8802\n",
      "[sklearn_metrics] Epoch:10 loss:3.2540 accuracy:0.8812 precision:0.8812 recall:0.8812 f1:0.8812\n",
      "[sklearn_metrics] Epoch:10 loss:3.6181 accuracy:0.8786 precision:0.8786 recall:0.8786 f1:0.8786\n",
      "[sklearn_metrics] Epoch:10 loss:3.9193 accuracy:0.8809 precision:0.8809 recall:0.8809 f1:0.8809\n",
      "[sklearn_metrics] Epoch:10 loss:4.3136 accuracy:0.8792 precision:0.8792 recall:0.8792 f1:0.8792\n",
      "[sklearn_metrics] Epoch:10 loss:4.6466 accuracy:0.8794 precision:0.8794 recall:0.8794 f1:0.8794\n",
      "[sklearn_metrics] Epoch:11 loss:0.1757 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:11 loss:0.4195 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:11 loss:0.7519 accuracy:0.9062 precision:0.9062 recall:0.9062 f1:0.9062\n",
      "[sklearn_metrics] Epoch:11 loss:1.1055 accuracy:0.8906 precision:0.8906 recall:0.8906 f1:0.8906\n",
      "[sklearn_metrics] Epoch:11 loss:1.4140 accuracy:0.8875 precision:0.8875 recall:0.8875 f1:0.8875\n",
      "[sklearn_metrics] Epoch:11 loss:1.6257 accuracy:0.8932 precision:0.8932 recall:0.8932 f1:0.8932\n",
      "[sklearn_metrics] Epoch:11 loss:1.8881 accuracy:0.8917 precision:0.8917 recall:0.8917 f1:0.8917\n",
      "[sklearn_metrics] Epoch:11 loss:2.1901 accuracy:0.8896 precision:0.8896 recall:0.8896 f1:0.8896\n",
      "[sklearn_metrics] Epoch:11 loss:2.7581 accuracy:0.8793 precision:0.8793 recall:0.8793 f1:0.8793\n",
      "[sklearn_metrics] Epoch:11 loss:3.1476 accuracy:0.8766 precision:0.8766 recall:0.8766 f1:0.8766\n",
      "[sklearn_metrics] Epoch:11 loss:3.4379 accuracy:0.8778 precision:0.8778 recall:0.8778 f1:0.8778\n",
      "[sklearn_metrics] Epoch:11 loss:3.7203 accuracy:0.8776 precision:0.8776 recall:0.8776 f1:0.8776\n",
      "[sklearn_metrics] Epoch:11 loss:4.0661 accuracy:0.8762 precision:0.8762 recall:0.8762 f1:0.8762\n",
      "[sklearn_metrics] Epoch:11 loss:4.3634 accuracy:0.8759 precision:0.8759 recall:0.8759 f1:0.8759\n",
      "[sklearn_metrics] Epoch:12 loss:0.2232 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:12 loss:0.4122 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:12 loss:0.6056 accuracy:0.9245 precision:0.9245 recall:0.9245 f1:0.9245\n",
      "[sklearn_metrics] Epoch:12 loss:0.8034 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:12 loss:1.0344 accuracy:0.9281 precision:0.9281 recall:0.9281 f1:0.9281\n",
      "[sklearn_metrics] Epoch:12 loss:1.3302 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:12 loss:1.5888 accuracy:0.9230 precision:0.9230 recall:0.9230 f1:0.9230\n",
      "[sklearn_metrics] Epoch:12 loss:1.8516 accuracy:0.9199 precision:0.9199 recall:0.9199 f1:0.9199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn_metrics] Epoch:12 loss:2.1737 accuracy:0.9149 precision:0.9149 recall:0.9149 f1:0.9149\n",
      "[sklearn_metrics] Epoch:12 loss:2.5623 accuracy:0.9102 precision:0.9102 recall:0.9102 f1:0.9102\n",
      "[sklearn_metrics] Epoch:12 loss:2.9361 accuracy:0.9070 precision:0.9070 recall:0.9070 f1:0.9070\n",
      "[sklearn_metrics] Epoch:12 loss:3.1804 accuracy:0.9069 precision:0.9069 recall:0.9069 f1:0.9069\n",
      "[sklearn_metrics] Epoch:12 loss:3.3993 accuracy:0.9075 precision:0.9075 recall:0.9075 f1:0.9075\n",
      "[sklearn_metrics] Epoch:12 loss:3.6603 accuracy:0.9076 precision:0.9076 recall:0.9076 f1:0.9076\n",
      "[sklearn_metrics] Epoch:13 loss:0.2458 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:13 loss:0.6700 accuracy:0.8906 precision:0.8906 recall:0.8906 f1:0.8906\n",
      "[sklearn_metrics] Epoch:13 loss:1.0091 accuracy:0.8802 precision:0.8802 recall:0.8802 f1:0.8802\n",
      "[sklearn_metrics] Epoch:13 loss:1.2314 accuracy:0.8867 precision:0.8867 recall:0.8867 f1:0.8867\n",
      "[sklearn_metrics] Epoch:13 loss:1.5064 accuracy:0.8922 precision:0.8922 recall:0.8922 f1:0.8922\n",
      "[sklearn_metrics] Epoch:13 loss:1.7229 accuracy:0.8958 precision:0.8958 recall:0.8958 f1:0.8958\n",
      "[sklearn_metrics] Epoch:13 loss:2.0436 accuracy:0.8895 precision:0.8895 recall:0.8895 f1:0.8895\n",
      "[sklearn_metrics] Epoch:13 loss:2.2711 accuracy:0.8926 precision:0.8926 recall:0.8926 f1:0.8926\n",
      "[sklearn_metrics] Epoch:13 loss:2.6067 accuracy:0.8898 precision:0.8898 recall:0.8898 f1:0.8898\n",
      "[sklearn_metrics] Epoch:13 loss:2.9722 accuracy:0.8844 precision:0.8844 recall:0.8844 f1:0.8844\n",
      "[sklearn_metrics] Epoch:13 loss:3.1898 accuracy:0.8899 precision:0.8899 recall:0.8899 f1:0.8899\n",
      "[sklearn_metrics] Epoch:13 loss:3.4152 accuracy:0.8900 precision:0.8900 recall:0.8900 f1:0.8900\n",
      "[sklearn_metrics] Epoch:13 loss:3.7699 accuracy:0.8888 precision:0.8888 recall:0.8888 f1:0.8888\n",
      "[sklearn_metrics] Epoch:13 loss:4.0630 accuracy:0.8876 precision:0.8876 recall:0.8876 f1:0.8876\n",
      "[sklearn_metrics] Epoch:14 loss:0.2593 accuracy:0.8906 precision:0.8906 recall:0.8906 f1:0.8906\n",
      "[sklearn_metrics] Epoch:14 loss:0.5419 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:14 loss:0.7501 accuracy:0.9089 precision:0.9089 recall:0.9089 f1:0.9089\n",
      "[sklearn_metrics] Epoch:14 loss:1.0586 accuracy:0.9062 precision:0.9062 recall:0.9062 f1:0.9062\n",
      "[sklearn_metrics] Epoch:14 loss:1.2777 accuracy:0.9047 precision:0.9047 recall:0.9047 f1:0.9047\n",
      "[sklearn_metrics] Epoch:14 loss:1.4562 accuracy:0.9102 precision:0.9102 recall:0.9102 f1:0.9102\n",
      "[sklearn_metrics] Epoch:14 loss:1.7200 accuracy:0.9085 precision:0.9085 recall:0.9085 f1:0.9085\n",
      "[sklearn_metrics] Epoch:14 loss:2.0715 accuracy:0.9043 precision:0.9043 recall:0.9043 f1:0.9043\n",
      "[sklearn_metrics] Epoch:14 loss:2.3095 accuracy:0.9054 precision:0.9054 recall:0.9054 f1:0.9054\n",
      "[sklearn_metrics] Epoch:14 loss:2.5562 accuracy:0.9070 precision:0.9070 recall:0.9070 f1:0.9070\n",
      "[sklearn_metrics] Epoch:14 loss:2.8420 accuracy:0.9034 precision:0.9034 recall:0.9034 f1:0.9034\n",
      "[sklearn_metrics] Epoch:14 loss:3.0774 accuracy:0.9049 precision:0.9049 recall:0.9049 f1:0.9049\n",
      "[sklearn_metrics] Epoch:14 loss:3.3544 accuracy:0.9044 precision:0.9044 recall:0.9044 f1:0.9044\n",
      "[sklearn_metrics] Epoch:14 loss:3.5183 accuracy:0.9053 precision:0.9053 recall:0.9053 f1:0.9053\n",
      "[sklearn_metrics] Epoch:15 loss:0.1942 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:15 loss:0.4314 accuracy:0.9180 precision:0.9180 recall:0.9180 f1:0.9180\n",
      "[sklearn_metrics] Epoch:15 loss:0.6742 accuracy:0.9167 precision:0.9167 recall:0.9167 f1:0.9167\n",
      "[sklearn_metrics] Epoch:15 loss:0.8406 accuracy:0.9238 precision:0.9238 recall:0.9238 f1:0.9238\n",
      "[sklearn_metrics] Epoch:15 loss:1.0169 accuracy:0.9234 precision:0.9234 recall:0.9234 f1:0.9234\n",
      "[sklearn_metrics] Epoch:15 loss:1.2410 accuracy:0.9232 precision:0.9232 recall:0.9232 f1:0.9232\n",
      "[sklearn_metrics] Epoch:15 loss:1.4713 accuracy:0.9241 precision:0.9241 recall:0.9241 f1:0.9241\n",
      "[sklearn_metrics] Epoch:15 loss:1.7929 accuracy:0.9170 precision:0.9170 recall:0.9170 f1:0.9170\n",
      "[sklearn_metrics] Epoch:15 loss:1.9693 accuracy:0.9167 precision:0.9167 recall:0.9167 f1:0.9167\n",
      "[sklearn_metrics] Epoch:15 loss:2.2057 accuracy:0.9172 precision:0.9172 recall:0.9172 f1:0.9172\n",
      "[sklearn_metrics] Epoch:15 loss:2.3563 accuracy:0.9183 precision:0.9183 recall:0.9183 f1:0.9183\n",
      "[sklearn_metrics] Epoch:15 loss:2.6413 accuracy:0.9154 precision:0.9154 recall:0.9154 f1:0.9154\n",
      "[sklearn_metrics] Epoch:15 loss:2.9029 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:15 loss:3.1313 accuracy:0.9135 precision:0.9135 recall:0.9135 f1:0.9135\n",
      "[sklearn_metrics] Epoch:16 loss:0.1730 accuracy:0.9062 precision:0.9062 recall:0.9062 f1:0.9062\n",
      "[sklearn_metrics] Epoch:16 loss:0.4056 accuracy:0.8984 precision:0.8984 recall:0.8984 f1:0.8984\n",
      "[sklearn_metrics] Epoch:16 loss:0.6427 accuracy:0.9036 precision:0.9036 recall:0.9036 f1:0.9036\n",
      "[sklearn_metrics] Epoch:16 loss:0.8763 accuracy:0.9062 precision:0.9062 recall:0.9062 f1:0.9062\n",
      "[sklearn_metrics] Epoch:16 loss:1.1458 accuracy:0.9062 precision:0.9062 recall:0.9062 f1:0.9062\n",
      "[sklearn_metrics] Epoch:16 loss:1.2909 accuracy:0.9167 precision:0.9167 recall:0.9167 f1:0.9167\n",
      "[sklearn_metrics] Epoch:16 loss:1.5832 accuracy:0.9107 precision:0.9107 recall:0.9107 f1:0.9107\n",
      "[sklearn_metrics] Epoch:16 loss:1.8691 accuracy:0.9082 precision:0.9082 recall:0.9082 f1:0.9082\n",
      "[sklearn_metrics] Epoch:16 loss:2.0154 accuracy:0.9132 precision:0.9132 recall:0.9132 f1:0.9132\n",
      "[sklearn_metrics] Epoch:16 loss:2.1998 accuracy:0.9148 precision:0.9148 recall:0.9148 f1:0.9148\n",
      "[sklearn_metrics] Epoch:16 loss:2.5655 accuracy:0.9119 precision:0.9119 recall:0.9119 f1:0.9119\n",
      "[sklearn_metrics] Epoch:16 loss:2.8061 accuracy:0.9128 precision:0.9128 recall:0.9128 f1:0.9128\n",
      "[sklearn_metrics] Epoch:16 loss:2.9845 accuracy:0.9147 precision:0.9147 recall:0.9147 f1:0.9147\n",
      "[sklearn_metrics] Epoch:16 loss:3.1224 accuracy:0.9147 precision:0.9147 recall:0.9147 f1:0.9147\n",
      "[sklearn_metrics] Epoch:17 loss:0.1022 accuracy:0.9609 precision:0.9609 recall:0.9609 f1:0.9609\n",
      "[sklearn_metrics] Epoch:17 loss:0.2751 accuracy:0.9609 precision:0.9609 recall:0.9609 f1:0.9609\n",
      "[sklearn_metrics] Epoch:17 loss:0.4232 accuracy:0.9531 precision:0.9531 recall:0.9531 f1:0.9531\n",
      "[sklearn_metrics] Epoch:17 loss:0.6241 accuracy:0.9434 precision:0.9434 recall:0.9434 f1:0.9434\n",
      "[sklearn_metrics] Epoch:17 loss:0.7946 accuracy:0.9437 precision:0.9437 recall:0.9437 f1:0.9437\n",
      "[sklearn_metrics] Epoch:17 loss:1.0360 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:17 loss:1.2168 accuracy:0.9353 precision:0.9353 recall:0.9353 f1:0.9353\n",
      "[sklearn_metrics] Epoch:17 loss:1.3834 accuracy:0.9365 precision:0.9365 recall:0.9365 f1:0.9365\n",
      "[sklearn_metrics] Epoch:17 loss:1.5342 accuracy:0.9358 precision:0.9358 recall:0.9358 f1:0.9358\n",
      "[sklearn_metrics] Epoch:17 loss:1.6611 accuracy:0.9359 precision:0.9359 recall:0.9359 f1:0.9359\n",
      "[sklearn_metrics] Epoch:17 loss:1.8024 accuracy:0.9382 precision:0.9382 recall:0.9382 f1:0.9382\n",
      "[sklearn_metrics] Epoch:17 loss:1.9302 accuracy:0.9382 precision:0.9382 recall:0.9382 f1:0.9382\n",
      "[sklearn_metrics] Epoch:17 loss:2.3003 accuracy:0.9333 precision:0.9333 recall:0.9333 f1:0.9333\n",
      "[sklearn_metrics] Epoch:17 loss:2.4945 accuracy:0.9329 precision:0.9329 recall:0.9329 f1:0.9329\n",
      "[sklearn_metrics] Epoch:18 loss:0.1314 accuracy:0.9844 precision:0.9844 recall:0.9844 f1:0.9844\n",
      "[sklearn_metrics] Epoch:18 loss:0.3054 accuracy:0.9531 precision:0.9531 recall:0.9531 f1:0.9531\n",
      "[sklearn_metrics] Epoch:18 loss:0.5758 accuracy:0.9427 precision:0.9427 recall:0.9427 f1:0.9427\n",
      "[sklearn_metrics] Epoch:18 loss:0.8815 accuracy:0.9277 precision:0.9277 recall:0.9277 f1:0.9277\n",
      "[sklearn_metrics] Epoch:18 loss:1.0437 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:18 loss:1.1712 accuracy:0.9323 precision:0.9323 recall:0.9323 f1:0.9323\n",
      "[sklearn_metrics] Epoch:18 loss:1.3480 accuracy:0.9319 precision:0.9319 recall:0.9319 f1:0.9319\n",
      "[sklearn_metrics] Epoch:18 loss:1.6917 accuracy:0.9258 precision:0.9258 recall:0.9258 f1:0.9258\n",
      "[sklearn_metrics] Epoch:18 loss:2.1011 accuracy:0.9210 precision:0.9210 recall:0.9210 f1:0.9210\n",
      "[sklearn_metrics] Epoch:18 loss:2.2816 accuracy:0.9203 precision:0.9203 recall:0.9203 f1:0.9203\n",
      "[sklearn_metrics] Epoch:18 loss:2.6234 accuracy:0.9176 precision:0.9176 recall:0.9176 f1:0.9176\n",
      "[sklearn_metrics] Epoch:18 loss:2.9006 accuracy:0.9160 precision:0.9160 recall:0.9160 f1:0.9160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn_metrics] Epoch:18 loss:3.1152 accuracy:0.9177 precision:0.9177 recall:0.9177 f1:0.9177\n",
      "[sklearn_metrics] Epoch:18 loss:3.5273 accuracy:0.9165 precision:0.9165 recall:0.9165 f1:0.9165\n",
      "[sklearn_metrics] Epoch:19 loss:0.1900 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:19 loss:0.2997 accuracy:0.9492 precision:0.9492 recall:0.9492 f1:0.9492\n",
      "[sklearn_metrics] Epoch:19 loss:0.5972 accuracy:0.9271 precision:0.9271 recall:0.9271 f1:0.9271\n",
      "[sklearn_metrics] Epoch:19 loss:0.8562 accuracy:0.9238 precision:0.9238 recall:0.9238 f1:0.9238\n",
      "[sklearn_metrics] Epoch:19 loss:1.0743 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:19 loss:1.2236 accuracy:0.9232 precision:0.9232 recall:0.9232 f1:0.9232\n",
      "[sklearn_metrics] Epoch:19 loss:1.4404 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:19 loss:1.6700 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:19 loss:1.9418 accuracy:0.9184 precision:0.9184 recall:0.9184 f1:0.9184\n",
      "[sklearn_metrics] Epoch:19 loss:2.1977 accuracy:0.9172 precision:0.9172 recall:0.9172 f1:0.9172\n",
      "[sklearn_metrics] Epoch:19 loss:2.3883 accuracy:0.9176 precision:0.9176 recall:0.9176 f1:0.9176\n",
      "[sklearn_metrics] Epoch:19 loss:2.5588 accuracy:0.9186 precision:0.9186 recall:0.9186 f1:0.9186\n",
      "[sklearn_metrics] Epoch:19 loss:2.8492 accuracy:0.9183 precision:0.9183 recall:0.9183 f1:0.9183\n",
      "[sklearn_metrics] Epoch:19 loss:3.1429 accuracy:0.9182 precision:0.9182 recall:0.9182 f1:0.9182\n",
      "[sklearn_metrics] Epoch:20 loss:0.1864 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:20 loss:0.3559 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:20 loss:0.6118 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:20 loss:0.7219 accuracy:0.9512 precision:0.9512 recall:0.9512 f1:0.9512\n",
      "[sklearn_metrics] Epoch:20 loss:0.9310 accuracy:0.9422 precision:0.9422 recall:0.9422 f1:0.9422\n",
      "[sklearn_metrics] Epoch:20 loss:1.1187 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:20 loss:1.3018 accuracy:0.9364 precision:0.9364 recall:0.9364 f1:0.9364\n",
      "[sklearn_metrics] Epoch:20 loss:1.5176 accuracy:0.9326 precision:0.9326 recall:0.9326 f1:0.9326\n",
      "[sklearn_metrics] Epoch:20 loss:1.9933 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:20 loss:2.1632 accuracy:0.9289 precision:0.9289 recall:0.9289 f1:0.9289\n",
      "[sklearn_metrics] Epoch:20 loss:2.4734 accuracy:0.9247 precision:0.9247 recall:0.9247 f1:0.9247\n",
      "[sklearn_metrics] Epoch:20 loss:2.8240 accuracy:0.9193 precision:0.9193 recall:0.9193 f1:0.9193\n",
      "[sklearn_metrics] Epoch:20 loss:3.0137 accuracy:0.9201 precision:0.9201 recall:0.9201 f1:0.9201\n",
      "[sklearn_metrics] Epoch:20 loss:3.3237 accuracy:0.9194 precision:0.9194 recall:0.9194 f1:0.9194\n",
      "[sklearn_metrics] Epoch:21 loss:0.2966 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:21 loss:0.4098 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:21 loss:0.6018 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:21 loss:0.7264 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:21 loss:1.0160 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:21 loss:1.1612 accuracy:0.9310 precision:0.9310 recall:0.9310 f1:0.9310\n",
      "[sklearn_metrics] Epoch:21 loss:1.4749 accuracy:0.9263 precision:0.9263 recall:0.9263 f1:0.9263\n",
      "[sklearn_metrics] Epoch:21 loss:1.7579 accuracy:0.9258 precision:0.9258 recall:0.9258 f1:0.9258\n",
      "[sklearn_metrics] Epoch:21 loss:1.9803 accuracy:0.9245 precision:0.9245 recall:0.9245 f1:0.9245\n",
      "[sklearn_metrics] Epoch:21 loss:2.2701 accuracy:0.9242 precision:0.9242 recall:0.9242 f1:0.9242\n",
      "[sklearn_metrics] Epoch:21 loss:2.4972 accuracy:0.9240 precision:0.9240 recall:0.9240 f1:0.9240\n",
      "[sklearn_metrics] Epoch:21 loss:2.7450 accuracy:0.9212 precision:0.9212 recall:0.9212 f1:0.9212\n",
      "[sklearn_metrics] Epoch:21 loss:2.9492 accuracy:0.9207 precision:0.9207 recall:0.9207 f1:0.9207\n",
      "[sklearn_metrics] Epoch:21 loss:3.4914 accuracy:0.9194 precision:0.9194 recall:0.9194 f1:0.9194\n",
      "[sklearn_metrics] Epoch:22 loss:0.1403 accuracy:0.9688 precision:0.9688 recall:0.9688 f1:0.9688\n",
      "[sklearn_metrics] Epoch:22 loss:0.5007 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:22 loss:0.6906 accuracy:0.9115 precision:0.9115 recall:0.9115 f1:0.9115\n",
      "[sklearn_metrics] Epoch:22 loss:0.8954 accuracy:0.9180 precision:0.9180 recall:0.9180 f1:0.9180\n",
      "[sklearn_metrics] Epoch:22 loss:1.1575 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:22 loss:1.4082 accuracy:0.9154 precision:0.9154 recall:0.9154 f1:0.9154\n",
      "[sklearn_metrics] Epoch:22 loss:1.5507 accuracy:0.9196 precision:0.9196 recall:0.9196 f1:0.9196\n",
      "[sklearn_metrics] Epoch:22 loss:1.8165 accuracy:0.9160 precision:0.9160 recall:0.9160 f1:0.9160\n",
      "[sklearn_metrics] Epoch:22 loss:2.1888 accuracy:0.9106 precision:0.9106 recall:0.9106 f1:0.9106\n",
      "[sklearn_metrics] Epoch:22 loss:2.4507 accuracy:0.9102 precision:0.9102 recall:0.9102 f1:0.9102\n",
      "[sklearn_metrics] Epoch:22 loss:2.7439 accuracy:0.9098 precision:0.9098 recall:0.9098 f1:0.9098\n",
      "[sklearn_metrics] Epoch:22 loss:3.0206 accuracy:0.9115 precision:0.9115 recall:0.9115 f1:0.9115\n",
      "[sklearn_metrics] Epoch:22 loss:3.2300 accuracy:0.9099 precision:0.9099 recall:0.9099 f1:0.9099\n",
      "[sklearn_metrics] Epoch:22 loss:3.4971 accuracy:0.9088 precision:0.9088 recall:0.9088 f1:0.9088\n",
      "[sklearn_metrics] Epoch:23 loss:0.1598 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:23 loss:0.3978 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:23 loss:0.6610 accuracy:0.9089 precision:0.9089 recall:0.9089 f1:0.9089\n",
      "[sklearn_metrics] Epoch:23 loss:0.8519 accuracy:0.9121 precision:0.9121 recall:0.9121 f1:0.9121\n",
      "[sklearn_metrics] Epoch:23 loss:1.0753 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:23 loss:1.3298 accuracy:0.9089 precision:0.9089 recall:0.9089 f1:0.9089\n",
      "[sklearn_metrics] Epoch:23 loss:1.5788 accuracy:0.9096 precision:0.9096 recall:0.9096 f1:0.9096\n",
      "[sklearn_metrics] Epoch:23 loss:1.7152 accuracy:0.9131 precision:0.9131 recall:0.9131 f1:0.9131\n",
      "[sklearn_metrics] Epoch:23 loss:1.9427 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:23 loss:2.1885 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:23 loss:2.4227 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:23 loss:2.7243 accuracy:0.9121 precision:0.9121 recall:0.9121 f1:0.9121\n",
      "[sklearn_metrics] Epoch:23 loss:2.9741 accuracy:0.9111 precision:0.9111 recall:0.9111 f1:0.9111\n",
      "[sklearn_metrics] Epoch:23 loss:3.2174 accuracy:0.9124 precision:0.9124 recall:0.9124 f1:0.9124\n",
      "[sklearn_metrics] Epoch:24 loss:0.1346 accuracy:0.9375 precision:0.9375 recall:0.9375 f1:0.9375\n",
      "[sklearn_metrics] Epoch:24 loss:0.2526 accuracy:0.9531 precision:0.9531 recall:0.9531 f1:0.9531\n",
      "[sklearn_metrics] Epoch:24 loss:0.4336 accuracy:0.9479 precision:0.9479 recall:0.9479 f1:0.9479\n",
      "[sklearn_metrics] Epoch:24 loss:0.5877 accuracy:0.9434 precision:0.9434 recall:0.9434 f1:0.9434\n",
      "[sklearn_metrics] Epoch:24 loss:0.7662 accuracy:0.9422 precision:0.9422 recall:0.9422 f1:0.9422\n",
      "[sklearn_metrics] Epoch:24 loss:0.9714 accuracy:0.9388 precision:0.9388 recall:0.9388 f1:0.9388\n",
      "[sklearn_metrics] Epoch:24 loss:1.0821 accuracy:0.9408 precision:0.9408 recall:0.9408 f1:0.9408\n",
      "[sklearn_metrics] Epoch:24 loss:1.3013 accuracy:0.9346 precision:0.9346 recall:0.9346 f1:0.9346\n",
      "[sklearn_metrics] Epoch:24 loss:1.5271 accuracy:0.9271 precision:0.9271 recall:0.9271 f1:0.9271\n",
      "[sklearn_metrics] Epoch:24 loss:1.8219 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:24 loss:1.9636 accuracy:0.9240 precision:0.9240 recall:0.9240 f1:0.9240\n",
      "[sklearn_metrics] Epoch:24 loss:2.1189 accuracy:0.9245 precision:0.9245 recall:0.9245 f1:0.9245\n",
      "[sklearn_metrics] Epoch:24 loss:2.2357 accuracy:0.9261 precision:0.9261 recall:0.9261 f1:0.9261\n",
      "[sklearn_metrics] Epoch:24 loss:2.5019 accuracy:0.9265 precision:0.9265 recall:0.9265 f1:0.9265\n",
      "[sklearn_metrics] Epoch:25 loss:0.2069 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:25 loss:0.4953 accuracy:0.9102 precision:0.9102 recall:0.9102 f1:0.9102\n",
      "[sklearn_metrics] Epoch:25 loss:0.7155 accuracy:0.9115 precision:0.9115 recall:0.9115 f1:0.9115\n",
      "[sklearn_metrics] Epoch:25 loss:0.9433 accuracy:0.9082 precision:0.9082 recall:0.9082 f1:0.9082\n",
      "[sklearn_metrics] Epoch:25 loss:1.0568 accuracy:0.9187 precision:0.9187 recall:0.9187 f1:0.9187\n",
      "[sklearn_metrics] Epoch:25 loss:1.3044 accuracy:0.9206 precision:0.9206 recall:0.9206 f1:0.9206\n",
      "[sklearn_metrics] Epoch:25 loss:1.4264 accuracy:0.9252 precision:0.9252 recall:0.9252 f1:0.9252\n",
      "[sklearn_metrics] Epoch:25 loss:1.8096 accuracy:0.9199 precision:0.9199 recall:0.9199 f1:0.9199\n",
      "[sklearn_metrics] Epoch:25 loss:2.0052 accuracy:0.9184 precision:0.9184 recall:0.9184 f1:0.9184\n",
      "[sklearn_metrics] Epoch:25 loss:2.1616 accuracy:0.9203 precision:0.9203 recall:0.9203 f1:0.9203\n",
      "[sklearn_metrics] Epoch:25 loss:2.2884 accuracy:0.9212 precision:0.9212 recall:0.9212 f1:0.9212\n",
      "[sklearn_metrics] Epoch:25 loss:2.4562 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:25 loss:2.6925 accuracy:0.9201 precision:0.9201 recall:0.9201 f1:0.9201\n",
      "[sklearn_metrics] Epoch:25 loss:2.8365 accuracy:0.9206 precision:0.9206 recall:0.9206 f1:0.9206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sklearn_metrics] Epoch:26 loss:0.1842 accuracy:0.9297 precision:0.9297 recall:0.9297 f1:0.9297\n",
      "[sklearn_metrics] Epoch:26 loss:0.3419 accuracy:0.9336 precision:0.9336 recall:0.9336 f1:0.9336\n",
      "[sklearn_metrics] Epoch:26 loss:0.4843 accuracy:0.9427 precision:0.9427 recall:0.9427 f1:0.9427\n",
      "[sklearn_metrics] Epoch:26 loss:0.8922 accuracy:0.9180 precision:0.9180 recall:0.9180 f1:0.9180\n",
      "[sklearn_metrics] Epoch:26 loss:1.1338 accuracy:0.9156 precision:0.9156 recall:0.9156 f1:0.9156\n",
      "[sklearn_metrics] Epoch:26 loss:1.3095 accuracy:0.9206 precision:0.9206 recall:0.9206 f1:0.9206\n",
      "[sklearn_metrics] Epoch:26 loss:1.4724 accuracy:0.9185 precision:0.9185 recall:0.9185 f1:0.9185\n",
      "[sklearn_metrics] Epoch:26 loss:1.7440 accuracy:0.9170 precision:0.9170 recall:0.9170 f1:0.9170\n",
      "[sklearn_metrics] Epoch:26 loss:2.0839 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:26 loss:2.4166 accuracy:0.9148 precision:0.9148 recall:0.9148 f1:0.9148\n",
      "[sklearn_metrics] Epoch:26 loss:2.7405 accuracy:0.9119 precision:0.9119 recall:0.9119 f1:0.9119\n",
      "[sklearn_metrics] Epoch:26 loss:2.9462 accuracy:0.9121 precision:0.9121 recall:0.9121 f1:0.9121\n",
      "[sklearn_metrics] Epoch:26 loss:3.3280 accuracy:0.9111 precision:0.9111 recall:0.9111 f1:0.9111\n",
      "[sklearn_metrics] Epoch:26 loss:3.4153 accuracy:0.9124 precision:0.9124 recall:0.9124 f1:0.9124\n",
      "[sklearn_metrics] Epoch:27 loss:0.2259 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:27 loss:0.4647 accuracy:0.9219 precision:0.9219 recall:0.9219 f1:0.9219\n",
      "[sklearn_metrics] Epoch:27 loss:0.7454 accuracy:0.9036 precision:0.9036 recall:0.9036 f1:0.9036\n",
      "[sklearn_metrics] Epoch:27 loss:0.9711 accuracy:0.9043 precision:0.9043 recall:0.9043 f1:0.9043\n",
      "[sklearn_metrics] Epoch:27 loss:1.1635 accuracy:0.9047 precision:0.9047 recall:0.9047 f1:0.9047\n",
      "[sklearn_metrics] Epoch:27 loss:1.3212 accuracy:0.9115 precision:0.9115 recall:0.9115 f1:0.9115\n",
      "[sklearn_metrics] Epoch:27 loss:1.5325 accuracy:0.9163 precision:0.9163 recall:0.9163 f1:0.9163\n",
      "[sklearn_metrics] Epoch:27 loss:1.7296 accuracy:0.9141 precision:0.9141 recall:0.9141 f1:0.9141\n",
      "[sklearn_metrics] Epoch:27 loss:1.9951 accuracy:0.9097 precision:0.9097 recall:0.9097 f1:0.9097\n",
      "[sklearn_metrics] Epoch:27 loss:2.1872 accuracy:0.9094 precision:0.9094 recall:0.9094 f1:0.9094\n",
      "[sklearn_metrics] Epoch:27 loss:2.3628 accuracy:0.9098 precision:0.9098 recall:0.9098 f1:0.9098\n",
      "[sklearn_metrics] Epoch:27 loss:2.5204 accuracy:0.9121 precision:0.9121 recall:0.9121 f1:0.9121\n",
      "[sklearn_metrics] Epoch:27 loss:2.7930 accuracy:0.9117 precision:0.9117 recall:0.9117 f1:0.9117\n",
      "[sklearn_metrics] Epoch:27 loss:2.8615 accuracy:0.9129 precision:0.9129 recall:0.9129 f1:0.9129\n",
      "[sklearn_metrics] Epoch:28 loss:0.1673 accuracy:0.9453 precision:0.9453 recall:0.9453 f1:0.9453\n",
      "[sklearn_metrics] Epoch:28 loss:0.3370 accuracy:0.9336 precision:0.9336 recall:0.9336 f1:0.9336\n",
      "[sklearn_metrics] Epoch:28 loss:0.4046 accuracy:0.9479 precision:0.9479 recall:0.9479 f1:0.9479\n",
      "[sklearn_metrics] Epoch:28 loss:0.5408 accuracy:0.9473 precision:0.9473 recall:0.9473 f1:0.9473\n",
      "[sklearn_metrics] Epoch:28 loss:0.6223 accuracy:0.9500 precision:0.9500 recall:0.9500 f1:0.9500\n",
      "[sklearn_metrics] Epoch:28 loss:0.7448 accuracy:0.9492 precision:0.9492 recall:0.9492 f1:0.9492\n",
      "[sklearn_metrics] Epoch:28 loss:0.9159 accuracy:0.9498 precision:0.9498 recall:0.9498 f1:0.9498\n",
      "[sklearn_metrics] Epoch:28 loss:1.0966 accuracy:0.9473 precision:0.9473 recall:0.9473 f1:0.9473\n",
      "[sklearn_metrics] Epoch:28 loss:1.1969 accuracy:0.9479 precision:0.9479 recall:0.9479 f1:0.9479\n",
      "[sklearn_metrics] Epoch:28 loss:1.3608 accuracy:0.9477 precision:0.9477 recall:0.9477 f1:0.9477\n",
      "[sklearn_metrics] Epoch:28 loss:1.4957 accuracy:0.9474 precision:0.9474 recall:0.9474 f1:0.9474\n",
      "[sklearn_metrics] Epoch:28 loss:1.6375 accuracy:0.9486 precision:0.9486 recall:0.9486 f1:0.9486\n",
      "[sklearn_metrics] Epoch:28 loss:1.8449 accuracy:0.9465 precision:0.9465 recall:0.9465 f1:0.9465\n",
      "[sklearn_metrics] Epoch:28 loss:1.9924 accuracy:0.9471 precision:0.9471 recall:0.9471 f1:0.9471\n",
      "[sklearn_metrics] Epoch:29 loss:0.1078 accuracy:0.9688 precision:0.9688 recall:0.9688 f1:0.9688\n",
      "[sklearn_metrics] Epoch:29 loss:0.1949 accuracy:0.9648 precision:0.9648 recall:0.9648 f1:0.9648\n",
      "[sklearn_metrics] Epoch:29 loss:0.3926 accuracy:0.9531 precision:0.9531 recall:0.9531 f1:0.9531\n",
      "[sklearn_metrics] Epoch:29 loss:0.5322 accuracy:0.9512 precision:0.9512 recall:0.9512 f1:0.9512\n",
      "[sklearn_metrics] Epoch:29 loss:0.6454 accuracy:0.9516 precision:0.9516 recall:0.9516 f1:0.9516\n",
      "[sklearn_metrics] Epoch:29 loss:0.7587 accuracy:0.9518 precision:0.9518 recall:0.9518 f1:0.9518\n",
      "[sklearn_metrics] Epoch:29 loss:0.8339 accuracy:0.9520 precision:0.9520 recall:0.9520 f1:0.9520\n",
      "[sklearn_metrics] Epoch:29 loss:0.9666 accuracy:0.9531 precision:0.9531 recall:0.9531 f1:0.9531\n",
      "[sklearn_metrics] Epoch:29 loss:1.1249 accuracy:0.9514 precision:0.9514 recall:0.9514 f1:0.9514\n",
      "[sklearn_metrics] Epoch:29 loss:1.2899 accuracy:0.9492 precision:0.9492 recall:0.9492 f1:0.9492\n",
      "[sklearn_metrics] Epoch:29 loss:1.3907 accuracy:0.9510 precision:0.9510 recall:0.9510 f1:0.9510\n",
      "[sklearn_metrics] Epoch:29 loss:1.4966 accuracy:0.9512 precision:0.9512 recall:0.9512 f1:0.9512\n",
      "[sklearn_metrics] Epoch:29 loss:1.5941 accuracy:0.9519 precision:0.9519 recall:0.9519 f1:0.9519\n",
      "[sklearn_metrics] Epoch:29 loss:1.7479 accuracy:0.9512 precision:0.9512 recall:0.9512 f1:0.9512\n",
      "3.2154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.76        22\n",
      "           1       0.93      0.97      0.95        39\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       0.67      0.40      0.50         5\n",
      "           5       0.83      0.83      0.83        18\n",
      "           6       1.00      0.67      0.80        15\n",
      "           7       0.62      1.00      0.77         5\n",
      "           8       0.75      1.00      0.86         6\n",
      "           9       0.45      0.56      0.50         9\n",
      "\n",
      "    accuracy                           0.80       128\n",
      "   macro avg       0.70      0.72      0.70       128\n",
      "weighted avg       0.80      0.80      0.79       128\n",
      "\n",
      "[[17  1  0  0  0  1  0  0  0  3]\n",
      " [ 1 38  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  5  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  3]\n",
      " [ 0  2  0  0  0 15  0  1  0  0]\n",
      " [ 0  0  1  0  0  2 10  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  5  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  6  0]\n",
      " [ 1  0  0  0  1  0  0  0  2  5]]\n",
      "[sklearn_metrics] accuracy:0.8047 precision:0.8047 recall:0.8047 f1:0.8047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86        49\n",
      "           1       0.91      0.95      0.93        79\n",
      "           2       0.50      0.20      0.29         5\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       0.67      0.40      0.50         5\n",
      "           5       0.86      0.82      0.84        39\n",
      "           6       0.89      0.76      0.82        33\n",
      "           7       0.79      1.00      0.88        11\n",
      "           8       0.82      0.90      0.86        10\n",
      "           9       0.65      0.76      0.70        17\n",
      "\n",
      "    accuracy                           0.86       256\n",
      "   macro avg       0.79      0.77      0.77       256\n",
      "weighted avg       0.85      0.86      0.85       256\n",
      "\n",
      "[[43  1  0  0  0  1  0  0  0  4]\n",
      " [ 1 75  0  0  0  2  1  0  0  0]\n",
      " [ 4  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  8  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  3]\n",
      " [ 0  4  0  0  0 32  2  1  0  0]\n",
      " [ 1  2  1  0  0  2 25  2  0  0]\n",
      " [ 0  0  0  0  0  0  0 11  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  9  0]\n",
      " [ 1  0  0  0  1  0  0  0  2 13]]\n",
      "[sklearn_metrics] accuracy:0.8555 precision:0.8555 recall:0.8555 f1:0.8555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85        69\n",
      "           1       0.90      0.94      0.92       104\n",
      "           2       0.75      0.33      0.46         9\n",
      "           3       0.85      0.79      0.81        14\n",
      "           4       0.78      0.58      0.67        12\n",
      "           5       0.89      0.86      0.88        65\n",
      "           6       0.86      0.79      0.83        48\n",
      "           7       0.86      0.95      0.90        19\n",
      "           8       0.65      0.92      0.76        12\n",
      "           9       0.68      0.72      0.70        32\n",
      "\n",
      "    accuracy                           0.84       384\n",
      "   macro avg       0.80      0.77      0.78       384\n",
      "weighted avg       0.85      0.84      0.84       384\n",
      "\n",
      "[[59  1  0  0  0  1  2  0  0  6]\n",
      " [ 1 98  0  1  0  3  1  0  0  0]\n",
      " [ 6  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  3  0 11  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  7  0  0  0  0  4]\n",
      " [ 1  5  0  0  0 56  2  1  0  0]\n",
      " [ 1  2  1  0  0  3 38  2  0  1]\n",
      " [ 0  0  0  0  0  0  1 18  0  0]\n",
      " [ 1  0  0  0  0  0  0  0 11  0]\n",
      " [ 1  0  0  0  2  0  0  0  6 23]]\n",
      "[sklearn_metrics] accuracy:0.8438 precision:0.8438 recall:0.8438 f1:0.8438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85        77\n",
      "           1       0.91      0.95      0.93       116\n",
      "           2       0.80      0.36      0.50        11\n",
      "           3       0.87      0.81      0.84        16\n",
      "           4       0.80      0.57      0.67        14\n",
      "           5       0.89      0.87      0.88        67\n",
      "           6       0.85      0.80      0.83        51\n",
      "           7       0.87      0.95      0.91        21\n",
      "           8       0.68      0.93      0.79        14\n",
      "           9       0.71      0.77      0.74        39\n",
      "\n",
      "    accuracy                           0.85       426\n",
      "   macro avg       0.82      0.79      0.79       426\n",
      "weighted avg       0.85      0.85      0.85       426\n",
      "\n",
      "[[ 66   1   0   0   0   1   3   0   0   6]\n",
      " [  1 110   0   1   0   3   1   0   0   0]\n",
      " [  7   0   4   0   0   0   0   0   0   0]\n",
      " [  0   3   0  13   0   0   0   0   0   0]\n",
      " [  0   0   0   1   8   0   0   0   0   5]\n",
      " [  1   5   0   0   0  58   2   1   0   0]\n",
      " [  1   2   1   0   0   3  41   2   0   1]\n",
      " [  0   0   0   0   0   0   1  20   0   0]\n",
      " [  1   0   0   0   0   0   0   0  13   0]\n",
      " [  1   0   0   0   2   0   0   0   6  30]]\n",
      "[sklearn_metrics] accuracy:0.8521 precision:0.8521 recall:0.8521 f1:0.8521\n"
     ]
    }
   ],
   "source": [
    "start=datetime.now()\n",
    "total_step = len(train_loader)\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    tot_loss = 0.0\n",
    "    tot_acc = 0.0\n",
    "    train_preds = []\n",
    "    train_trues = []\n",
    "  # model.train()\n",
    "    for i,(train_data_batch, train_label_batch) in enumerate(train_loader):\n",
    "        train_data_batch = train_data_batch.float().to(device) #from double to float\n",
    "        train_label_batch = train_label_batch.to(device)\n",
    "        outputs = model(train_data_batch)\n",
    "        # _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, train_label_batch)\n",
    "        # print(loss)\n",
    "        #backword propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # accumulate the loss of each step \n",
    "        tot_loss += loss.data\n",
    "        train_outputs = outputs.argmax(dim=1)\n",
    "        train_preds.extend(train_outputs.detach().cpu().numpy())\n",
    "        train_trues.extend(train_label_batch.detach().cpu().numpy())\n",
    "        # tot_acc += (outputs.argmax(dim=1) == train_label_batch).sum().item()\n",
    "        sklearn_accuracy = accuracy_score(train_trues, train_preds)\n",
    "        sklearn_precision = precision_score(train_trues, train_preds, average='micro')\n",
    "        sklearn_recall = recall_score(train_trues, train_preds, average='micro')\n",
    "        sklearn_f1 = f1_score(train_trues, train_preds, average='micro')\n",
    "        print(\"[sklearn_metrics] Epoch:{} loss:{:.4f} accuracy:{:.4f} precision:{:.4f} recall:{:.4f} f1:{:.4f}\".format(epoch, tot_loss, sklearn_accuracy, sklearn_precision, sklearn_recall, sklearn_f1))\n",
    "stop=datetime.now()\n",
    "execution_time_ann=(stop-start)\n",
    "training_time_ann='%.4f'%(execution_time_ann).total_seconds()\n",
    "print(training_time_ann)\n",
    "        \n",
    "test_preds = []\n",
    "test_trues = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i,(test_data_batch, test_data_label) in enumerate(test_loader):\n",
    "        test_data_batch = test_data_batch.float().to(device) #from double to float\n",
    "        test_data_label = test_data_label.to(device)\n",
    "        test_outputs = model(test_data_batch)\n",
    "        probs = F.softmax(test_outputs, dim=1) \n",
    "        test_outputs = test_outputs.argmax(dim=1)\n",
    "        testloss = criterion(probs, test_data_label)\n",
    "#         preds = torch.argmax(logits, dim=1)\n",
    "        test_preds.extend(test_outputs.detach().cpu().numpy())\n",
    "        test_trues.extend(test_data_label.detach().cpu().numpy())\n",
    "        sklearn_accuracy = accuracy_score(test_trues, test_preds)\n",
    "        sklearn_precision = precision_score(test_trues, test_preds, average='micro')\n",
    "        sklearn_recall = recall_score(test_trues, test_preds, average='micro')\n",
    "        sklearn_f1 = f1_score(test_trues, test_preds, average='micro')\n",
    "        print(classification_report(test_trues, test_preds))\n",
    "        conf_matrix = confusion_matrix(test_trues, test_preds)\n",
    "        print(conf_matrix)\n",
    "#         plot_confusion_matrix(conf_matrix)\n",
    "        print(\"[sklearn_metrics] accuracy:{:.4f} precision:{:.4f} recall:{:.4f} f1:{:.4f}\".format(sklearn_accuracy, sklearn_precision, sklearn_recall, sklearn_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08470beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2154'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf50a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
